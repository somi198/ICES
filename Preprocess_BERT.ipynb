{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordpiece\n",
    "import create_pretraining_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('../dataset/QnA_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv('../dataset/paper.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('../dataset/finalDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAPER_FULL_TXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>목차먼지와 미세먼지미세먼지의 성분먼지와 미세먼지먼지란 대기 중에 떠다니거나 흩날려 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>힘의 MKSA 단위. 질량 1 의 물체에 작용하여 1m/s2의 가속도( )를 발생시...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>원래는 산소와 화합하는 반응 혹은 수소를 상실하는 반응을 산화라고 하였으나 현재는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>지구상에 존재하는 수많은 쓰레기 중가장 고약하기로 소문난 #플라스틱오늘 리사이클맨,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미세먼지 발생원은 자연적인 것과 인위적인 것으로 구분된다. 자연적 발생원은 흙먼지,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101197</th>\n",
       "      <td>지난 25일까지 애플워치 발화 발열 사고 15건 국내 14건 해외 1건 애플의 애플...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101198</th>\n",
       "      <td>오픈시그널 서울 인천 부산 조사 이전 전국 조사보다 가용성 상승 오픈시그널 홈페이지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101199</th>\n",
       "      <td>불붙은 새 먹거리 전쟁 AI 혼합현실 기반 제조 금융 의료SK텔레콤 KT LG유플러...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101200</th>\n",
       "      <td>시대가 변하면 명당도 바뀐다. 게티이미지뱅크 제공강원도 삼척에는 조선 태조의 5대조...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101201</th>\n",
       "      <td>애플 신제품 아이폰12 시리즈가 한국에 정식 출시된 30일 오전 서울 강남구 애플스...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101202 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           PAPER_FULL_TXT\n",
       "0       목차먼지와 미세먼지미세먼지의 성분먼지와 미세먼지먼지란 대기 중에 떠다니거나 흩날려 ...\n",
       "1       힘의 MKSA 단위. 질량 1 의 물체에 작용하여 1m/s2의 가속도( )를 발생시...\n",
       "2       원래는 산소와 화합하는 반응 혹은 수소를 상실하는 반응을 산화라고 하였으나 현재는 ...\n",
       "3       지구상에 존재하는 수많은 쓰레기 중가장 고약하기로 소문난 #플라스틱오늘 리사이클맨,...\n",
       "4       미세먼지 발생원은 자연적인 것과 인위적인 것으로 구분된다. 자연적 발생원은 흙먼지,...\n",
       "...                                                   ...\n",
       "101197  지난 25일까지 애플워치 발화 발열 사고 15건 국내 14건 해외 1건 애플의 애플...\n",
       "101198  오픈시그널 서울 인천 부산 조사 이전 전국 조사보다 가용성 상승 오픈시그널 홈페이지...\n",
       "101199  불붙은 새 먹거리 전쟁 AI 혼합현실 기반 제조 금융 의료SK텔레콤 KT LG유플러...\n",
       "101200  시대가 변하면 명당도 바뀐다. 게티이미지뱅크 제공강원도 삼척에는 조선 태조의 5대조...\n",
       "101201  애플 신제품 아이폰12 시리즈가 한국에 정식 출시된 30일 오전 서울 강남구 애플스...\n",
       "\n",
       "[101202 rows x 1 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.dropna()\n",
    "final = final.reset_index()\n",
    "final = final.drop(['index'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for i in range(len(final)):\n",
    "    #print(i)\n",
    "    text += final.loc[i].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('raw.txt', 'w')\n",
    "file.write(text)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open('my_vocab.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminated vocabulary scanning\n",
      "('##다', '##.')\n",
      "('##으', '##로')\n",
      "('##에', '##서')\n",
      "('##o', '##n')\n",
      "('##e', '##r')\n",
      "('##t', '##i')\n",
      "('##하', '##여')\n",
      "('##하', '##였')\n",
      "('##하', '##는')\n",
      "('##e', '##n')\n",
      "('##i', '##n')\n",
      "('##e', '##s')\n",
      "('연', '##구')\n",
      "('##a', '##l')\n",
      "('##q', '##u')\n",
      "('##o', '##r')\n",
      "('##하', '##고')\n",
      "('##qu', '##o')\n",
      "('##a', '##n')\n",
      "('##하였', '##다.')\n",
      "('##h', '##e')\n",
      "('##0', '##0')\n",
      "('있', '##다.')\n",
      "('##ti', '##on')\n",
      "('##e', '##d')\n",
      "('##a', '##r')\n",
      "('##s', '##quo')\n",
      "('o', '##f')\n",
      "('나', '##타')\n",
      "('##i', '##g')\n",
      "('대', '##한')\n",
      "('##며', '##,')\n",
      "('##l', '##e')\n",
      "('##a', '##t')\n",
      "('##적', '##으로')\n",
      "('##n', '##d')\n",
      "('사', '##용')\n",
      "('t', '##he')\n",
      "('##적', '##인')\n",
      "('##i', '##c')\n",
      "('있', '##는')\n",
      "('##r', '##o')\n",
      "('##r', '##e')\n",
      "('##이', '##다.')\n",
      "('##i', '##t')\n",
      "('결', '##과')\n",
      "('##0', '##1')\n",
      "('경', '##우')\n",
      "('##i', '##s')\n",
      "('##a', '##s')\n",
      "('a', '##nd')\n",
      "('##in', '##g')\n",
      "('분', '##석')\n",
      "('##었', '##다.')\n",
      "('##에서', '##는')\n",
      "('것', '##으로')\n",
      "('##s', '##p')\n",
      "('##하', '##기')\n",
      "('##en', '##t')\n",
      "('##)', '##,')\n",
      "('이', '##용')\n",
      "('따', '##라')\n",
      "('##e', '##l')\n",
      "('##)', '##.')\n",
      "('i', '##n')\n",
      "('##a', '##c')\n",
      "('##a', '##b')\n",
      "('##b', '##sp')\n",
      "('n', '##bsp')\n",
      "('##으', '##며,')\n",
      "('##고', '##,')\n",
      "('##e', '##t')\n",
      "('##i', '##d')\n",
      "('위', '##해')\n",
      "('##ig', '##.')\n",
      "('##한', '##다.')\n",
      "('r', '##squo')\n",
      "('영', '##향')\n",
      "('##e', '##c')\n",
      "('##성', '##을')\n",
      "('##m', '##p')\n",
      "('2', '##01')\n",
      "('l', '##squo')\n",
      "('##i', '##m')\n",
      "('##u', '##s')\n",
      "('##하', '##게')\n",
      "('0', '##.')\n",
      "('##o', '##l')\n",
      "('##다', '##(')\n",
      "('##o', '##t')\n",
      "('##되', '##어')\n",
      "('##ab', '##le')\n",
      "('##되', '##는')\n",
      "('##u', '##l')\n",
      "('측', '##정')\n",
      "('통', '##해')\n",
      "('증', '##가')\n",
      "('2', '##00')\n",
      "('나타', '##났')\n",
      "('필', '##요')\n",
      "training bpe 100 / 1000('##2', '##.')\n",
      "('방', '##법')\n",
      "('##다', '##는')\n",
      "('위', '##한')\n",
      "('##u', '##r')\n",
      "('발', '##생')\n",
      "('영향', '##을')\n",
      "('##된', '##다.')\n",
      "('##에', '##는')\n",
      "('또', '##한')\n",
      "('##i', '##l')\n",
      "('a', '##l')\n",
      "('대', '##상')\n",
      "('##자', '##의')\n",
      "('적', '##용')\n",
      "('##o', '##d')\n",
      "('##다', '##고')\n",
      "('##지', '##만')\n",
      "('##t', '##er')\n",
      "('##F', '##ig.')\n",
      "('가', '##장')\n",
      "('때', '##문')\n",
      "('##도', '##를')\n",
      "('##3', '##.')\n",
      "('차', '##이')\n",
      "('평', '##가')\n",
      "('##스', '##템')\n",
      "('변', '##화')\n",
      "('##a', '##m')\n",
      "('관', '##련')\n",
      "('1', '##0')\n",
      "('l', '##t')\n",
      "('정', '##보')\n",
      "('##c', '##e')\n",
      "('1', '##9')\n",
      "('t', '##o')\n",
      "('확', '##인')\n",
      "('##부', '##터')\n",
      "('##성', '##이')\n",
      "('실', '##험')\n",
      "('따', '##른')\n",
      "('##러', '##한')\n",
      "('##들', '##의')\n",
      "('##들', '##이')\n",
      "('수', '##행')\n",
      "('##이', '##터')\n",
      "('구', '##성')\n",
      "('비', '##교')\n",
      "('##o', '##s')\n",
      "('##였', '##다.')\n",
      "('##)', '##의')\n",
      "('개', '##발')\n",
      "('##1', '##.')\n",
      "('같', '##이')\n",
      "('유', '##의')\n",
      "('한', '##다.')\n",
      "('다', '##양')\n",
      "('s', '##t')\n",
      "('같', '##은')\n",
      "('활', '##용')\n",
      "('##도', '##가')\n",
      "('기', '##술')\n",
      "('##으', '##며')\n",
      "('가', '##능')\n",
      "('문', '##제')\n",
      "('프', '##로')\n",
      "('##v', '##e')\n",
      "('이', '##러한')\n",
      "('것', '##이')\n",
      "('##m', '##ent')\n",
      "('f', '##or')\n",
      "('##되', '##고')\n",
      "('이', '##상')\n",
      "('##되', '##었다.')\n",
      "('교', '##육')\n",
      "('##비', '##스')\n",
      "('##하', '##면')\n",
      "('##까', '##지')\n",
      "('##it', '##y')\n",
      "('##a', '##g')\n",
      "('높', '##은')\n",
      "('효', '##과')\n",
      "('가', '##지')\n",
      "('c', '##on')\n",
      "('##도', '##록')\n",
      "('##치', '##는')\n",
      "('##되', '##었')\n",
      "('##f', '##f')\n",
      "('대', '##해')\n",
      "('하', '##는')\n",
      "('것', '##을')\n",
      "('나타났', '##다.')\n",
      "('e', '##t')\n",
      "('##보', '##다')\n",
      "('##u', '##m')\n",
      "('##o', '##w')\n",
      "('따라', '##서')\n",
      "('##하', '##지')\n",
      "('1', '##.')\n",
      "('중', '##요')\n",
      "training bpe 200 / 1000('다', '##음')\n",
      "('제', '##시')\n",
      "('사', '##회')\n",
      "('때문', '##에')\n",
      "('##시', '##간')\n",
      "('이용', '##하여')\n",
      "('데', '##이터')\n",
      "('다양', '##한')\n",
      "('t', '##h')\n",
      "('##리', '##고')\n",
      "('조', '##사')\n",
      "('평', '##균')\n",
      "('##d', '##ot')\n",
      "('있', '##어')\n",
      "('시', '##스템')\n",
      "('감', '##소')\n",
      "('##들', '##은')\n",
      "('##1', '##)')\n",
      "('##T', '##able')\n",
      "('일', '##반')\n",
      "('나타', '##내')\n",
      "('##d', '##quo')\n",
      "('특', '##성')\n",
      "('요', '##인')\n",
      "('##u', '##c')\n",
      "('##4', '##.')\n",
      "('##a', '##d')\n",
      "('##e', '##g')\n",
      "('##서', '##는')\n",
      "('##므', '##로')\n",
      "('m', '##id')\n",
      "('관', '##계')\n",
      "('다', '##른')\n",
      "('F', '##ig.')\n",
      "('##u', '##n')\n",
      "('##하고', '##,')\n",
      "('시', '##간')\n",
      "('구', '##조')\n",
      "('##o', '##m')\n",
      "('지', '##역')\n",
      "('##이', '##나')\n",
      "('그', '##리고')\n",
      "('환', '##경')\n",
      "('이', '##는')\n",
      "('mid', '##dot')\n",
      "('al', '##.')\n",
      "('##a', '##p')\n",
      "('고', '##려')\n",
      "('미', '##치는')\n",
      "('제', '##공')\n",
      "('이', '##를')\n",
      "('각', '##각')\n",
      "('##e', '##m')\n",
      "('자', '##료')\n",
      "('##u', '##t')\n",
      "('##2', '##)')\n",
      "('##에', '##게')\n",
      "('p', '##ro')\n",
      "('##c', '##h')\n",
      "('의', '##미')\n",
      "('모', '##델')\n",
      "('2', '##.')\n",
      "('서', '##비스')\n",
      "('##그', '##램')\n",
      "('##u', '##d')\n",
      "('연구', '##에서는')\n",
      "('과', '##정')\n",
      "('##들', '##을')\n",
      "('의', '##해')\n",
      "('이', '##루')\n",
      "('기', '##준')\n",
      "('o', '##n')\n",
      "('그', '##림')\n",
      "('##으', '##나')\n",
      "('등', '##의')\n",
      "('T', '##able')\n",
      "('포', '##함')\n",
      "('##도', '##는')\n",
      "('##에서', '##의')\n",
      "('진', '##행')\n",
      "('하', '##였다.')\n",
      "('##시', '##키')\n",
      "('설', '##계')\n",
      "('a', '##n')\n",
      "('g', '##t')\n",
      "('3', '##.')\n",
      "('실', '##시')\n",
      "('아', '##니')\n",
      "('p', '##l')\n",
      "('기', '##존')\n",
      "('위', '##하여')\n",
      "('##)', '##를')\n",
      "('##at', '##e')\n",
      "('##i', '##on')\n",
      "('판', '##단')\n",
      "('연구', '##는')\n",
      "('##하', '##다.')\n",
      "('##)', '##을')\n",
      "('수', '##준')\n",
      "('학', '##생')\n",
      "training bpe 300 / 1000('##수', '##록')\n",
      "('##자', '##가')\n",
      "('결과', '##를')\n",
      "('##0', '##%')\n",
      "('##r', '##i')\n",
      "('대상', '##으로')\n",
      "('학', '##습')\n",
      "('전', '##체')\n",
      "('그', '##러')\n",
      "('##지', '##를')\n",
      "('또', '##는')\n",
      "('인', '##식')\n",
      "('이루', '##어')\n",
      "('##지', '##는')\n",
      "('모', '##두')\n",
      "('##도', '##의')\n",
      "('기', '##능')\n",
      "('관', '##리')\n",
      "('##력', '##을')\n",
      "('##이', '##라')\n",
      "('처', '##리')\n",
      "('의', '##한')\n",
      "('형', '##태')\n",
      "('비', '##해')\n",
      "('##수', '##를')\n",
      "('##도', '##에')\n",
      "('##ec', '##t')\n",
      "('많', '##은')\n",
      "('##하였', '##으며,')\n",
      "('나타', '##나')\n",
      "('같', '##다.')\n",
      "('T', '##he')\n",
      "('위', '##치')\n",
      "('##i', '##r')\n",
      "('##an', '##g')\n",
      "('기', '##반')\n",
      "('##o', '##c')\n",
      "('있', '##었다.')\n",
      "('##거', '##나')\n",
      "('보', '##고')\n",
      "('e', '##x')\n",
      "('##데', '##,')\n",
      "('r', '##es')\n",
      "('있', '##으며,')\n",
      "('##3', '##)')\n",
      "('##았', '##다.')\n",
      "('##음', '##을')\n",
      "('매', '##우')\n",
      "('영', '##역')\n",
      "('특', '##히')\n",
      "('2', '##0')\n",
      "('I', '##n')\n",
      "('##o', '##p')\n",
      "('##학', '##적')\n",
      "('a', '##c')\n",
      "('사', '##이')\n",
      "('기', '##업')\n",
      "('##성', '##과')\n",
      "('프로', '##그램')\n",
      "('내', '##용')\n",
      "('살', '##펴')\n",
      "('##5', '##.')\n",
      "('제', '##안')\n",
      "('##기', '##를')\n",
      "('##a', '##y')\n",
      "('##l', '##y')\n",
      "('##i', '##f')\n",
      "('a', '##mp')\n",
      "('##으로', '##써')\n",
      "('##면', '##,')\n",
      "('##째', '##,')\n",
      "('##o', '##g')\n",
      "('만', '##족')\n",
      "('연구', '##에서')\n",
      "('상', '##태')\n",
      "('##상', '##을')\n",
      "('##기', '##의')\n",
      "('##e', '##,')\n",
      "('##에', '##도')\n",
      "('al.', '##,')\n",
      "('i', '##s')\n",
      "('중', '##심')\n",
      "('건', '##강')\n",
      "('조', '##직')\n",
      "('결', '##정')\n",
      "('한', '##국')\n",
      "('##점', '##을')\n",
      "('된', '##다.')\n",
      "('b', '##y')\n",
      "('개', '##인')\n",
      "('국', '##내')\n",
      "('간', '##호')\n",
      "('##an', '##d')\n",
      "('##p', '##er')\n",
      "('계', '##산')\n",
      "('공', '##간')\n",
      "('아니', '##라')\n",
      "('있', '##다')\n",
      "training bpe 400 / 1000('논', '##문')\n",
      "('##레', '##이')\n",
      "('##개', '##의')\n",
      "('다음', '##과')\n",
      "('모', '##든')\n",
      "('그러', '##나')\n",
      "('해', '##당')\n",
      "('방', '##식')\n",
      "('차이', '##가')\n",
      "('실', '##제')\n",
      "('1', '##2')\n",
      "('##al', '##y')\n",
      "('##)', '##는')\n",
      "('참', '##여')\n",
      "('경', '##험')\n",
      "('##수', '##의')\n",
      "('1', '##5')\n",
      "('##사', '##의')\n",
      "('설', '##명')\n",
      "('##%', '##,')\n",
      "('해', '##석')\n",
      "('19', '##9')\n",
      "('추', '##출')\n",
      "('요', '##구')\n",
      "('##이', '##고')\n",
      "('관', '##한')\n",
      "('##)', '##에')\n",
      "('활', '##동')\n",
      "('##in', '##e')\n",
      "('생', '##산')\n",
      "('조', '##건')\n",
      "('##물', '##의')\n",
      "('##너', '##지')\n",
      "('등', '##을')\n",
      "('소', '##비')\n",
      "('##기', '##에')\n",
      "('통', '##계')\n",
      "('##수', '##가')\n",
      "('##부', '##분')\n",
      "('현', '##재')\n",
      "('c', '##h')\n",
      "('##an', '##t')\n",
      "('##e', '##p')\n",
      "('##하고', '##자')\n",
      "('4', '##.')\n",
      "('신', '##뢰')\n",
      "('##로', '##서')\n",
      "('##해', '##야')\n",
      "('w', '##as')\n",
      "('이', '##에')\n",
      "('##량', '##을')\n",
      "('연구', '##의')\n",
      "('파', '##악')\n",
      "('##레', '##스')\n",
      "('##량', '##이')\n",
      "('##면', '##서')\n",
      "('반', '##응')\n",
      "('##or', '##e')\n",
      "('보', '##여')\n",
      "('##도', '##와')\n",
      "('##i', '##z')\n",
      "('t', '##im')\n",
      "('안', '##전')\n",
      "('부', '##분')\n",
      "('동', '##일')\n",
      "('요', '##소')\n",
      "('표', '##준')\n",
      "('##)', '##은')\n",
      "('a', '##s')\n",
      "('이용', '##한')\n",
      "('##스', '##트')\n",
      "('유', '##지')\n",
      "('##도', '##로')\n",
      "('분', '##류')\n",
      "('지', '##속')\n",
      "('##as', '##e')\n",
      "('##력', '##이')\n",
      "('설', '##정')\n",
      "('##u', '##p')\n",
      "('시', '##험')\n",
      "('생', '##각')\n",
      "('모', '##형')\n",
      "('하', '##나')\n",
      "('존', '##재')\n",
      "('개', '##념')\n",
      "('##m', '##n')\n",
      "('##an', '##ce')\n",
      "('pl', '##us')\n",
      "('상', '##황')\n",
      "('개', '##선')\n",
      "('검', '##증')\n",
      "('##s', '##.')\n",
      "('##0', '##5')\n",
      "('성', '##능')\n",
      "('상', '##대')\n",
      "('plus', '##mn')\n",
      "('효', '##율')\n",
      "('있', '##을')\n",
      "('상', '##관')\n",
      "('표', '##현')\n",
      "training bpe 500 / 1000('l', '##dquo')\n",
      "('지', '##원')\n",
      "('보', '##다')\n",
      "('자', '##신')\n",
      "('##i', '##p')\n",
      "('우', '##리')\n",
      "('이', '##후')\n",
      "('##h', '##a')\n",
      "('유', '##사')\n",
      "('전', '##문')\n",
      "('r', '##dquo')\n",
      "('최', '##대')\n",
      "('##성', '##에')\n",
      "('선', '##택')\n",
      "('운', '##영')\n",
      "('u', '##s')\n",
      "('##ig', '##n')\n",
      "('3', '##0')\n",
      "('##ig', '##h')\n",
      "('낮', '##은')\n",
      "('##e', '##ar')\n",
      "('자', '##기')\n",
      "('예', '##측')\n",
      "('역', '##할')\n",
      "('##)', '##이')\n",
      "('구', '##분')\n",
      "('##로', '##운')\n",
      "('중요', '##한')\n",
      "('것', '##은')\n",
      "('b', '##et')\n",
      "('정', '##의')\n",
      "('##도', '##,')\n",
      "('않', '##는')\n",
      "('##간', '##의')\n",
      "('위해', '##서는')\n",
      "('##ic', '##al')\n",
      "('##하였', '##고,')\n",
      "('##성', '##,')\n",
      "('##s', '##,')\n",
      "('##하', '##며,')\n",
      "('향', '##상')\n",
      "('나타', '##낸')\n",
      "('연구', '##가')\n",
      "('##a', '##in')\n",
      "('추', '##정')\n",
      "('많', '##이')\n",
      "('하', '##여')\n",
      "('##er', '##e')\n",
      "('단', '##계')\n",
      "('설', '##치')\n",
      "('##자', '##는')\n",
      "('주', '##요')\n",
      "('이', '##해')\n",
      "('##워', '##크')\n",
      "('st', '##ud')\n",
      "('분', '##포')\n",
      "('생', '##성')\n",
      "('##ag', '##e')\n",
      "('##6', '##.')\n",
      "('산', '##업')\n",
      "('##s', '##is')\n",
      "('경', '##제')\n",
      "('제', '##작')\n",
      "('제', '##품')\n",
      "('##체', '##의')\n",
      "('함', '##께')\n",
      "('##학', '##교')\n",
      "('S', '##t')\n",
      "('크', '##게')\n",
      "('여', '##러')\n",
      "('방', '##향')\n",
      "('##u', '##b')\n",
      "('##수', '##는')\n",
      "('1', '##1')\n",
      "('응', '##답')\n",
      "('##지만', '##,')\n",
      "('직', '##접')\n",
      "('##)', '##와')\n",
      "('형', '##성')\n",
      "('상', '##호')\n",
      "('##ro', '##m')\n",
      "('이', '##미')\n",
      "('집', '##단')\n",
      "('사', '##업')\n",
      "('사회', '##적')\n",
      "('##로', '##부터')\n",
      "('정', '##확')\n",
      "('사', '##람')\n",
      "('치', '##료')\n",
      "('제', '##어')\n",
      "('선', '##정')\n",
      "('w', '##ere')\n",
      "('지', '##식')\n",
      "('결과', '##는')\n",
      "('##y', '##st')\n",
      "('##el', '##l')\n",
      "('##en', '##s')\n",
      "('a', '##t')\n",
      "('##하', '##며')\n",
      "('##리', '##적')\n",
      "training bpe 600 / 1000('선', '##행')\n",
      "('대', '##부분')\n",
      "('있', '##었')\n",
      "('b', '##e')\n",
      "('s', '##p')\n",
      "('##3', '##9')\n",
      "('비', '##율')\n",
      "('##ig', '##ure')\n",
      "('측', '##면')\n",
      "('1', '##8')\n",
      "('##에서', '##도')\n",
      "('##대', '##로')\n",
      "('201', '##4')\n",
      "('설', '##문')\n",
      "('##과', '##의')\n",
      "('a', '##re')\n",
      "('분', '##야')\n",
      "('##for', '##m')\n",
      "('##원', '##의')\n",
      "('##5', '##%')\n",
      "('##자', '##를')\n",
      "('않', '##은')\n",
      "('##되', '##지')\n",
      "('##기', '##가')\n",
      "('신', '##호')\n",
      "('위', '##험')\n",
      "('##트', '##워크')\n",
      "('살펴', '##보')\n",
      "('발', '##전')\n",
      "('동', '##안')\n",
      "('새', '##로운')\n",
      "('연', '##결')\n",
      "('이', '##동')\n",
      "('##이', '##며,')\n",
      "('유', '##형')\n",
      "('인', '##해')\n",
      "('통', '##하여')\n",
      "('하', '##였')\n",
      "('있', '##도록')\n",
      "('첨', '##가')\n",
      "('에', '##서')\n",
      "('통', '##한')\n",
      "('##치', '##를')\n",
      "('##성', '##의')\n",
      "('어', '##려')\n",
      "('없', '##는')\n",
      "('##성', '##은')\n",
      "('##res', '##s')\n",
      "('##별', '##로')\n",
      "('##고', '##리')\n",
      "('##기', '##는')\n",
      "('사용', '##하여')\n",
      "('##7', '##.')\n",
      "('##yst', '##em')\n",
      "('제', '##조')\n",
      "('an', '##aly')\n",
      "('경', '##향')\n",
      "('정보', '##를')\n",
      "('범', '##위')\n",
      "('최', '##근')\n",
      "('국', '##가')\n",
      "('가', '##정')\n",
      "('##i', '##al')\n",
      "('특', '##징')\n",
      "('가지', '##고')\n",
      "('관', '##찰')\n",
      "('등', '##이')\n",
      "('내', '##부')\n",
      "('##)', '##과')\n",
      "('5', '##.')\n",
      "('스', '##트')\n",
      "('추', '##가')\n",
      "('대', '##하여')\n",
      "('##on', '##g')\n",
      "('영', '##상')\n",
      "('간', '##의')\n",
      "('목', '##적')\n",
      "('에', '##너지')\n",
      "('값', '##을')\n",
      "('행', '##동')\n",
      "('##함', '##으로써')\n",
      "('표', '##면')\n",
      "('##량', '##은')\n",
      "('긍', '##정')\n",
      "('인', '##지')\n",
      "('##(', '##C')\n",
      "('##기', '##관')\n",
      "('필요', '##한')\n",
      "('##es', '##s')\n",
      "('기', '##본')\n",
      "('##a', '##k')\n",
      "('도', '##출')\n",
      "('안', '##정')\n",
      "('기', '##법')\n",
      "('p', '##er')\n",
      "('직', '##무')\n",
      "('##이', '##스')\n",
      "('tim', '##es')\n",
      "('적', '##합')\n",
      "('되', '##는')\n",
      "training bpe 700 / 1000('##하는', '##데')\n",
      "('##ar', '##d')\n",
      "('##화', '##를')\n",
      "('의', '##료')\n",
      "('##al', '##u')\n",
      "('작', '##업')\n",
      "('##)', '##로')\n",
      "('##h', '##o')\n",
      "('##마', '##트')\n",
      "('높', '##게')\n",
      "('항', '##목')\n",
      "('관련', '##된')\n",
      "('시', '##작')\n",
      "('##하면', '##서')\n",
      "('##나', '##라')\n",
      "('##라', '##고')\n",
      "('최', '##소')\n",
      "('결과', '##,')\n",
      "('##-', '##1')\n",
      "('m', '##m')\n",
      "('c', '##omp')\n",
      "('1', '##,')\n",
      "('##지', '##의')\n",
      "('##r', '##ac')\n",
      "('환', '##자')\n",
      "('네', '##트워크')\n",
      "('접', '##근')\n",
      "('운', '##동')\n",
      "('##량', '##의')\n",
      "('##인', '##의')\n",
      "('s', '##im')\n",
      "('업', '##무')\n",
      "('시', '##행')\n",
      "('구', '##축')\n",
      "('수', '##업')\n",
      "('##(', '##200')\n",
      "('##하', '##도록')\n",
      "('##ar', '##i')\n",
      "('문', '##항')\n",
      "('r', '##e')\n",
      "('있', '##으며')\n",
      "('##y', '##p')\n",
      "('있', '##음을')\n",
      "('d', '##eg')\n",
      "('##%', '##로')\n",
      "('사', '##례')\n",
      "('하', '##고')\n",
      "('##c', '##t')\n",
      "('con', '##t')\n",
      "('기', '##록')\n",
      "('경우', '##,')\n",
      "('##시', '##설')\n",
      "('인', '##터')\n",
      "('##으나', '##,')\n",
      "('##od', '##el')\n",
      "('##시', '##에')\n",
      "('##작', '##용')\n",
      "('확', '##보')\n",
      "('##5', '##0')\n",
      "('시', '##료')\n",
      "('확인', '##할')\n",
      "('##점', '##이')\n",
      "('1', '##4')\n",
      "('##변', '##수')\n",
      "('해', '##결')\n",
      "('1', '##6')\n",
      "('학', '##교')\n",
      "('##(', '##S')\n",
      "('##고리', '##즘')\n",
      "('##g', '##/')\n",
      "('##e', '##vel')\n",
      "('##c', '##al')\n",
      "('바', '##탕')\n",
      "('기', '##초')\n",
      "('나타내', '##었다.')\n",
      "('변', '##수')\n",
      "('사용', '##하였다.')\n",
      "('##u', '##g')\n",
      "('스', '##마트')\n",
      "('연구', '##를')\n",
      "('1', '##3')\n",
      "('##시', '##켜')\n",
      "('##했', '##다.')\n",
      "('주', '##로')\n",
      "('즉', '##,')\n",
      "('##r', '##an')\n",
      "('반', '##영')\n",
      "('stud', '##y')\n",
      "('도', '##시')\n",
      "('결', '##론')\n",
      "('th', '##at')\n",
      "('##시키', '##는')\n",
      "('##d', '##uc')\n",
      "('의', '##사')\n",
      "('사', '##고')\n",
      "('수', '##집')\n",
      "('##e', '##e')\n",
      "('최', '##적')\n",
      "('보', '##인')\n",
      "('##생', '##활')\n",
      "training bpe 800 / 1000('##명', '##(')\n",
      "('정', '##책')\n",
      "('저', '##장')\n",
      "('##u', '##al')\n",
      "('##if', '##ic')\n",
      "('알', '##고리즘')\n",
      "('C', '##on')\n",
      "('만', '##들')\n",
      "('품', '##질')\n",
      "('문', '##화')\n",
      "('이', '##론')\n",
      "('이', '##와')\n",
      "('제', '##외')\n",
      "('과', '##학')\n",
      "('##d', '##ing')\n",
      "('분석', '##을')\n",
      "('판단', '##된다.')\n",
      "('제', '##거')\n",
      "('기존', '##의')\n",
      "('##P', '##S')\n",
      "('##00', '##0')\n",
      "('보', '##였다.')\n",
      "('##산', '##화')\n",
      "('작', '##용')\n",
      "('검', '##사')\n",
      "('바탕', '##으로')\n",
      "('인', '##한')\n",
      "('##)', '##으로')\n",
      "('스트', '##레스')\n",
      "('방법', '##을')\n",
      "('관', '##심')\n",
      "('나타', '##난')\n",
      "('되', '##어')\n",
      "('6', '##.')\n",
      "('5', '##0')\n",
      "('##2', '##,')\n",
      "('##자', '##인')\n",
      "('##부', '##의')\n",
      "('하', '##지만')\n",
      "('활', '##성')\n",
      "('f', '##rom')\n",
      "('어', '##휘')\n",
      "('공', '##급')\n",
      "('##as', '##s')\n",
      "('##at', '##a')\n",
      "('우리', '##나라')\n",
      "('고', '##객')\n",
      "('#', '##39')\n",
      "('자', '##연')\n",
      "('##y', '##l')\n",
      "('d', '##iff')\n",
      "('##화', '##된')\n",
      "('성', '##장')\n",
      "('목', '##표')\n",
      "('##라', '##는')\n",
      "('시', '##장')\n",
      "('본', '##문')\n",
      "('변화', '##를')\n",
      "('##8', '##.')\n",
      "('분석', '##하였다.')\n",
      "('##기', '##간')\n",
      "('이상', '##의')\n",
      "('##레이', '##션')\n",
      "('가', '##진')\n",
      "('전', '##략')\n",
      "('있어', '##서')\n",
      "('가능', '##한')\n",
      "('혼', '##합')\n",
      "('##지', '##고')\n",
      "('일', '##정')\n",
      "('##으로', '##서')\n",
      "('연', '##령')\n",
      "('##eth', '##od')\n",
      "('##o', '##us')\n",
      "('##e', '##w')\n",
      "('갖', '##는')\n",
      "('전', '##기')\n",
      "('c', '##o')\n",
      "('한', '##계')\n",
      "('초', '##기')\n",
      "('##ff', '##ect')\n",
      "('효과', '##를')\n",
      "('발생', '##하는')\n",
      "('통', '##합')\n",
      "('필요', '##하다.')\n",
      "('현', '##장')\n",
      "('특', '##정')\n",
      "('조', '##절')\n",
      "('##ar', '##k')\n",
      "('자', '##동')\n",
      "('대', '##표')\n",
      "('##물', '##을')\n",
      "('o', '##r')\n",
      "('높', '##아')\n",
      "('또한', '##,')\n",
      "('공', '##정')\n",
      "('##어', '##진')\n",
      "('res', '##ult')\n",
      "('##er', '##s')\n",
      "('전', '##송')\n",
      "training bpe 900 / 1000('들', '##어')\n",
      "('산', '##출')\n",
      "('미', '##국')\n",
      "('초', '##록')\n",
      "('등', '##에')\n",
      "('##%', '##),')\n",
      "('제', '##한')\n",
      "('도', '##입')\n",
      "('##도', '##(')\n",
      "('상대', '##적으로')\n",
      "('##or', '##t')\n",
      "('##r', '##a')\n",
      "('##상', '##의')\n",
      "('##이', '##며')\n",
      "('##)', '##가')\n",
      "('적', '##절')\n",
      "('m', '##u')\n",
      "('##p', '##ha')\n",
      "('##임', '##을')\n",
      "('##되어', '##야')\n",
      "('##en', '##ce')\n",
      "('상관', '##관계')\n",
      "('th', '##is')\n",
      "('##라', '##인')\n",
      "('이', '##하')\n",
      "('계', '##획')\n",
      "('##리', '##를')\n",
      "('##하', '##거나')\n",
      "('신', '##체')\n",
      "('경우', '##에는')\n",
      "('단', '##위')\n",
      "('##는', '##데,')\n",
      "('##한', '##다')\n",
      "('##으', '##므로')\n",
      "('교', '##사')\n",
      "('##핵', '##심')\n",
      "('중심', '##으로')\n",
      "('입', '##력')\n",
      "('##주', '##의')\n",
      "('m', '##e')\n",
      "('##함', '##을')\n",
      "('##(', '##P')\n",
      "('대', '##조')\n",
      "('가', '##족')\n",
      "('##크', '##리')\n",
      "('##il', '##ity')\n",
      "('최', '##종')\n",
      "('##i', '##a')\n",
      "('##지', '##에')\n",
      "('기준', '##으로')\n",
      "('보', '##였')\n",
      "('al', '##pha')\n",
      "('알', '##려')\n",
      "('구', '##체')\n",
      "('필요', '##가')\n",
      "('이', '##유')\n",
      "('t', '##est')\n",
      "('센', '##서')\n",
      "('##기', '##서')\n",
      "('##(', '##p')\n",
      "('##i', '##b')\n",
      "('##을', '##수록')\n",
      "('검', '##토')\n",
      "('동일', '##한')\n",
      "('##ro', '##l')\n",
      "('e', '##n')\n",
      "('##igh', '##t')\n",
      "('관계', '##를')\n",
      "('g', '##ro')\n",
      "('##물', '##질')\n",
      "('방', '##안')\n",
      "('##9', '##.')\n",
      "('주', '##파')\n",
      "('##i', '##es')\n",
      "('역할', '##을')\n",
      "('##하였', '##으며')\n",
      "('0.', '##05')\n",
      "('##이', '##션')\n",
      "('##이', '##었')\n",
      "('번', '##째')\n",
      "('일', '##부')\n",
      "('시', '##뮬')\n",
      "('K', '##ore')\n",
      "('사용', '##자')\n",
      "('부', '##족')\n",
      "('분', '##리')\n",
      "('##니', '##다.')\n",
      "('##로', '##는')\n",
      "('##하였', '##다(')\n",
      "('##어', '##나')\n",
      "('##이', '##기')\n",
      "('##4', '##)')\n",
      "('구', '##현')\n",
      "('##점', '##에서')\n",
      "('##으로', '##는')\n",
      "('##S', '##A')\n",
      "('비', '##용')\n",
      "('bet', '##a')\n",
      "('데이터', '##를')\n",
      "('2', '##5')\n",
      "training bpe 1000 / 1000('##r', '##uc')\n",
      "training bpe was done                                        \n"
     ]
    }
   ],
   "source": [
    "!python wordpiece.py \\\n",
    "--corpus=raw.txt \\\n",
    "--iter=1000 \\\n",
    "--fname=my_vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open('my_vocab.txt', 'r')\n",
    "kor_vocab = f2.read()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('bert_vocab.txt', 'r')\n",
    "bert_vocab = f1.read()\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##의\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_vocab[31:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vocab = bert_vocab + kor_vocab[31:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135548"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = final_vocab.split('\\n')\n",
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131747"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 없애기\n",
    "new_vocab = []\n",
    "for x in vocab_list:\n",
    "    if x not in new_vocab:\n",
    "        new_vocab.append(x)\n",
    "len(new_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vocab.pop(new_vocab.index(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131746"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "\n",
    "for v in new_vocab:\n",
    "    text +=  v+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 bert vocab.txt 크기: 764415\n",
      "새로 학습시킨 vocab.txt 크기: 91953\n",
      "중복 없애기 전 vocab.txt 크기: 856337\n",
      "중복 없애기 후 vocab.txt 크기: 841571\n"
     ]
    }
   ],
   "source": [
    "print('기존 bert vocab.txt 크기:', len(bert_vocab))\n",
    "print('새로 학습시킨 vocab.txt 크기:', len(kor_vocab))\n",
    "print('중복 없애기 전 vocab.txt 크기:', len(final_vocab))\n",
    "print('중복 없애기 후 vocab.txt 크기:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = open('final_vocab.txt', 'w')\n",
    "f3.write(text)\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From create_pretraining_data.py:455: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From create_pretraining_data.py:422: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W1120 15:51:54.582713 47619347533312 module_wrapper.py:139] From create_pretraining_data.py:422: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From create_pretraining_data.py:422: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W1120 15:51:54.583001 47619347533312 module_wrapper.py:139] From create_pretraining_data.py:422: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From create_pretraining_data.py:429: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W1120 15:51:54.803255 47619347533312 module_wrapper.py:139] From create_pretraining_data.py:429: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:From create_pretraining_data.py:431: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1120 15:51:54.807857 47619347533312 module_wrapper.py:139] From create_pretraining_data.py:431: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:*** Reading from input files ***\n",
      "I1120 15:51:54.808015 47619347533312 create_pretraining_data.py:431] *** Reading from input files ***\n",
      "INFO:tensorflow:  ./training_data/Finalresult_30000.txt\n",
      "I1120 15:51:54.808149 47619347533312 create_pretraining_data.py:433]   ./training_data/Finalresult_30000.txt\n",
      "before instance\n",
      "INFO:tensorflow:begin read input file\n",
      "I1120 15:51:54.808866 47619347533312 create_pretraining_data.py:192] begin read input file\n",
      "INFO:tensorflow:50000 line pass\n",
      "I1120 15:52:06.115970 47619347533312 create_pretraining_data.py:199] 50000 line pass\n",
      "INFO:tensorflow:100000 line pass\n",
      "I1120 15:52:17.119982 47619347533312 create_pretraining_data.py:199] 100000 line pass\n",
      "INFO:tensorflow:150000 line pass\n",
      "I1120 15:52:28.370006 47619347533312 create_pretraining_data.py:199] 150000 line pass\n",
      "INFO:tensorflow:200000 line pass\n",
      "I1120 15:52:39.816104 47619347533312 create_pretraining_data.py:199] 200000 line pass\n",
      "INFO:tensorflow:250000 line pass\n",
      "I1120 15:52:50.494639 47619347533312 create_pretraining_data.py:199] 250000 line pass\n",
      "INFO:tensorflow:300000 line pass\n",
      "I1120 15:53:01.844156 47619347533312 create_pretraining_data.py:199] 300000 line pass\n",
      "INFO:tensorflow:350000 line pass\n",
      "I1120 15:53:12.554815 47619347533312 create_pretraining_data.py:199] 350000 line pass\n",
      "INFO:tensorflow:400000 line pass\n",
      "I1120 15:53:23.511205 47619347533312 create_pretraining_data.py:199] 400000 line pass\n",
      "INFO:tensorflow:450000 line pass\n",
      "I1120 15:53:34.904945 47619347533312 create_pretraining_data.py:199] 450000 line pass\n",
      "INFO:tensorflow:500000 line pass\n",
      "I1120 15:53:45.520095 47619347533312 create_pretraining_data.py:199] 500000 line pass\n",
      "INFO:tensorflow:550000 line pass\n",
      "I1120 15:53:56.834016 47619347533312 create_pretraining_data.py:199] 550000 line pass\n",
      "INFO:tensorflow:600000 line pass\n",
      "I1120 15:54:07.344741 47619347533312 create_pretraining_data.py:199] 600000 line pass\n",
      "INFO:tensorflow:650000 line pass\n",
      "I1120 15:54:18.121894 47619347533312 create_pretraining_data.py:199] 650000 line pass\n",
      "INFO:tensorflow:700000 line pass\n",
      "I1120 15:54:28.715697 47619347533312 create_pretraining_data.py:199] 700000 line pass\n",
      "INFO:tensorflow:750000 line pass\n",
      "I1120 15:54:40.419934 47619347533312 create_pretraining_data.py:199] 750000 line pass\n",
      "INFO:tensorflow:finish read input file\n",
      "I1120 15:54:46.577738 47619347533312 create_pretraining_data.py:214] finish read input file\n",
      "INFO:tensorflow:shuffle all documents\n",
      "I1120 15:54:46.580964 47619347533312 create_pretraining_data.py:216] shuffle all documents\n",
      "INFO:tensorflow:make vocab dict\n",
      "I1120 15:54:46.588580 47619347533312 create_pretraining_data.py:218] make vocab dict\n",
      "INFO:tensorflow:make tokens\n",
      "I1120 15:54:46.600706 47619347533312 create_pretraining_data.py:221] make tokens\n",
      "INFO:tensorflow:*** Writing to output files ***\n",
      "I1120 16:06:43.829305 47619347533312 create_pretraining_data.py:443] *** Writing to output files ***\n",
      "INFO:tensorflow:  ./preprocessed_training_data/Finalresult_30000_tf.record\n",
      "I1120 16:06:43.829656 47619347533312 create_pretraining_data.py:445]   ./preprocessed_training_data/Finalresult_30000_tf.record\n",
      "WARNING:tensorflow:From create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W1120 16:06:43.829983 47619347533312 module_wrapper.py:139] From create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.840984 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 그림 12 ##와 13 ##izuje 건 ##설 ##된 H ##V ##DC 현 ##황 [MASK] 건 ##설 ##예 ##정 ##인 H ##V ##DC 현 ##황 ##을 [MASK] ##준 ##다. [SEP] Vo [MASK] ( ##V ##oi ##ce over IP ##) 서비스 ##, 스트 ##리 ##밍 [MASK] 등 다양한 종 ##류의 서비스 ##가 공 ##존 ##하고 있다. 각 서비스 ##는 시간 ##지 ##연 ##, 손 ##실 ##률 ##, 지 ##터 [MASK] ##J ##itter ##) [MASK] 서로 다른 Q ##o ##S ( ##Q ##uali ##ty of Service ##) 수준 ##을 요구 ##하지만 ##, IP 네트워크 ##는 Best effort 서비스 ##를 지 ##향 ##하는 IP 패 ##킷 단위 ##의 라 ##우 ##팅 및 상태 비 ##보 ##존 ##형 ( ##St ##ateles ##s ##) 라 ##우 ##팅 방식 ##을 사용 ##하기 때문에 Q ##o ##S ##를 제공 ##하기 위한 연결 수 ##락 제어 ( ##C ##all Ad ##mission Control ##), 스 ##케 ##줄 ##링 ##, 네트워크 가 ##상 ##화 서비스 등의 지원 ##에 어려 ##움 ##이 있다. 특히 ##, [MASK] ##선 단 ##말 ##의 급 ##증 ##으로 인 ##하여 이동 무 ##선 venduto ##래 ##픽 ##이 급 ##증 ##하고 있는 상 황 ##을 고려 ##할 때 이동 무 ##선 네트워크 ##에서 이용 ##자 서비스 별 ##로 요구 ##하는 Q ##o ##S 수준 ##을 파악 ##하여 이를 만족 ##시키는 더욱 정 ##교 ##하고 효율 ##적인 트 ##래 ##픽 관리 방법 ##이 요구 ##된다. 이러한 요구 ##에 부 ##합 ##하여 최근 유 ##무 ##선 액 ##세 ##스 네트워크 ##에서 코 ##어 네트워크 [MASK] 광 ##범위 ##하게 플 ##로 ##우 단위 ##의 트 ##래 ##픽 관리 기술 ##이 각 ##광 ##을 받고 있다 1 ##- ##9 . 플 ##로 ##우 트 ##래 ##픽 관리 기술 ##은 라 ##우 ##터 ##에서 플 ##로 ##우 ##의 상태 정보를 유지 ##하는 보 ##존 ##형 ( ##St ##ate ##ful ##) 라 ##우 ##팅 방식 ##을 사용 ##함으로써 ##, 각 플 ##로 ##우 ##에 포함 ##된 모든 패 ##킷 ##들이 플 ##로 ##우 ##의 Q ##o ##rages 요구 ##사 ##항 ##에 따라 동일 ##하게 [MASK] ##될 수 있도록 하는 방법 ##이다. 플 ##로 ##우 트 ##래 ##픽 관리 기술 ##은 상태 보 ##전 ##형 라 ##우 ##팅 방식 ##을 통해 전송 ##단 ##에서 플 ##로 ##우 단위 ##의 세 ##분 ##화된 연결 수 ##락 제어 ##, 스 ##케 ##줄 ##링 ##, 망 ##자 ##원 관리 등을 가능 ##하게 한다. 그러나 이동 무 ##선 네트워크 ##의 액 ##세 ##스 단 ##에서는 단 ##말 ##의 이동 ##으로 인 ##하여 데이터 플 ##로 ##우 ##의 전 ##달 ##경 ##로 ##가 자 ##주 변경 될 [MASK] 있 ##기 때문에 개 ##별 ##적인 플 ##로 ##우 단위 ##로 핸 ##드 ##오 ##버 ##를 지원 ##하는 방안 ##이 필 ##수 ##적 ##이다. 지 ##금 ##까지 MI ##P ( ##M [MASK] ##e IP ##) 10 , Hier ##arch ##ical Mobile IP ( ##H ##MI ##P ##) 11 , Pro ##xy Mobile IP [MASK] ##PM ##IP ##) 12 등의 IP 기반 ##의 이동 ##성 지원 방식 ##을 포함 ##하여 많은 핸 ##드 ##오 ##버 방안 ##이 제안 ##되었 ##지만 대부분의 방식 ##들은 [MASK] ##전 ##히 단 ##말 이동 ##성 ( ##T ##erm [SEP]\n",
      "I1120 16:06:43.841302 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 그림 12 ##와 13 ##izuje 건 ##설 ##된 H ##V ##DC 현 ##황 [MASK] 건 ##설 ##예 ##정 ##인 H ##V ##DC 현 ##황 ##을 [MASK] ##준 ##다. [SEP] Vo [MASK] ( ##V ##oi ##ce over IP ##) 서비스 ##, 스트 ##리 ##밍 [MASK] 등 다양한 종 ##류의 서비스 ##가 공 ##존 ##하고 있다. 각 서비스 ##는 시간 ##지 ##연 ##, 손 ##실 ##률 ##, 지 ##터 [MASK] ##J ##itter ##) [MASK] 서로 다른 Q ##o ##S ( ##Q ##uali ##ty of Service ##) 수준 ##을 요구 ##하지만 ##, IP 네트워크 ##는 Best effort 서비스 ##를 지 ##향 ##하는 IP 패 ##킷 단위 ##의 라 ##우 ##팅 및 상태 비 ##보 ##존 ##형 ( ##St ##ateles ##s ##) 라 ##우 ##팅 방식 ##을 사용 ##하기 때문에 Q ##o ##S ##를 제공 ##하기 위한 연결 수 ##락 제어 ( ##C ##all Ad ##mission Control ##), 스 ##케 ##줄 ##링 ##, 네트워크 가 ##상 ##화 서비스 등의 지원 ##에 어려 ##움 ##이 있다. 특히 ##, [MASK] ##선 단 ##말 ##의 급 ##증 ##으로 인 ##하여 이동 무 ##선 venduto ##래 ##픽 ##이 급 ##증 ##하고 있는 상 황 ##을 고려 ##할 때 이동 무 ##선 네트워크 ##에서 이용 ##자 서비스 별 ##로 요구 ##하는 Q ##o ##S 수준 ##을 파악 ##하여 이를 만족 ##시키는 더욱 정 ##교 ##하고 효율 ##적인 트 ##래 ##픽 관리 방법 ##이 요구 ##된다. 이러한 요구 ##에 부 ##합 ##하여 최근 유 ##무 ##선 액 ##세 ##스 네트워크 ##에서 코 ##어 네트워크 [MASK] 광 ##범위 ##하게 플 ##로 ##우 단위 ##의 트 ##래 ##픽 관리 기술 ##이 각 ##광 ##을 받고 있다 1 ##- ##9 . 플 ##로 ##우 트 ##래 ##픽 관리 기술 ##은 라 ##우 ##터 ##에서 플 ##로 ##우 ##의 상태 정보를 유지 ##하는 보 ##존 ##형 ( ##St ##ate ##ful ##) 라 ##우 ##팅 방식 ##을 사용 ##함으로써 ##, 각 플 ##로 ##우 ##에 포함 ##된 모든 패 ##킷 ##들이 플 ##로 ##우 ##의 Q ##o ##rages 요구 ##사 ##항 ##에 따라 동일 ##하게 [MASK] ##될 수 있도록 하는 방법 ##이다. 플 ##로 ##우 트 ##래 ##픽 관리 기술 ##은 상태 보 ##전 ##형 라 ##우 ##팅 방식 ##을 통해 전송 ##단 ##에서 플 ##로 ##우 단위 ##의 세 ##분 ##화된 연결 수 ##락 제어 ##, 스 ##케 ##줄 ##링 ##, 망 ##자 ##원 관리 등을 가능 ##하게 한다. 그러나 이동 무 ##선 네트워크 ##의 액 ##세 ##스 단 ##에서는 단 ##말 ##의 이동 ##으로 인 ##하여 데이터 플 ##로 ##우 ##의 전 ##달 ##경 ##로 ##가 자 ##주 변경 될 [MASK] 있 ##기 때문에 개 ##별 ##적인 플 ##로 ##우 단위 ##로 핸 ##드 ##오 ##버 ##를 지원 ##하는 방안 ##이 필 ##수 ##적 ##이다. 지 ##금 ##까지 MI ##P ( ##M [MASK] ##e IP ##) 10 , Hier ##arch ##ical Mobile IP ( ##H ##MI ##P ##) 11 , Pro ##xy Mobile IP [MASK] ##PM ##IP ##) 12 등의 IP 기반 ##의 이동 ##성 지원 방식 ##을 포함 ##하여 많은 핸 ##드 ##오 ##버 방안 ##이 제안 ##되었 ##지만 대부분의 방식 ##들은 [MASK] ##전 ##히 단 ##말 이동 ##성 ( ##T ##erm [SEP]\n",
      "INFO:tensorflow:input_ids: 101 119621 10186 12638 10249 107356 8865 31928 13441 145 11779 95449 9978 65649 103 8865 31928 96279 16605 12030 145 11779 95449 9978 65649 10622 103 54867 119549 102 59482 103 113 11779 14638 10419 10491 24124 110859 119617 110862 120322 12692 118960 103 9121 53645 9684 89267 119617 11287 8896 79718 12453 119547 8844 119617 11018 119612 12508 25486 110862 9450 31503 88350 110862 9706 21876 103 15417 62549 110859 103 67324 19709 154 10133 10731 113 19282 47543 11195 10108 13489 110859 119636 10622 119703 120140 110862 24124 119894 11018 11730 24912 119617 11513 9706 79544 12178 24124 9909 119333 120057 10459 9157 27355 100329 9316 119675 9379 30005 79718 27506 113 120336 123521 10107 110859 9157 27355 100329 119693 10622 119550 22440 20729 154 10133 10731 11513 119611 22440 28195 119830 9460 107693 119808 113 10858 18995 25474 27551 20083 119557 9477 88332 119219 80174 110862 119894 8843 14871 18227 119617 28697 119752 10530 119838 119169 10739 119547 39671 110862 103 18471 9059 89523 10459 8929 119230 11467 9640 13374 119831 9294 18471 108017 37388 119414 10739 8929 119230 12453 13767 9414 9997 10622 119608 14843 9137 119831 9294 18471 119894 11489 119580 13764 119617 9353 11261 119703 12178 154 10133 10731 119636 10622 119720 13374 35756 119673 119950 99958 9670 25242 12453 119747 15387 9890 37388 119414 119649 119567 10739 119703 119574 34079 119703 10530 9365 33188 13374 119852 9625 32537 18471 9533 24982 12605 119894 11489 9812 12965 119894 103 8903 120178 17594 9944 11261 27355 120057 10459 9890 37388 119414 119649 119578 10739 8844 118649 10622 79602 11506 122 110863 11373 119 9944 11261 27355 9890 37388 119414 119649 119578 10892 9157 27355 21876 11489 9944 11261 27355 10459 119675 119850 119729 12178 9356 79718 27506 113 120336 12436 14446 110859 9157 27355 100329 119693 10622 119550 119866 110862 8844 9944 11261 27355 10530 119623 13441 25701 9909 119333 20173 9944 11261 27355 10459 154 10133 126098 119703 12945 50632 10530 22799 120112 17594 103 59330 9460 107931 23969 119567 119555 9944 11261 27355 9890 37388 119414 119649 119578 10892 119675 9356 16617 27506 9157 27355 100329 119693 10622 25605 120038 24989 11489 9944 11261 27355 120057 10459 9435 37712 120004 119830 9460 107693 119808 110862 9477 88332 119219 80174 110862 9255 13764 14279 119649 33727 119609 17594 119575 21890 119831 9294 18471 119894 10459 9533 24982 12605 9059 23635 9059 89523 10459 119831 11467 9640 13374 119633 9944 11261 27355 10459 9665 89851 31720 11261 11287 9651 16323 60839 9100 103 9647 12310 20729 8857 61844 15387 9944 11261 27355 120057 11261 9962 15001 28188 41605 11513 119752 12178 120086 10739 9949 15891 14801 119555 9706 40032 18382 75416 11127 113 11517 103 10112 24124 110859 10150 117 19994 96355 17616 23506 24124 113 12396 79443 11127 110859 10193 117 14021 46776 23506 24124 103 96325 30331 110859 10186 28697 24124 119658 10459 119831 17138 119752 119693 10622 119623 13374 25685 9962 15001 28188 41605 120086 10739 119670 119587 28578 85146 119693 22879 103 16617 18108 9059 89523 119831 17138 113 11090 91724 102\n",
      "I1120 16:06:43.841699 47619347533312 create_pretraining_data.py:161] input_ids: 101 119621 10186 12638 10249 107356 8865 31928 13441 145 11779 95449 9978 65649 103 8865 31928 96279 16605 12030 145 11779 95449 9978 65649 10622 103 54867 119549 102 59482 103 113 11779 14638 10419 10491 24124 110859 119617 110862 120322 12692 118960 103 9121 53645 9684 89267 119617 11287 8896 79718 12453 119547 8844 119617 11018 119612 12508 25486 110862 9450 31503 88350 110862 9706 21876 103 15417 62549 110859 103 67324 19709 154 10133 10731 113 19282 47543 11195 10108 13489 110859 119636 10622 119703 120140 110862 24124 119894 11018 11730 24912 119617 11513 9706 79544 12178 24124 9909 119333 120057 10459 9157 27355 100329 9316 119675 9379 30005 79718 27506 113 120336 123521 10107 110859 9157 27355 100329 119693 10622 119550 22440 20729 154 10133 10731 11513 119611 22440 28195 119830 9460 107693 119808 113 10858 18995 25474 27551 20083 119557 9477 88332 119219 80174 110862 119894 8843 14871 18227 119617 28697 119752 10530 119838 119169 10739 119547 39671 110862 103 18471 9059 89523 10459 8929 119230 11467 9640 13374 119831 9294 18471 108017 37388 119414 10739 8929 119230 12453 13767 9414 9997 10622 119608 14843 9137 119831 9294 18471 119894 11489 119580 13764 119617 9353 11261 119703 12178 154 10133 10731 119636 10622 119720 13374 35756 119673 119950 99958 9670 25242 12453 119747 15387 9890 37388 119414 119649 119567 10739 119703 119574 34079 119703 10530 9365 33188 13374 119852 9625 32537 18471 9533 24982 12605 119894 11489 9812 12965 119894 103 8903 120178 17594 9944 11261 27355 120057 10459 9890 37388 119414 119649 119578 10739 8844 118649 10622 79602 11506 122 110863 11373 119 9944 11261 27355 9890 37388 119414 119649 119578 10892 9157 27355 21876 11489 9944 11261 27355 10459 119675 119850 119729 12178 9356 79718 27506 113 120336 12436 14446 110859 9157 27355 100329 119693 10622 119550 119866 110862 8844 9944 11261 27355 10530 119623 13441 25701 9909 119333 20173 9944 11261 27355 10459 154 10133 126098 119703 12945 50632 10530 22799 120112 17594 103 59330 9460 107931 23969 119567 119555 9944 11261 27355 9890 37388 119414 119649 119578 10892 119675 9356 16617 27506 9157 27355 100329 119693 10622 25605 120038 24989 11489 9944 11261 27355 120057 10459 9435 37712 120004 119830 9460 107693 119808 110862 9477 88332 119219 80174 110862 9255 13764 14279 119649 33727 119609 17594 119575 21890 119831 9294 18471 119894 10459 9533 24982 12605 9059 23635 9059 89523 10459 119831 11467 9640 13374 119633 9944 11261 27355 10459 9665 89851 31720 11261 11287 9651 16323 60839 9100 103 9647 12310 20729 8857 61844 15387 9944 11261 27355 120057 11261 9962 15001 28188 41605 11513 119752 12178 120086 10739 9949 15891 14801 119555 9706 40032 18382 75416 11127 113 11517 103 10112 24124 110859 10150 117 19994 96355 17616 23506 24124 113 12396 79443 11127 110859 10193 117 14021 46776 23506 24124 103 96325 30331 110859 10186 28697 24124 119658 10459 119831 17138 119752 119693 10622 119623 13374 25685 9962 15001 28188 41605 120086 10739 119670 119587 28578 85146 119693 22879 103 16617 18108 9059 89523 119831 17138 113 11090 91724 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.849511 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.849799 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 5 14 26 31 44 64 68 72 164 177 193 217 245 323 331 418 450 463 472 501\n",
      "I1120 16:06:43.849933 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 5 14 26 31 44 64 68 72 164 177 193 217 245 323 331 418 450 463 472 501\n",
      "INFO:tensorflow:masked_lm_ids: 10892 11882 119723 30331 119617 88350 113 120355 9294 9890 18471 119747 18382 10731 119651 9460 79438 79443 113 9565\n",
      "I1120 16:06:43.850058 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 10892 11882 119723 30331 119617 88350 113 120355 9294 9890 18471 119747 18382 10731 119651 9460 79438 79443 113 9565\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.850196 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "I1120 16:06:43.850302 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.851399 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 는 의 ##견 ##과 함께 최근 보 ##안 산업 ##이 이 ##슈 ##화 ##되면서 대학교 ##에 정보 ##보 ##안 ##학과 ##가 많이 생 ##겨 ##나 ##고 있지만 ##, 실제 그 졸업 ##생 ##을 인터 ##뷰 ##를 해 ##보 ##면 기업 니 ##즈 ##에 필 ##적 ##한 인 ##재 ##를 찾 ##기 어 ##렵 ##다. 는 의 ##견 ##이 다 ##수 ##였다 R ##4 . 산 ##학 ##연 ##계 ##과정 ##에 대해 ##서는 근 ##본 ##적으로 학교 기반 및 역 ##량 ##에 기반 ##을 둔 연 ##계 ##과정 ##은 기업 니 ##즈 [MASK] 반영 ##하여 교육 [MASK] ##을 개선 ##하기 ##가 매우 어 ##렵 ##다. 고 밝혔다 R ##5 . [SEP] 이 변화 ##는 다음 연 ##도에 영향을 미치는 ##데 그 크 ##기는 12 ##가 되 ##며, 그 ##다음 [MASK] ##도에 미치는 영향 ##의 크 ##기는 122 ##가 ##rend 이를 누 [MASK] ##하면 1 ##( ##1 ##- ##2 ) ##이 되는 ##데, 이 ##로 ##써 장 ##기 탄 ##성 ##치를 계 ##측 ##할 수 있다. [MASK] ##일 시 ##계 ##열 자료 ##가 정 ##상 ##적 ##이지 않 ##지만 1 ##계 차 ##분 ##자료 ##( ##fir ##st difference ##d ##)가 정 ##상 ##적 [MASK] 두 자료 ##가 공 ##적 ##분 관계 ##에 있다 ##면, 가 ##성 ##적 회 ##귀 ##를 피 ##하기 위해 식 6 ##과 같은 오 ##차 ##수 ##정 [MASK] ##( ##er ##ror ##- ##corre ##ction model ##)을 [MASK] ##한다. y ##t = 0 + 1x [MASK] ##- ##( ##yt ##-1 + x ##t ##-1) + t ( ##6 ##鹼 는 [MASK] ##분 ##연 ##산 ##자 ##이고, 는 조 ##정 ##속 ##도( ##sp ##eed of ad ##just ##ment [MASK] 나타낸 ##다. 또 ##, 1 은 단 ##기 탄 ##성 ##치를 가 ##리 ##키 ##며, 는 장 ##기 탄 ##성 ##치를 가 ##리 ##킨 ##다( ##J ##ohn ##son ##, 1992 Ko ##h ##, 2000 Gan ##, 2006 ##). ##시 ##계 ##열 자료 ##가 정 ##상 ##적 ##이지 않고 1 ##계 차 ##분 ##자료 ##가 정 ##상 ##적 ##이 ##면서 공 ##적 ##분 관계 ##에 있 ##지 않 ##다 ##ncy 식 7 ##과 같은 모형 ##을 채 ##용한 ##다. y ##t = 0 + 1 x ##t + t ( ##7 ##) ##여 [MASK] 1 은 단 ##기 탄 ##성 ##치를 가 ##리 ##키 ##며, 장 ##기 탄 ##성 ##치는 계 ##측 ##되지 않는다 ##. ##3. 분석 [MASK] ##목 ##제품 시장 ##을 분석 ##대상으로 하여 주요 목 ##제품 ##, 즉 합 ##판 ##, 섬 ##유 ##판 ##, 파 [MASK] ##클 ##보 ##드를 분석 ##대상으로 하였다. 여 ##기에서 분석 ##대상으로 한 목 ##제품 외 ##에 기타 목 ##제품 ##도 생산 ##액 ##이 1 ##조 ##6 ##천 ##억 원 ##에 이 ##르는 것으로 추정 ##되고 [MASK] ##세 ##율 ##도 8 ##% ##에 이 ##르 ##지만 여 ##기에는 특성이 다른 제품 ##들이 다 ##수 포함 ##되어 있어 기준 가 ##격 ##의 설정 ##이 곤 [MASK] ##하여 분석 ##에 포함 ##하지 못 ##하였다. [SEP]\n",
      "I1120 16:06:43.851660 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 는 의 ##견 ##과 함께 최근 보 ##안 산업 ##이 이 ##슈 ##화 ##되면서 대학교 ##에 정보 ##보 ##안 ##학과 ##가 많이 생 ##겨 ##나 ##고 있지만 ##, 실제 그 졸업 ##생 ##을 인터 ##뷰 ##를 해 ##보 ##면 기업 니 ##즈 ##에 필 ##적 ##한 인 ##재 ##를 찾 ##기 어 ##렵 ##다. 는 의 ##견 ##이 다 ##수 ##였다 R ##4 . 산 ##학 ##연 ##계 ##과정 ##에 대해 ##서는 근 ##본 ##적으로 학교 기반 및 역 ##량 ##에 기반 ##을 둔 연 ##계 ##과정 ##은 기업 니 ##즈 [MASK] 반영 ##하여 교육 [MASK] ##을 개선 ##하기 ##가 매우 어 ##렵 ##다. 고 밝혔다 R ##5 . [SEP] 이 변화 ##는 다음 연 ##도에 영향을 미치는 ##데 그 크 ##기는 12 ##가 되 ##며, 그 ##다음 [MASK] ##도에 미치는 영향 ##의 크 ##기는 122 ##가 ##rend 이를 누 [MASK] ##하면 1 ##( ##1 ##- ##2 ) ##이 되는 ##데, 이 ##로 ##써 장 ##기 탄 ##성 ##치를 계 ##측 ##할 수 있다. [MASK] ##일 시 ##계 ##열 자료 ##가 정 ##상 ##적 ##이지 않 ##지만 1 ##계 차 ##분 ##자료 ##( ##fir ##st difference ##d ##)가 정 ##상 ##적 [MASK] 두 자료 ##가 공 ##적 ##분 관계 ##에 있다 ##면, 가 ##성 ##적 회 ##귀 ##를 피 ##하기 위해 식 6 ##과 같은 오 ##차 ##수 ##정 [MASK] ##( ##er ##ror ##- ##corre ##ction model ##)을 [MASK] ##한다. y ##t = 0 + 1x [MASK] ##- ##( ##yt ##-1 + x ##t ##-1) + t ( ##6 ##鹼 는 [MASK] ##분 ##연 ##산 ##자 ##이고, 는 조 ##정 ##속 ##도( ##sp ##eed of ad ##just ##ment [MASK] 나타낸 ##다. 또 ##, 1 은 단 ##기 탄 ##성 ##치를 가 ##리 ##키 ##며, 는 장 ##기 탄 ##성 ##치를 가 ##리 ##킨 ##다( ##J ##ohn ##son ##, 1992 Ko ##h ##, 2000 Gan ##, 2006 ##). ##시 ##계 ##열 자료 ##가 정 ##상 ##적 ##이지 않고 1 ##계 차 ##분 ##자료 ##가 정 ##상 ##적 ##이 ##면서 공 ##적 ##분 관계 ##에 있 ##지 않 ##다 ##ncy 식 7 ##과 같은 모형 ##을 채 ##용한 ##다. y ##t = 0 + 1 x ##t + t ( ##7 ##) ##여 [MASK] 1 은 단 ##기 탄 ##성 ##치를 가 ##리 ##키 ##며, 장 ##기 탄 ##성 ##치는 계 ##측 ##되지 않는다 ##. ##3. 분석 [MASK] ##목 ##제품 시장 ##을 분석 ##대상으로 하여 주요 목 ##제품 ##, 즉 합 ##판 ##, 섬 ##유 ##판 ##, 파 [MASK] ##클 ##보 ##드를 분석 ##대상으로 하였다. 여 ##기에서 분석 ##대상으로 한 목 ##제품 외 ##에 기타 목 ##제품 ##도 생산 ##액 ##이 1 ##조 ##6 ##천 ##억 원 ##에 이 ##르는 것으로 추정 ##되고 [MASK] ##세 ##율 ##도 8 ##% ##에 이 ##르 ##지만 여 ##기에는 특성이 다른 제품 ##들이 다 ##수 포함 ##되어 있어 기준 가 ##격 ##의 설정 ##이 곤 [MASK] ##하여 분석 ##에 포함 ##하지 못 ##하였다. [SEP]\n",
      "INFO:tensorflow:input_ids: 101 9043 9637 118634 11882 19653 119852 9356 34951 119787 10739 9638 119073 18227 96377 72085 10530 119596 30005 34951 65610 11287 47058 9420 89045 16439 11664 76123 110862 119695 8924 45004 24017 10622 119914 118999 11513 9960 30005 14867 119667 9049 24891 10530 9949 14801 11102 9640 36210 11513 9737 12310 9546 118879 119549 9043 9637 118634 10739 9056 15891 34776 155 11011 119 9407 23321 25486 21611 119719 10530 33378 37321 8926 40419 17022 119929 119658 9316 9566 44321 10530 119658 10622 9104 9568 21611 119719 10892 119667 9049 24891 103 119945 13374 119583 103 10622 119744 22440 11287 42608 9546 118879 119549 8888 99896 155 11166 119 102 9638 119586 11018 52292 9568 108521 58088 119610 28911 8924 9834 46216 10186 11287 9098 119635 8924 120385 103 108521 119610 119642 10459 9834 46216 17484 11287 68712 35756 9032 103 38378 122 110858 10759 110863 10729 114 10739 54780 119953 9638 11261 73131 9657 12310 9847 17138 62672 8887 119281 14843 9460 119547 103 18392 9485 21611 79604 119613 11287 9670 14871 14801 44359 9523 28578 122 21611 9730 37712 119882 110858 61644 10562 30856 10162 120060 9670 14871 14801 103 9102 119613 11287 8896 14801 37712 119657 10530 11506 119678 8843 17138 14801 9998 118661 11513 9946 22440 19905 9486 127 11882 18589 9580 23466 15891 16605 103 110858 10165 30101 110863 46968 17530 13192 119643 103 119554 193 10123 134 121 116 107179 103 110863 110858 20246 120109 116 192 10123 120560 116 188 113 11211 118542 9043 103 37712 25486 21386 13764 120148 9043 9678 16605 43962 120045 54609 40154 10108 10840 106670 10426 103 119777 119549 9144 110862 122 9632 9059 12310 9847 17138 62672 8843 12692 21039 119635 9043 9657 12310 9847 17138 62672 8843 12692 119330 119576 15417 77406 11599 110862 10450 30186 10237 110862 10180 90792 110862 10214 119558 14040 21611 79604 119613 11287 9670 14871 14801 44359 45593 122 21611 9730 37712 119882 11287 9670 14871 14801 10739 30936 8896 14801 37712 119657 10530 9647 12508 9523 11903 24166 9486 128 11882 18589 119736 10622 9738 65219 119549 193 10123 134 121 116 122 192 10123 116 188 113 11305 110859 29935 103 122 9632 9059 12310 9847 17138 62672 8843 12692 21039 119635 9657 12310 9847 17138 72087 8887 119281 59902 52723 110864 119573 119552 103 68055 120170 120008 10622 119552 120583 51076 55368 9284 120170 110862 9701 9957 33323 110862 9430 42815 33323 110862 9901 103 119327 30005 103151 119552 120583 119626 9565 120229 119552 120583 9954 9284 120170 9597 10530 73142 9284 120170 12092 119707 119122 10739 122 20626 11211 38631 91837 9612 10530 9638 47908 23925 119779 29208 103 24982 119183 12092 129 110855 10530 9638 31401 28578 9565 120370 120246 19709 119791 20173 9056 15891 119623 16855 45893 63185 8843 45465 10459 119734 10739 8890 103 13374 119552 10530 119623 23665 9290 119548 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.852007 47619347533312 create_pretraining_data.py:161] input_ids: 101 9043 9637 118634 11882 19653 119852 9356 34951 119787 10739 9638 119073 18227 96377 72085 10530 119596 30005 34951 65610 11287 47058 9420 89045 16439 11664 76123 110862 119695 8924 45004 24017 10622 119914 118999 11513 9960 30005 14867 119667 9049 24891 10530 9949 14801 11102 9640 36210 11513 9737 12310 9546 118879 119549 9043 9637 118634 10739 9056 15891 34776 155 11011 119 9407 23321 25486 21611 119719 10530 33378 37321 8926 40419 17022 119929 119658 9316 9566 44321 10530 119658 10622 9104 9568 21611 119719 10892 119667 9049 24891 103 119945 13374 119583 103 10622 119744 22440 11287 42608 9546 118879 119549 8888 99896 155 11166 119 102 9638 119586 11018 52292 9568 108521 58088 119610 28911 8924 9834 46216 10186 11287 9098 119635 8924 120385 103 108521 119610 119642 10459 9834 46216 17484 11287 68712 35756 9032 103 38378 122 110858 10759 110863 10729 114 10739 54780 119953 9638 11261 73131 9657 12310 9847 17138 62672 8887 119281 14843 9460 119547 103 18392 9485 21611 79604 119613 11287 9670 14871 14801 44359 9523 28578 122 21611 9730 37712 119882 110858 61644 10562 30856 10162 120060 9670 14871 14801 103 9102 119613 11287 8896 14801 37712 119657 10530 11506 119678 8843 17138 14801 9998 118661 11513 9946 22440 19905 9486 127 11882 18589 9580 23466 15891 16605 103 110858 10165 30101 110863 46968 17530 13192 119643 103 119554 193 10123 134 121 116 107179 103 110863 110858 20246 120109 116 192 10123 120560 116 188 113 11211 118542 9043 103 37712 25486 21386 13764 120148 9043 9678 16605 43962 120045 54609 40154 10108 10840 106670 10426 103 119777 119549 9144 110862 122 9632 9059 12310 9847 17138 62672 8843 12692 21039 119635 9043 9657 12310 9847 17138 62672 8843 12692 119330 119576 15417 77406 11599 110862 10450 30186 10237 110862 10180 90792 110862 10214 119558 14040 21611 79604 119613 11287 9670 14871 14801 44359 45593 122 21611 9730 37712 119882 11287 9670 14871 14801 10739 30936 8896 14801 37712 119657 10530 9647 12508 9523 11903 24166 9486 128 11882 18589 119736 10622 9738 65219 119549 193 10123 134 121 116 122 192 10123 116 188 113 11305 110859 29935 103 122 9632 9059 12310 9847 17138 62672 8843 12692 21039 119635 9657 12310 9847 17138 72087 8887 119281 59902 52723 110864 119573 119552 103 68055 120170 120008 10622 119552 120583 51076 55368 9284 120170 110862 9701 9957 33323 110862 9430 42815 33323 110862 9901 103 119327 30005 103151 119552 120583 119626 9565 120229 119552 120583 9954 9284 120170 9597 10530 73142 9284 120170 12092 119707 119122 10739 122 20626 11211 38631 91837 9612 10530 9638 47908 23925 119779 29208 103 24982 119183 12092 129 110855 10530 9638 31401 28578 9565 120370 120246 19709 119791 20173 9056 15891 119623 16855 45893 63185 8843 45465 10459 119734 10739 8890 103 13374 119552 10530 119623 23665 9290 119548 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.852298 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.852550 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 92 96 129 138 141 165 192 211 220 229 237 250 252 269 338 362 386 407 442 470\n",
      "I1120 16:06:43.852676 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 92 96 129 138 141 165 192 211 220 229 237 250 252 269 338 362 386 407 442 470\n",
      "INFO:tensorflow:masked_lm_ids: 11513 120198 9568 119684 14801 9248 54355 19905 119952 119564 10123 110859 9730 119638 119678 120229 119882 45725 8900 49919\n",
      "I1120 16:06:43.852792 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 11513 120198 9568 119684 14801 9248 54355 19905 119952 119564 10123 110859 9730 119638 119678 120229 119882 45725 8900 49919\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.852908 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "I1120 16:06:43.853012 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.854093 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 팜 산 ##유 ##(P ##A ##O ##)는 팜 착 ##유 [MASK] ##에서 팜 열 ##매 ##송 ##이 ##( ##FF ##B ##, Fresh Fruit Bu ##nch austro [MASK] ##팀 ##살 ##균 과정 [MASK] [MASK] [MASK] ##수 ##와 함께 나 ##오는 기 ##름 ##성 ##분 [MASK] ##, 일정 ##량을 모 ##으 ##기 위해 저장 ##소 [MASK] ##ond [MASK] 오 ##랫 ##동안 정 ##체 ##된 상태 ##로 있 ##기 때문에 산 ##패 ##가 발생 ##하여 지방 [MASK] ##이 [MASK] ##고 이 ##물질 ##이 많 [MASK] ##수 ##분 ##함 [MASK] 높 ##다. 전 ##산 ##가 ##( ##aci ##d number ##) ##란 시료 1 ##g 중에 함 ##유 ##되어 있는 산 ##성 성 ##분을 적 [MASK] ##하는데 소 ##요 ##되는 염 [MASK] 수 ##량 ##으로 시료 그 ##램 당 수 ##산화 ##칼 ##륨 ##의 mg 단위 ##로 [MASK] ##시 ##되 ##므로 전 ##산 ##가 ##가 크 ##면 산 ##화된 물 ##질 ##이 많다 ##는 [MASK] [MASK] ##한다. [SEP] 고 ##정 ##식 ##과 회 ##전 ##식 ##이 있다. [SEP]\n",
      "I1120 16:06:43.854283 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 팜 산 ##유 ##(P ##A ##O ##)는 팜 착 ##유 [MASK] ##에서 팜 열 ##매 ##송 ##이 ##( ##FF ##B ##, Fresh Fruit Bu ##nch austro [MASK] ##팀 ##살 ##균 과정 [MASK] [MASK] [MASK] ##수 ##와 함께 나 ##오는 기 ##름 ##성 ##분 [MASK] ##, 일정 ##량을 모 ##으 ##기 위해 저장 ##소 [MASK] ##ond [MASK] 오 ##랫 ##동안 정 ##체 ##된 상태 ##로 있 ##기 때문에 산 ##패 ##가 발생 ##하여 지방 [MASK] ##이 [MASK] ##고 이 ##물질 ##이 많 [MASK] ##수 ##분 ##함 [MASK] 높 ##다. 전 ##산 ##가 ##( ##aci ##d number ##) ##란 시료 1 ##g 중에 함 ##유 ##되어 있는 산 ##성 성 ##분을 적 [MASK] ##하는데 소 ##요 ##되는 염 [MASK] 수 ##량 ##으로 시료 그 ##램 당 수 ##산화 ##칼 ##륨 ##의 mg 단위 ##로 [MASK] ##시 ##되 ##므로 전 ##산 ##가 ##가 크 ##면 산 ##화된 물 ##질 ##이 많다 ##는 [MASK] [MASK] ##한다. [SEP] 고 ##정 ##식 ##과 회 ##전 ##식 ##이 있다. [SEP]\n",
      "INFO:tensorflow:input_ids: 101 9905 9407 42815 120065 10738 11403 119706 9905 9731 42815 103 11489 9905 9569 100372 119057 10739 110858 82678 11274 110862 61138 79345 11916 31215 63063 103 74399 106249 77692 119622 103 103 103 15891 12638 19653 8982 82823 8932 49543 17138 37712 103 110862 120018 119717 9283 119185 12310 19905 119963 22333 103 26029 103 9580 118859 93867 9670 29683 13441 119675 11261 9647 12310 20729 9407 119383 11287 119568 13374 105383 103 10739 103 11664 9638 120085 10739 9249 103 15891 37712 48533 103 9028 119549 9665 21386 11287 110858 28841 10162 11487 110859 49919 119923 122 10240 102246 9956 42815 16855 13767 9407 17138 9434 97005 9664 103 119885 9448 48549 24683 9570 103 9460 44321 11467 119923 8924 118857 9067 9460 119979 119287 118900 10459 25699 120057 11261 103 14040 118800 56460 9665 21386 11287 11287 9834 14867 9407 120004 9299 48599 10739 100313 11018 103 103 119554 102 8888 16605 21155 11882 9998 16617 21155 10739 119547 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.854562 47619347533312 create_pretraining_data.py:161] input_ids: 101 9905 9407 42815 120065 10738 11403 119706 9905 9731 42815 103 11489 9905 9569 100372 119057 10739 110858 82678 11274 110862 61138 79345 11916 31215 63063 103 74399 106249 77692 119622 103 103 103 15891 12638 19653 8982 82823 8932 49543 17138 37712 103 110862 120018 119717 9283 119185 12310 19905 119963 22333 103 26029 103 9580 118859 93867 9670 29683 13441 119675 11261 9647 12310 20729 9407 119383 11287 119568 13374 105383 103 10739 103 11664 9638 120085 10739 9249 103 15891 37712 48533 103 9028 119549 9665 21386 11287 110858 28841 10162 11487 110859 49919 119923 122 10240 102246 9956 42815 16855 13767 9407 17138 9434 97005 9664 103 119885 9448 48549 24683 9570 103 9460 44321 11467 119923 8924 118857 9067 9460 119979 119287 118900 10459 25699 120057 11261 103 14040 118800 56460 9665 21386 11287 11287 9834 14867 9407 120004 9299 48599 10739 100313 11018 103 103 119554 102 8888 16605 21155 11882 9998 16617 21155 10739 119547 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.854857 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.855135 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 7 11 26 27 32 33 34 44 54 56 74 76 82 86 111 117 133 148 150 151\n",
      "I1120 16:06:43.855260 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 7 11 26 27 32 33 34 44 54 56 74 76 82 86 111 117 133 148 150 151\n",
      "INFO:tensorflow:masked_lm_ids: 119706 120255 119592 9477 9485 9636 70122 120024 120065 119994 21386 9028 119579 119722 16605 46874 9934 100313 21371 119614\n",
      "I1120 16:06:43.855371 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 119706 120255 119592 9477 9485 9636 70122 120024 120065 119994 21386 9028 119579 119722 16605 46874 9934 100313 21371 119614\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.855484 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "I1120 16:06:43.855585 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.857412 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 사회 ##성은 디 ##자인 과정 ##을 통해 사회 [MASK] ##나 이 ##슈 ##에 대해 이용 ##자와 공간 ##이 소 ##통 ##하고 있는 ##가를 평가 ##하였으며, 윤 ##리 ##성은 디 ##자인 결과 ##물 ##이 사회 ##발전 ##과 이 ##익 朐 이용 ##자 ##들과 공 ##유 ##하고 있는 ##지를 평가 ##하였다. Fig. 1. Sus ##tain ##able design and plane over place property ##. ##3. ##2. ##1. IB ##A 엠 ##셔 ##파 ##크 ##위치 독일 중 ##부 노 ##르 ##트 ##라인 베 ##스트 ##팔 [MASK] 루 ##르 공 ##업 ##지역 ##규 [MASK] 784 ##평 ##방 ##킬 ##로 ##미 ##터 ##( ##17 ##개 도시 ##, 200 ##만 인구 ##) ##시설 광 ##장 ##, 공 ##원 ##, 전 ##시장 ##Fig. 2. Image of before development Em ##scher Park ##. Fig. 3. Image of after development Em ##scher Park ##엠 ##셔 ##파 ##크 ##는 라 ##인 ##강 ##의 지 ##류 중 하나 ##인 [MASK] ##셔 ##강 주 ##위 ##의 도시 ##를 중심으로 광 ##역 ##적인 도시 ##환경 ##계획 전 ##반 ##을 아 ##우 ##르는 통 ##칭 ##이다. [SEP] ##으나 관련 산업 ##의 재 ##편 ##과 구조 ##조 ##정을 거 ##치 ##며 [MASK] ##염 ##과 훼 ##손 ##, 자연 ##과 거 ##주 ##민 ##들의 황 ##폐 ##화된 모 ##습 등을 남 ##기 ##며 쇠 ##퇴 ##해 ##갔다 ##. [MASK] IB ##A 주 ##관 ##으로 국제 ##설계 ##경 ##기를 통해 본 ##격 ##적으로 진행 ##되었으며 다 ##수의 계획 ##가 ##, 건 ##축 ##가 ##, 조 ##경 ##가 ##, 공 [MASK] ##, 예 [MASK] ##가 ##, 시 ##민 ##, 환경 ##단 ##체 등의 노 ##력 ##과 협 ##력 ##으로 1989 1999년 ##까지 10 ##년 ##간 집 ##중 ##적으로 시행 ##되었다. 이 ##들의 협 ##력 ##은 엠 ##셔 [MASK] ##변 ##지역 [MASK] 오 ##염 ##을 치 ##유 ##하고 건강 ##한 생 ##태 ##계 ##로 ##의 회 ##복 ##을 이루 ##는 한편 ##, 주 ##민 ##과 자연 ##환경 ##과의 관계 ##, 문화 ##적인 성 ##취 [MASK] 주 ##민 ##생활 조건 ##의 충 ##족 등에 대한 다양 ##하고 심 ##도 깊 ##은 대 ##안 ##을 제시 ##하고 실 ##행 ##하는 역할을 수행 ##하였다. Table 2. Evaluation and Analysis of IB ##A Em ##scher Park ##Table 3. Evaluation [MASK] Analysis of High Line Park ##3. ##2. ##2. 뉴 ##욕 하 ##이라 ##인 공 ##원 ##위치 뉴 ##욕 맨 [MASK] ##탄 서 ##부 ##규 ##모 길 ##이 13 mile ( ##20 km ##) ##면 ##적 6 ##에 ##이 ##커 ##( ##1200 [MASK] ##) ##시설 광 ##장 ##, 공 ##원 ##, 전 ##시장 ##하 ##이라 ##인은 1930 [MASK] 교 ##각 ##높 ##이 약 9 m 정도 ##의 건 ##물 ##과 건 ##물을 잇 ##는 철도 [MASK] 공 ##업 ##지 ##대 쇠 ##락 ##과 트 ##럭 ##의 이용 ##이 늘 ##어나 ##면서 열 ##차 ##운 ##행 ##이 줄 ##어 1980 년 ##대 폐 ##쇄 ##되어 30 ##년 ##간 흉 ##물 [MASK] 방 ##치 ##되었 [MASK] 철 ##로 ##이다. 방 [MASK] ##되었 ##던 고 ##가 ##철도 ##를 1999년 하 ##이라 ##인 인 ##근 ##에 사 ##는 주 ##민 조 ##수 ##아 데 ##이 ##비 ##드 ##와 로 ##버 ##트 해 ##먼 ##드 가 하 ##이라 ##인 친 [SEP]\n",
      "I1120 16:06:43.857724 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 사회 ##성은 디 ##자인 과정 ##을 통해 사회 [MASK] ##나 이 ##슈 ##에 대해 이용 ##자와 공간 ##이 소 ##통 ##하고 있는 ##가를 평가 ##하였으며, 윤 ##리 ##성은 디 ##자인 결과 ##물 ##이 사회 ##발전 ##과 이 ##익 朐 이용 ##자 ##들과 공 ##유 ##하고 있는 ##지를 평가 ##하였다. Fig. 1. Sus ##tain ##able design and plane over place property ##. ##3. ##2. ##1. IB ##A 엠 ##셔 ##파 ##크 ##위치 독일 중 ##부 노 ##르 ##트 ##라인 베 ##스트 ##팔 [MASK] 루 ##르 공 ##업 ##지역 ##규 [MASK] 784 ##평 ##방 ##킬 ##로 ##미 ##터 ##( ##17 ##개 도시 ##, 200 ##만 인구 ##) ##시설 광 ##장 ##, 공 ##원 ##, 전 ##시장 ##Fig. 2. Image of before development Em ##scher Park ##. Fig. 3. Image of after development Em ##scher Park ##엠 ##셔 ##파 ##크 ##는 라 ##인 ##강 ##의 지 ##류 중 하나 ##인 [MASK] ##셔 ##강 주 ##위 ##의 도시 ##를 중심으로 광 ##역 ##적인 도시 ##환경 ##계획 전 ##반 ##을 아 ##우 ##르는 통 ##칭 ##이다. [SEP] ##으나 관련 산업 ##의 재 ##편 ##과 구조 ##조 ##정을 거 ##치 ##며 [MASK] ##염 ##과 훼 ##손 ##, 자연 ##과 거 ##주 ##민 ##들의 황 ##폐 ##화된 모 ##습 등을 남 ##기 ##며 쇠 ##퇴 ##해 ##갔다 ##. [MASK] IB ##A 주 ##관 ##으로 국제 ##설계 ##경 ##기를 통해 본 ##격 ##적으로 진행 ##되었으며 다 ##수의 계획 ##가 ##, 건 ##축 ##가 ##, 조 ##경 ##가 ##, 공 [MASK] ##, 예 [MASK] ##가 ##, 시 ##민 ##, 환경 ##단 ##체 등의 노 ##력 ##과 협 ##력 ##으로 1989 1999년 ##까지 10 ##년 ##간 집 ##중 ##적으로 시행 ##되었다. 이 ##들의 협 ##력 ##은 엠 ##셔 [MASK] ##변 ##지역 [MASK] 오 ##염 ##을 치 ##유 ##하고 건강 ##한 생 ##태 ##계 ##로 ##의 회 ##복 ##을 이루 ##는 한편 ##, 주 ##민 ##과 자연 ##환경 ##과의 관계 ##, 문화 ##적인 성 ##취 [MASK] 주 ##민 ##생활 조건 ##의 충 ##족 등에 대한 다양 ##하고 심 ##도 깊 ##은 대 ##안 ##을 제시 ##하고 실 ##행 ##하는 역할을 수행 ##하였다. Table 2. Evaluation and Analysis of IB ##A Em ##scher Park ##Table 3. Evaluation [MASK] Analysis of High Line Park ##3. ##2. ##2. 뉴 ##욕 하 ##이라 ##인 공 ##원 ##위치 뉴 ##욕 맨 [MASK] ##탄 서 ##부 ##규 ##모 길 ##이 13 mile ( ##20 km ##) ##면 ##적 6 ##에 ##이 ##커 ##( ##1200 [MASK] ##) ##시설 광 ##장 ##, 공 ##원 ##, 전 ##시장 ##하 ##이라 ##인은 1930 [MASK] 교 ##각 ##높 ##이 약 9 m 정도 ##의 건 ##물 ##과 건 ##물을 잇 ##는 철도 [MASK] 공 ##업 ##지 ##대 쇠 ##락 ##과 트 ##럭 ##의 이용 ##이 늘 ##어나 ##면서 열 ##차 ##운 ##행 ##이 줄 ##어 1980 년 ##대 폐 ##쇄 ##되어 30 ##년 ##간 흉 ##물 [MASK] 방 ##치 ##되었 [MASK] 철 ##로 ##이다. 방 [MASK] ##되었 ##던 고 ##가 ##철도 ##를 1999년 하 ##이라 ##인 인 ##근 ##에 사 ##는 주 ##민 조 ##수 ##아 데 ##이 ##비 ##드 ##와 로 ##버 ##트 해 ##먼 ##드 가 하 ##이라 ##인 친 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 119701 107442 9122 86150 119622 10622 25605 119701 103 16439 9638 119073 10530 33378 119580 89389 119711 10739 9448 43022 12453 13767 92318 119566 119654 9627 12692 107442 9122 86150 85533 29364 10739 119701 120240 11882 9638 119188 4464 119580 13764 72482 8896 42815 12453 13767 36908 119566 119548 119603 119590 21241 37879 13096 13684 10111 35007 10491 11192 18381 110864 119573 119562 119589 110503 10738 9563 119049 46150 20308 120245 51175 9694 14646 9022 31401 15184 120051 9344 34994 119378 103 9213 31401 8896 26784 119788 69753 103 68658 119398 42337 119331 11261 22458 21876 110858 34264 21789 101660 110862 10777 19105 110484 110859 119922 8903 13890 110862 8896 14279 110862 9665 120172 119565 119616 35314 10108 11360 13405 11289 21045 11239 110864 119603 119631 35314 10108 10662 13405 11289 21045 11239 119141 119049 46150 20308 11018 9157 12030 47181 10459 9706 46520 9694 119737 12030 103 119049 47181 9689 19855 10459 101660 11513 75109 8903 23160 15387 101660 119764 120125 9665 30134 10622 9519 27355 47908 9879 52094 119555 102 35466 86080 119787 10459 9659 50450 11882 119605 20626 40818 8863 18622 21406 103 119144 11882 10009 119053 110862 120002 11882 8863 16323 36553 25258 9997 119399 120004 9283 119081 33727 8987 12310 21406 9456 119362 14523 84986 110864 103 110503 10738 9689 20595 11467 61320 120153 31720 29669 25605 9358 45465 17022 119625 55835 9056 57138 120053 11287 110862 8865 70122 11287 110862 9678 31720 11287 110862 8896 103 110862 9576 103 11287 110862 9485 36553 110862 119606 24989 29683 28697 9022 28143 11882 9981 28143 11467 10524 47810 18382 10150 10954 18784 9711 41693 17022 119902 119582 9638 25258 9981 28143 10892 9563 119049 103 118985 119788 103 9580 119144 10622 9779 42815 12453 119681 11102 9420 83616 21611 11261 10459 9998 70915 10622 120233 11018 53519 110862 9689 36553 11882 120002 119764 102003 119657 110862 119968 15387 9434 119279 103 9689 36553 119961 119705 10459 9770 52560 77547 18154 120122 12453 9491 12092 8938 10892 9069 34951 10622 119591 12453 9489 25549 12178 69144 119570 119548 34421 119616 77702 10111 24314 10108 110503 10738 11289 21045 11239 119599 119631 77702 103 24314 10108 11956 14357 11239 119573 119562 119562 9039 109971 9952 119671 12030 8896 14279 120245 9039 109971 9260 103 66554 9425 14646 69753 39420 8934 10739 10249 21128 113 22650 10204 110859 14867 14801 127 10530 10739 106826 110858 121717 103 110859 119922 8903 13890 110862 8896 14279 110862 9665 120172 35506 119671 88236 11028 103 8907 66540 118747 10739 9539 130 181 107657 10459 8865 29364 11882 8865 69047 9646 11018 87624 103 8896 26784 12508 14423 9456 107693 11882 9890 118864 10459 119580 10739 9044 120098 30936 9569 23466 21614 25549 10739 9692 12965 10538 9018 14423 9927 119058 16855 10244 10954 18784 10014 29364 103 9328 18622 119587 103 9747 11261 119555 9328 103 119587 23990 8888 11287 80012 11513 47810 9952 119671 12030 9640 50248 10530 9405 11018 9689 36553 9678 15891 16985 9083 10739 29455 15001 12638 9202 41605 15184 9960 118922 15001 8843 9952 119671 12030 9781 102\n",
      "I1120 16:06:43.858109 47619347533312 create_pretraining_data.py:161] input_ids: 101 119701 107442 9122 86150 119622 10622 25605 119701 103 16439 9638 119073 10530 33378 119580 89389 119711 10739 9448 43022 12453 13767 92318 119566 119654 9627 12692 107442 9122 86150 85533 29364 10739 119701 120240 11882 9638 119188 4464 119580 13764 72482 8896 42815 12453 13767 36908 119566 119548 119603 119590 21241 37879 13096 13684 10111 35007 10491 11192 18381 110864 119573 119562 119589 110503 10738 9563 119049 46150 20308 120245 51175 9694 14646 9022 31401 15184 120051 9344 34994 119378 103 9213 31401 8896 26784 119788 69753 103 68658 119398 42337 119331 11261 22458 21876 110858 34264 21789 101660 110862 10777 19105 110484 110859 119922 8903 13890 110862 8896 14279 110862 9665 120172 119565 119616 35314 10108 11360 13405 11289 21045 11239 110864 119603 119631 35314 10108 10662 13405 11289 21045 11239 119141 119049 46150 20308 11018 9157 12030 47181 10459 9706 46520 9694 119737 12030 103 119049 47181 9689 19855 10459 101660 11513 75109 8903 23160 15387 101660 119764 120125 9665 30134 10622 9519 27355 47908 9879 52094 119555 102 35466 86080 119787 10459 9659 50450 11882 119605 20626 40818 8863 18622 21406 103 119144 11882 10009 119053 110862 120002 11882 8863 16323 36553 25258 9997 119399 120004 9283 119081 33727 8987 12310 21406 9456 119362 14523 84986 110864 103 110503 10738 9689 20595 11467 61320 120153 31720 29669 25605 9358 45465 17022 119625 55835 9056 57138 120053 11287 110862 8865 70122 11287 110862 9678 31720 11287 110862 8896 103 110862 9576 103 11287 110862 9485 36553 110862 119606 24989 29683 28697 9022 28143 11882 9981 28143 11467 10524 47810 18382 10150 10954 18784 9711 41693 17022 119902 119582 9638 25258 9981 28143 10892 9563 119049 103 118985 119788 103 9580 119144 10622 9779 42815 12453 119681 11102 9420 83616 21611 11261 10459 9998 70915 10622 120233 11018 53519 110862 9689 36553 11882 120002 119764 102003 119657 110862 119968 15387 9434 119279 103 9689 36553 119961 119705 10459 9770 52560 77547 18154 120122 12453 9491 12092 8938 10892 9069 34951 10622 119591 12453 9489 25549 12178 69144 119570 119548 34421 119616 77702 10111 24314 10108 110503 10738 11289 21045 11239 119599 119631 77702 103 24314 10108 11956 14357 11239 119573 119562 119562 9039 109971 9952 119671 12030 8896 14279 120245 9039 109971 9260 103 66554 9425 14646 69753 39420 8934 10739 10249 21128 113 22650 10204 110859 14867 14801 127 10530 10739 106826 110858 121717 103 110859 119922 8903 13890 110862 8896 14279 110862 9665 120172 35506 119671 88236 11028 103 8907 66540 118747 10739 9539 130 181 107657 10459 8865 29364 11882 8865 69047 9646 11018 87624 103 8896 26784 12508 14423 9456 107693 11882 9890 118864 10459 119580 10739 9044 120098 30936 9569 23466 21614 25549 10739 9692 12965 10538 9018 14423 9927 119058 16855 10244 10954 18784 10014 29364 103 9328 18622 119587 103 9747 11261 119555 9328 103 119587 23990 8888 11287 80012 11513 47810 9952 119671 12030 9640 50248 10530 9405 11018 9689 36553 9678 15891 16985 9083 10739 29455 15001 12638 9202 41605 15184 9960 118922 15001 8843 9952 119671 12030 9781 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.858409 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.858667 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 9 39 82 89 148 186 212 242 245 279 282 315 356 376 398 413 431 465 469 474\n",
      "I1120 16:06:43.858828 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 9 39 82 89 148 186 212 242 245 279 282 315 356 376 398 413 431 465 469 474\n",
      "INFO:tensorflow:masked_lm_ids: 120144 10622 118873 39420 9563 9580 69610 109522 51945 9689 10459 12638 10111 35506 119398 86181 74519 11261 23990 18622\n",
      "I1120 16:06:43.858947 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 120144 10622 118873 39420 9563 9580 69610 109522 51945 9689 10459 12638 10111 35506 119398 86181 74519 11261 23990 18622\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.859077 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "I1120 16:06:43.859182 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.860247 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 사용자 비 [MASK] ##은 대 ##략 아 ##시아 ##인 16 ##%, 비 ##아 ##시아 ##인 [MASK] [MASK] ##이며, 특히 백 ##인이 [MASK] ##%로 압 ##도 ##적인 비 [MASK] ##을 차 ##지 ##한다. 미국 ##인이 ##라는 타 [MASK] 고객 공 ##략 ##에 성 ##공 ##했 ##음을 의미 [MASK] 드라마 ##피 ##버 ##는 출 ##발 ##부터 단 ##순 ##히 아 ##시아 사용자를 위한 서비스 ##가 아니 ##었고 ##, 결과 ##적으로 현 ##지의 미국 ##인 [MASK] 한국 ##의 독 ##특 ##한 콘 ##텐 ##츠 ##를 [MASK] ##하는 járásban ##별 ##한 창 ##구 ##로 자 ##리 ##잡 ##았다 ##( [MASK] ##석 ##, 창 ##업 ##자 ##) ##2) 이 ##익 [MASK] ##드라마 ##피 [MASK] ##는 월 ##9. ##99 의 사용 ##료 ##를 받고 있는데 ##, 비 ##키 ##에 비해 높은 [MASK] ##액 ##이다. 광 ##고 ##없 ##이 HD ##급 화 ##질 ##로 이용 ##할 수 있고 [MASK] 로 ##쿠 ##를 통해 TV ##에서도 [MASK] ##텐 ##츠 ##를 감 ##상 ##할 수 있다. [SEP] 이 취 ##성을 말한다 ##. [SEP]\n",
      "I1120 16:06:43.860418 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 사용자 비 [MASK] ##은 대 ##략 아 ##시아 ##인 16 ##%, 비 ##아 ##시아 ##인 [MASK] [MASK] ##이며, 특히 백 ##인이 [MASK] ##%로 압 ##도 ##적인 비 [MASK] ##을 차 ##지 ##한다. 미국 ##인이 ##라는 타 [MASK] 고객 공 ##략 ##에 성 ##공 ##했 ##음을 의미 [MASK] 드라마 ##피 ##버 ##는 출 ##발 ##부터 단 ##순 ##히 아 ##시아 사용자를 위한 서비스 ##가 아니 ##었고 ##, 결과 ##적으로 현 ##지의 미국 ##인 [MASK] 한국 ##의 독 ##특 ##한 콘 ##텐 ##츠 ##를 [MASK] ##하는 járásban ##별 ##한 창 ##구 ##로 자 ##리 ##잡 ##았다 ##( [MASK] ##석 ##, 창 ##업 ##자 ##) ##2) 이 ##익 [MASK] ##드라마 ##피 [MASK] ##는 월 ##9. ##99 의 사용 ##료 ##를 받고 있는데 ##, 비 ##키 ##에 비해 높은 [MASK] ##액 ##이다. 광 ##고 ##없 ##이 HD ##급 화 ##질 ##로 이용 ##할 수 있고 [MASK] 로 ##쿠 ##를 통해 TV ##에서도 [MASK] ##텐 ##츠 ##를 감 ##상 ##할 수 있다. [SEP] 이 취 ##성을 말한다 ##. [SEP]\n",
      "INFO:tensorflow:input_ids: 101 120092 9379 103 10892 9069 118863 9519 46861 12030 10250 119749 9379 16985 46861 12030 103 103 119841 39671 9331 56789 103 119910 9527 12092 15387 9379 103 10622 9730 12508 119554 23545 56789 60362 9845 103 120000 8896 118863 10530 9434 28000 119424 59724 119614 103 53736 97146 41605 11018 9768 51431 17655 9059 119064 18108 9519 46861 120867 28195 119617 11287 120145 48754 110862 85533 17022 9978 73479 23545 12030 103 48556 10459 9088 119371 11102 9814 119353 60479 11513 103 12178 95650 61844 11102 9736 17196 11261 9651 12692 119199 27303 110858 103 40958 110862 9736 26784 13764 110859 119647 9638 119188 103 75782 97146 103 11018 9613 120087 88657 9637 119550 38688 11513 79602 60030 110862 9379 21039 10530 100876 55600 103 119122 119555 8903 11664 119136 10739 18987 37568 9993 48599 11261 119580 14843 9460 40523 103 9202 61156 11513 25605 10813 119829 103 119353 60479 11513 8848 14871 14843 9460 119547 102 9638 9773 36456 52462 110864 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.860693 47619347533312 create_pretraining_data.py:161] input_ids: 101 120092 9379 103 10892 9069 118863 9519 46861 12030 10250 119749 9379 16985 46861 12030 103 103 119841 39671 9331 56789 103 119910 9527 12092 15387 9379 103 10622 9730 12508 119554 23545 56789 60362 9845 103 120000 8896 118863 10530 9434 28000 119424 59724 119614 103 53736 97146 41605 11018 9768 51431 17655 9059 119064 18108 9519 46861 120867 28195 119617 11287 120145 48754 110862 85533 17022 9978 73479 23545 12030 103 48556 10459 9088 119371 11102 9814 119353 60479 11513 103 12178 95650 61844 11102 9736 17196 11261 9651 12692 119199 27303 110858 103 40958 110862 9736 26784 13764 110859 119647 9638 119188 103 75782 97146 103 11018 9613 120087 88657 9637 119550 38688 11513 79602 60030 110862 9379 21039 10530 100876 55600 103 119122 119555 8903 11664 119136 10739 18987 37568 9993 48599 11261 119580 14843 9460 40523 103 9202 61156 11513 25605 10813 119829 103 119353 60479 11513 8848 14871 14843 9460 119547 102 9638 9773 36456 52462 110864 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.860980 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.861246 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 3 16 17 22 28 37 47 73 83 85 95 96 97 106 109 113 126 142 149 153\n",
      "I1120 16:06:43.861370 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 3 16 17 22 28 37 47 73 83 85 95 96 97 106 109 113 126 142 149 153\n",
      "INFO:tensorflow:masked_lm_ids: 41693 11761 110855 11126 41693 118669 119554 26212 119611 9891 110858 118963 40958 73844 41605 88657 8928 110862 9814 8848\n",
      "I1120 16:06:43.861482 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 41693 11761 110855 11126 41693 118669 119554 26212 119611 9891 110858 118963 40958 73844 41605 88657 8928 110862 9814 8848\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.861593 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "I1120 16:06:43.861696 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.862810 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] ##ivar ##s of Kentucky blue ##grass grown under [MASK] and natural conditions ##. G ##erm ##ination speed was compared as days to ger ##mination percentage of 50 ##, 65 and 80 ##%, respectively ##. Alternative and natural conditions represent alternative conditions of 8 ##- ##hr light ( ##9 00 AM ##17 00 PM ##) [MASK] 25 ##C and 16 ##- ##hr dark ( ##17 00 PM ##9 00 AM ##) at 15 ##C and natural environmental conditions at [MASK] room temperature of 5 to 23 ##C ##, respectively ##. 켄 ##터 [MASK] 블 ##루 ##그 ##래 ##스 종 ##자의 50% 발 ##아 ##세는 Blacks ##burg II 및 Voyager II 품 ##종 ##을 [MASK] ##한 대부분 품 ##종의 경우 IS ##TA 변 ##온 환경 ##에서는 11일 전 ##후 ##로 나타났다. 하지만 자연 실 ##온 환경 ##에서는 이 ##보다 느 ##린 15일 전 ##후 ##로 나타났다. 즉 켄 ##터 ##키 블 ##루 ##그 ##래 ##스 종 ##자를 IS ##TA 변 ##온 ##과 유사 ##한 적 ##기에 파 ##종 ##할 경우 50% 발 ##아 ##세는 생 ##육 ##환경 ##이 다 ##소 불 ##리 ##한 시 ##기에 파 [MASK] 하는 것 ##보다 평균 4일 정도 더 빠 ##른 것을 의미 ##한다. 전체 15 종 ##류의 공 ##시 품 ##종 중 특히 Voyager II 품 ##종 ##은 예 ##외 [MASK] 발 ##아 ##속 ##도가 늦 ##어 ##서 IS ##TA 변 ##온 ##에서는 21 ##. ##6 ##8 ##일 ##, 자연 실 ##온 ##에서는 20. ##7 [MASK] ##일 정도로 나타났다. 즉 다른 품 ##종 ##에 비해 Voyager II 품 ##종 ##은 50% [MASK] ##아 ##세가 평균 510 ##일 정도 더 늦 ##는 것을 의미 ##한다. 한 ##지 ##형 계 ##통 ##인 켄 ##터 ##키 블 ##루 ##그 ##래 ##스의 경우 줄 [MASK] ##생 ##장의 생 ##육 ##적 ##온 ##이 1624 ##C ##이기 때문에 이와 좀 더 유사 ##한 환경 ##조건 ##인 IS ##TA 변 ##온 ##에 가 ##까 ##울 ##수록 유 ##묘 [SEP] [MASK] 7 ##. Solid ##ification zone [MASK] occurs when fill ##ing ##( ##a ##) injection condition A ( ##b ##) injection condition B ##( ##c ##) injection condition C3 ##. ##1. ##5 전 ##단 ##응 ##력 ##과 전 ##단 ##률 ##전 ##단 ##응 ##력 ##과 전 ##단 ##률 ##은 수 ##지 ##마다 가지고 있는 최대 [MASK] ##용 ##치를 초 ##과 ##할 경우 수 ##지 자 ##체의 특성이 바 ##뀌 ##고 제품 표면 ##에 박 ##리가 발생 ##할 수 있다. 아 ##래 Fig. 8 ##( ##a ##)은 충 ##전 ##률 98 ##% ##일 때 [MASK] 전 ##단 응 ##력을 나타낸 ##다. [MASK] ##되는 최대 전 ##단 ##응 ##력 값을 비교 ##하면 사 ##출 ##조건 A ##는 10. ##39 ##MP ##a ##, B ##는 12. ##7 ##3 ##MP ##a ##, C ##는 21 ##. ##83 ##MP [MASK] ##이 발생 ##한다. 사용 ##된 수 ##지의 최대 허 ##용 전 ##단 ##응 ##력 값 ##은 0. ##25 ##MP ##a 이다 ##. [MASK] ##출 ##조건 C ##의 경우 최대 허 ##용 전 ##단 ##응 ##력 ##값 이상 ##인 영역 [MASK] 가장 많 ##고, ##사 ##출 ##조건 A ##가 허 ##용 ##치 이상 [MASK] 영역 ##이 가장 적 ##게 나타났다. [SEP]\n",
      "I1120 16:06:43.863116 47619347533312 create_pretraining_data.py:151] tokens: [CLS] ##ivar ##s of Kentucky blue ##grass grown under [MASK] and natural conditions ##. G ##erm ##ination speed was compared as days to ger ##mination percentage of 50 ##, 65 and 80 ##%, respectively ##. Alternative and natural conditions represent alternative conditions of 8 ##- ##hr light ( ##9 00 AM ##17 00 PM ##) [MASK] 25 ##C and 16 ##- ##hr dark ( ##17 00 PM ##9 00 AM ##) at 15 ##C and natural environmental conditions at [MASK] room temperature of 5 to 23 ##C ##, respectively ##. 켄 ##터 [MASK] 블 ##루 ##그 ##래 ##스 종 ##자의 50% 발 ##아 ##세는 Blacks ##burg II 및 Voyager II 품 ##종 ##을 [MASK] ##한 대부분 품 ##종의 경우 IS ##TA 변 ##온 환경 ##에서는 11일 전 ##후 ##로 나타났다. 하지만 자연 실 ##온 환경 ##에서는 이 ##보다 느 ##린 15일 전 ##후 ##로 나타났다. 즉 켄 ##터 ##키 블 ##루 ##그 ##래 ##스 종 ##자를 IS ##TA 변 ##온 ##과 유사 ##한 적 ##기에 파 ##종 ##할 경우 50% 발 ##아 ##세는 생 ##육 ##환경 ##이 다 ##소 불 ##리 ##한 시 ##기에 파 [MASK] 하는 것 ##보다 평균 4일 정도 더 빠 ##른 것을 의미 ##한다. 전체 15 종 ##류의 공 ##시 품 ##종 중 특히 Voyager II 품 ##종 ##은 예 ##외 [MASK] 발 ##아 ##속 ##도가 늦 ##어 ##서 IS ##TA 변 ##온 ##에서는 21 ##. ##6 ##8 ##일 ##, 자연 실 ##온 ##에서는 20. ##7 [MASK] ##일 정도로 나타났다. 즉 다른 품 ##종 ##에 비해 Voyager II 품 ##종 ##은 50% [MASK] ##아 ##세가 평균 510 ##일 정도 더 늦 ##는 것을 의미 ##한다. 한 ##지 ##형 계 ##통 ##인 켄 ##터 ##키 블 ##루 ##그 ##래 ##스의 경우 줄 [MASK] ##생 ##장의 생 ##육 ##적 ##온 ##이 1624 ##C ##이기 때문에 이와 좀 더 유사 ##한 환경 ##조건 ##인 IS ##TA 변 ##온 ##에 가 ##까 ##울 ##수록 유 ##묘 [SEP] [MASK] 7 ##. Solid ##ification zone [MASK] occurs when fill ##ing ##( ##a ##) injection condition A ( ##b ##) injection condition B ##( ##c ##) injection condition C3 ##. ##1. ##5 전 ##단 ##응 ##력 ##과 전 ##단 ##률 ##전 ##단 ##응 ##력 ##과 전 ##단 ##률 ##은 수 ##지 ##마다 가지고 있는 최대 [MASK] ##용 ##치를 초 ##과 ##할 경우 수 ##지 자 ##체의 특성이 바 ##뀌 ##고 제품 표면 ##에 박 ##리가 발생 ##할 수 있다. 아 ##래 Fig. 8 ##( ##a ##)은 충 ##전 ##률 98 ##% ##일 때 [MASK] 전 ##단 응 ##력을 나타낸 ##다. [MASK] ##되는 최대 전 ##단 ##응 ##력 값을 비교 ##하면 사 ##출 ##조건 A ##는 10. ##39 ##MP ##a ##, B ##는 12. ##7 ##3 ##MP ##a ##, C ##는 21 ##. ##83 ##MP [MASK] ##이 발생 ##한다. 사용 ##된 수 ##지의 최대 허 ##용 전 ##단 ##응 ##력 값 ##은 0. ##25 ##MP ##a 이다 ##. [MASK] ##출 ##조건 C ##의 경우 최대 허 ##용 전 ##단 ##응 ##력 ##값 이상 ##인 영역 [MASK] 가장 많 ##고, ##사 ##출 ##조건 A ##가 허 ##용 ##치 이상 [MASK] 영역 ##이 가장 적 ##게 나타났다. [SEP]\n",
      "INFO:tensorflow:input_ids: 101 54072 10107 10108 19627 23254 87578 42527 10571 103 10111 13409 17315 110864 144 91724 64714 19085 10134 25626 10146 13990 10114 15554 41550 46971 10108 10462 110862 10843 10111 10832 119749 25179 110864 37520 10111 13409 17315 30382 22596 17315 10108 129 110863 16757 15765 113 11373 11025 24339 34264 11025 46161 110859 103 10258 10858 10111 10250 110863 16757 25100 113 34264 11025 46161 11373 11025 24339 110859 10160 10208 10858 10111 13409 32704 17315 10160 103 19555 23509 10108 126 10114 10328 10858 110862 25179 110864 9807 21876 103 9378 35866 78136 37388 12605 9684 42984 120267 9323 16985 93770 107375 12248 10335 9316 52442 10335 9938 22200 10622 103 11102 107153 9938 91393 28467 40214 24951 9352 37093 119606 23635 46986 9665 31531 11261 119588 32775 120002 9489 37093 119606 23635 9638 80001 9041 27654 37912 9665 31531 11261 119588 9701 9807 21876 21039 9378 35866 78136 37388 12605 9684 48959 40214 24951 9352 37093 11882 119754 11102 9664 33797 9901 22200 14843 28467 120267 9323 16985 93770 9420 83811 119764 10739 9056 22333 9368 12692 11102 9485 33797 9901 103 23969 8870 80001 119594 43494 107657 9074 9388 37819 21371 119614 119554 96567 10208 9684 89267 8896 14040 9938 22200 9694 39671 52442 10335 9938 22200 10892 9576 78705 103 9323 16985 43962 68516 9047 12965 12424 40214 24951 9352 37093 23635 10296 110864 11211 11396 18392 110862 120002 9489 37093 23635 120364 11305 103 18392 106593 119588 9701 19709 9938 22200 10530 100876 52442 10335 9938 22200 10892 120267 103 16985 101880 119594 34959 18392 107657 9074 9047 11018 21371 119614 119554 9954 12508 27506 8887 43022 12030 9807 21876 21039 9378 35866 78136 37388 49319 28467 9692 103 24017 83685 9420 83811 14801 37093 10739 44864 10858 120099 20729 104342 9682 9074 119754 11102 119606 119956 12030 40214 24951 9352 37093 10530 8843 118671 78123 119766 9625 118943 102 103 128 110864 53043 29748 15245 103 31136 10841 20241 10230 110858 10113 110859 91879 24713 138 113 10457 110859 91879 24713 139 110858 10350 110859 91879 24713 59768 110864 119589 11166 9665 24989 119187 28143 11882 9665 24989 88350 16617 24989 119187 28143 11882 9665 24989 88350 10892 9460 12508 101814 44270 13767 99405 103 24974 62672 9757 11882 14843 28467 9460 12508 9651 79025 120246 9318 118700 11664 119791 119867 10530 9319 44130 119568 14843 9460 119547 9519 37388 119603 129 110858 10113 119748 9770 16617 88350 12327 110855 18392 9137 103 9665 24989 9636 33975 119777 119549 103 24683 99405 9665 24989 119187 28143 119864 119572 38378 9405 52363 119956 138 11018 120197 120247 79936 10113 110862 139 11018 120234 11305 10884 79936 10113 110862 140 11018 10296 110864 68073 79936 103 10739 119568 119554 119550 13441 9460 73479 99405 9968 24974 9665 24989 119187 28143 8850 10892 119560 69168 79936 10113 30919 110864 103 52363 119956 140 10459 28467 99405 9968 24974 9665 24989 119187 28143 118611 66982 12030 119663 103 22224 9249 119563 12945 52363 119956 138 11287 9968 24974 18622 66982 103 119663 10739 22224 9664 14153 119588 102\n",
      "I1120 16:06:43.863437 47619347533312 create_pretraining_data.py:161] input_ids: 101 54072 10107 10108 19627 23254 87578 42527 10571 103 10111 13409 17315 110864 144 91724 64714 19085 10134 25626 10146 13990 10114 15554 41550 46971 10108 10462 110862 10843 10111 10832 119749 25179 110864 37520 10111 13409 17315 30382 22596 17315 10108 129 110863 16757 15765 113 11373 11025 24339 34264 11025 46161 110859 103 10258 10858 10111 10250 110863 16757 25100 113 34264 11025 46161 11373 11025 24339 110859 10160 10208 10858 10111 13409 32704 17315 10160 103 19555 23509 10108 126 10114 10328 10858 110862 25179 110864 9807 21876 103 9378 35866 78136 37388 12605 9684 42984 120267 9323 16985 93770 107375 12248 10335 9316 52442 10335 9938 22200 10622 103 11102 107153 9938 91393 28467 40214 24951 9352 37093 119606 23635 46986 9665 31531 11261 119588 32775 120002 9489 37093 119606 23635 9638 80001 9041 27654 37912 9665 31531 11261 119588 9701 9807 21876 21039 9378 35866 78136 37388 12605 9684 48959 40214 24951 9352 37093 11882 119754 11102 9664 33797 9901 22200 14843 28467 120267 9323 16985 93770 9420 83811 119764 10739 9056 22333 9368 12692 11102 9485 33797 9901 103 23969 8870 80001 119594 43494 107657 9074 9388 37819 21371 119614 119554 96567 10208 9684 89267 8896 14040 9938 22200 9694 39671 52442 10335 9938 22200 10892 9576 78705 103 9323 16985 43962 68516 9047 12965 12424 40214 24951 9352 37093 23635 10296 110864 11211 11396 18392 110862 120002 9489 37093 23635 120364 11305 103 18392 106593 119588 9701 19709 9938 22200 10530 100876 52442 10335 9938 22200 10892 120267 103 16985 101880 119594 34959 18392 107657 9074 9047 11018 21371 119614 119554 9954 12508 27506 8887 43022 12030 9807 21876 21039 9378 35866 78136 37388 49319 28467 9692 103 24017 83685 9420 83811 14801 37093 10739 44864 10858 120099 20729 104342 9682 9074 119754 11102 119606 119956 12030 40214 24951 9352 37093 10530 8843 118671 78123 119766 9625 118943 102 103 128 110864 53043 29748 15245 103 31136 10841 20241 10230 110858 10113 110859 91879 24713 138 113 10457 110859 91879 24713 139 110858 10350 110859 91879 24713 59768 110864 119589 11166 9665 24989 119187 28143 11882 9665 24989 88350 16617 24989 119187 28143 11882 9665 24989 88350 10892 9460 12508 101814 44270 13767 99405 103 24974 62672 9757 11882 14843 28467 9460 12508 9651 79025 120246 9318 118700 11664 119791 119867 10530 9319 44130 119568 14843 9460 119547 9519 37388 119603 129 110858 10113 119748 9770 16617 88350 12327 110855 18392 9137 103 9665 24989 9636 33975 119777 119549 103 24683 99405 9665 24989 119187 28143 119864 119572 38378 9405 52363 119956 138 11018 120197 120247 79936 10113 110862 139 11018 120234 11305 10884 79936 10113 110862 140 11018 10296 110864 68073 79936 103 10739 119568 119554 119550 13441 9460 73479 99405 9968 24974 9665 24989 119187 28143 8850 10892 119560 69168 79936 10113 30919 110864 103 52363 119956 140 10459 28467 99405 9968 24974 9665 24989 119187 28143 118611 66982 12030 119663 103 22224 9249 119563 12945 52363 119956 138 11287 9968 24974 18622 66982 103 119663 10739 22224 9664 14153 119588 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.863709 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.863992 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 9 31 55 79 92 113 185 215 240 256 285 317 323 372 410 417 451 474 491 504\n",
      "I1120 16:06:43.864133 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 9 31 55 79 92 113 185 215 240 256 285 317 323 372 410 417 451 474 491 504\n",
      "INFO:tensorflow:masked_lm_ids: 22596 10832 10160 10105 21039 119970 22200 17022 11396 9323 12310 119603 10189 9968 10459 119564 10113 9405 10739 12030\n",
      "I1120 16:06:43.864248 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 22596 10832 10160 10105 21039 119970 22200 17022 11396 9323 12310 119603 10189 9968 10459 119564 10113 9405 10739 12030\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.864358 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "I1120 16:06:43.864462 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.865603 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 보통 자동 ##차 ##에서는 앞 ##쪽에 있는 기 ##관 ##, 클 ##러 ##치 ##, 변 ##속 ##기 등에서 [MASK] 차 ##축 ##에 회 ##전 ##력을 전 ##달 ##하는 축 ##을 말한다 ##. 중 ##공 ##( ) 강 ##관 ##이 사용 ##되며 ##, 뒤 차 ##축 ##은 스 ##프 ##링 ##으로 지 [MASK] ##되어 상 ##하 ##로 움 ##직 ##이 ##므로 ##, 보통 전 ##후 2 ##개 [MASK] ##에 만 ##능 [MASK] ##음을 가진 ##다. [SEP] ##저 ##항 구현 ##이 가능 ##하기 때문에 고 ##전 ##류 ##, 고 ##전 ##압 ##을 필요 ##로 하는 전 ##력 ##반 ##도 ##체 소 ##자 ##에 적용 ##하기 적합 ##한 물 ##질 ##이라 ##고 볼 수 있다 1 3 . 현재 전 ##력 ##반 ##도 ##체 소 ##자의 주 ##贻 이루 ##고 있는 I ##GB ##T ##나 파 ##워 MO ##SF ##ET ##을 대 ##체 ##하여 전 ##력 ##반 ##도 ##체 소 ##자의 효율 ##을 극 ##대 ##화 ##시키 ##기 위해 Al ##G ##a ##N ##/ ##G ##a ##N ##을 이용한 트 ##랜 ##지 ##스터 ##나 다 ##이 ##오 ##드 ##에 대한 연구가 전 ##세 ##계 ##적으로 활 ##발 ##히 진행 ##되고 ##있다 4 6 . ##A ##l [MASK] ##a movimientos ##/ ##G ##a ##N 이 ##종 ##접 ##합 기반 ##의 HF ##ET ##은 높은 항 ##복 ##전 [MASK] ##과 낮은 누 ##설 ##전 ##류 ##를 얻 ##기 위해 질 ##화 [MASK] ##륨 버 ##퍼 ##층 ##의 두 ##께 ##를 두 ##껍 ##게 성장 ##하거나 철 ##( ##F ##e ##)이나 탄 ##소 ##(C ##)가 도 ##핑 ##된 질 ##화 ##갈 ##륨 버 ##퍼 ##층 ##을 사용 ##하기도 한다 [MASK] 8 . 이와 같이 누 ##설 ##전 ##류 ##를 big ##이기 위해 에 ##피 ##텍 ##시 성장 기법 ##에 변화를 주 ##어 웨 ##이 ##퍼 성장 ##이 가능 ##하지만 ##, Al ##G ##a ##N ##/ ##G ##a ##N HF ##ET ##을 제작 ##하는데 있어서 여러 가지 공정 과정 중에 ##서 오 ##염 및 손 ##상 ##되는 부분 ##을 최소 ##화 하여 ##야 한다. 특히 ##, 트 ##랜 ##지 ##스터 ##의 낮은 온 [MASK] ##항 구현 ##을 위해 낮은 오 ##믹 ##접 ##촉 ##저 ##항 ##을 필요 ##로 하는 ##데, 이때 고 ##온 열 ##처리 공정 ##이 동 ##반 ##되고 이 ##로 인해 표면 손 ##상을 야 ##기 시 ##킨 ##다. 기 보고 ##된 논문 ##에 의 ##하면 열 ##처리 과정 ##에서 생성 ##된 트 ##랩 ##은 소 ##자 특성을 저 ##하 ##시키는 [MASK] ##인이 된다. [MASK] 해결 ##하기 위한 오 ##믹 고 ##온 열 ##처리 전 Si ##N ##x 박 ##막 등을 이용한 표면 패 ##시 ##베 [MASK] ##을 통해 표면 [MASK] [MASK] ##호 banda 고 ##온 열 ##처리 ##로 발생 ##할 수 있는 표면 ##손 ##상을 줄 ##이는 방법 ##, 즉, 선 표면 ##처리 공정 ##이 제안 [MASK] 바 있다 9 . 하지만, 선 표면 ##처리 공정 ##만 ##으로는 표면 손 ##상을 완전히 막 ##기에는 부족 ##하다 ##고 판단 ##되며 개선 ##을 필요 ##로 한다. 본 논문 ##에서는 고 ##온 열 ##처리 ##로 인해 손 ##상 ##된 표면 ##을 회 ##복 ##하기 위해 O ##2 플 ##라 ##즈 ##마 ##를 사용하여 형성 ##시 ##킨 산 [SEP]\n",
      "I1120 16:06:43.865906 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 보통 자동 ##차 ##에서는 앞 ##쪽에 있는 기 ##관 ##, 클 ##러 ##치 ##, 변 ##속 ##기 등에서 [MASK] 차 ##축 ##에 회 ##전 ##력을 전 ##달 ##하는 축 ##을 말한다 ##. 중 ##공 ##( ) 강 ##관 ##이 사용 ##되며 ##, 뒤 차 ##축 ##은 스 ##프 ##링 ##으로 지 [MASK] ##되어 상 ##하 ##로 움 ##직 ##이 ##므로 ##, 보통 전 ##후 2 ##개 [MASK] ##에 만 ##능 [MASK] ##음을 가진 ##다. [SEP] ##저 ##항 구현 ##이 가능 ##하기 때문에 고 ##전 ##류 ##, 고 ##전 ##압 ##을 필요 ##로 하는 전 ##력 ##반 ##도 ##체 소 ##자 ##에 적용 ##하기 적합 ##한 물 ##질 ##이라 ##고 볼 수 있다 1 3 . 현재 전 ##력 ##반 ##도 ##체 소 ##자의 주 ##贻 이루 ##고 있는 I ##GB ##T ##나 파 ##워 MO ##SF ##ET ##을 대 ##체 ##하여 전 ##력 ##반 ##도 ##체 소 ##자의 효율 ##을 극 ##대 ##화 ##시키 ##기 위해 Al ##G ##a ##N ##/ ##G ##a ##N ##을 이용한 트 ##랜 ##지 ##스터 ##나 다 ##이 ##오 ##드 ##에 대한 연구가 전 ##세 ##계 ##적으로 활 ##발 ##히 진행 ##되고 ##있다 4 6 . ##A ##l [MASK] ##a movimientos ##/ ##G ##a ##N 이 ##종 ##접 ##합 기반 ##의 HF ##ET ##은 높은 항 ##복 ##전 [MASK] ##과 낮은 누 ##설 ##전 ##류 ##를 얻 ##기 위해 질 ##화 [MASK] ##륨 버 ##퍼 ##층 ##의 두 ##께 ##를 두 ##껍 ##게 성장 ##하거나 철 ##( ##F ##e ##)이나 탄 ##소 ##(C ##)가 도 ##핑 ##된 질 ##화 ##갈 ##륨 버 ##퍼 ##층 ##을 사용 ##하기도 한다 [MASK] 8 . 이와 같이 누 ##설 ##전 ##류 ##를 big ##이기 위해 에 ##피 ##텍 ##시 성장 기법 ##에 변화를 주 ##어 웨 ##이 ##퍼 성장 ##이 가능 ##하지만 ##, Al ##G ##a ##N ##/ ##G ##a ##N HF ##ET ##을 제작 ##하는데 있어서 여러 가지 공정 과정 중에 ##서 오 ##염 및 손 ##상 ##되는 부분 ##을 최소 ##화 하여 ##야 한다. 특히 ##, 트 ##랜 ##지 ##스터 ##의 낮은 온 [MASK] ##항 구현 ##을 위해 낮은 오 ##믹 ##접 ##촉 ##저 ##항 ##을 필요 ##로 하는 ##데, 이때 고 ##온 열 ##처리 공정 ##이 동 ##반 ##되고 이 ##로 인해 표면 손 ##상을 야 ##기 시 ##킨 ##다. 기 보고 ##된 논문 ##에 의 ##하면 열 ##처리 과정 ##에서 생성 ##된 트 ##랩 ##은 소 ##자 특성을 저 ##하 ##시키는 [MASK] ##인이 된다. [MASK] 해결 ##하기 위한 오 ##믹 고 ##온 열 ##처리 전 Si ##N ##x 박 ##막 등을 이용한 표면 패 ##시 ##베 [MASK] ##을 통해 표면 [MASK] [MASK] ##호 banda 고 ##온 열 ##처리 ##로 발생 ##할 수 있는 표면 ##손 ##상을 줄 ##이는 방법 ##, 즉, 선 표면 ##처리 공정 ##이 제안 [MASK] 바 있다 9 . 하지만, 선 표면 ##처리 공정 ##만 ##으로는 표면 손 ##상을 완전히 막 ##기에는 부족 ##하다 ##고 판단 ##되며 개선 ##을 필요 ##로 한다. 본 논문 ##에서는 고 ##온 열 ##처리 ##로 인해 손 ##상 ##된 표면 ##을 회 ##복 ##하기 위해 O ##2 플 ##라 ##즈 ##마 ##를 사용하여 형성 ##시 ##킨 산 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 84097 120033 23466 23635 9531 84457 13767 8932 20595 110862 9836 30873 18622 110862 9352 43962 12310 120355 103 9730 70122 10530 9998 16617 33975 9665 89851 12178 9766 10622 52462 110864 9694 28000 110858 114 8853 20595 10739 119550 99265 110862 9109 9730 70122 10892 9477 28396 80174 11467 9706 103 16855 9414 35506 11261 9608 33077 10739 56460 110862 84097 9665 31531 123 21789 103 10530 9248 74986 103 59724 64722 119549 102 48387 50632 120101 10739 119609 22440 20729 8888 16617 46520 110862 8888 16617 119116 10622 119629 11261 23969 9665 28143 30134 12092 29683 9448 13764 10530 119564 22440 119880 11102 9299 48599 119671 11664 9359 9460 11506 122 124 119 26565 9665 28143 30134 12092 29683 9448 42984 9689 117266 120233 11664 13767 146 32469 11090 16439 9901 69592 102059 46378 52338 10622 9069 29683 13374 9665 28143 30134 12092 29683 9448 42984 119747 10622 8925 14423 18227 119761 12310 19905 10883 11447 10113 11537 110865 11447 10113 11537 10622 119728 9890 118856 12508 58823 16439 9056 10739 28188 15001 10530 18154 119778 9665 24982 21611 17022 9996 51431 18108 119625 29208 76820 125 127 119 10738 10161 103 10113 51804 110865 11447 10113 11537 9638 22200 119205 33188 119658 10459 82338 52338 10892 55600 9959 70915 16617 103 11882 119758 9032 31928 16617 46520 11513 9550 12310 19905 9709 18227 103 118900 9336 68984 70450 10459 9102 118683 11513 9102 118681 14153 120005 120054 9747 110858 11565 10112 120775 9847 22333 119936 120060 9087 119418 13441 9709 18227 101202 118900 9336 68984 70450 10622 119550 68100 16139 103 129 119 104342 38401 9032 31928 16617 46520 11513 22185 120099 19905 9559 97146 119352 14040 120005 119878 10530 120010 9689 12965 9615 10739 68984 120005 10739 119609 120140 110862 10883 11447 10113 11537 110865 11447 10113 11537 82338 52338 10622 104865 119885 90587 30085 69164 120037 119622 102246 12424 9580 119144 9316 9450 14871 24683 119725 10622 119890 18227 51076 21711 119575 39671 110862 9890 118856 12508 58823 10459 119758 9582 103 50632 120101 10622 19905 119758 9580 118956 119205 119267 48387 50632 10622 119629 11261 23969 119953 86838 8888 37093 9569 119775 120037 10739 9095 30134 29208 9638 11261 39629 119867 9450 33654 9538 12310 9485 119330 119549 8932 98199 13441 119691 10530 9637 38378 9569 119775 119622 11489 119786 13441 9890 118858 10892 9448 13764 119772 9663 35506 119950 103 56789 119684 103 119927 22440 28195 9580 118956 8888 37093 9569 119775 9665 11741 11537 10686 9319 118907 33727 119728 119867 9909 14040 92688 103 10622 25605 119867 103 103 20309 12274 8888 37093 9569 119775 11261 119568 14843 9460 13767 119867 119053 33654 9692 31728 119567 110862 119944 9428 119867 119775 120037 10739 119670 103 9318 11506 130 119 120321 9428 119867 119775 120037 19105 120103 119867 9450 33654 103995 9247 120370 120093 32679 11664 119797 99265 119744 10622 119629 11261 119575 9358 119691 23635 8888 37093 9569 119775 11261 39629 9450 14871 13441 119867 10622 9998 70915 22440 19905 152 10729 9944 17342 24891 23811 11513 119843 119799 14040 119330 9407 102\n",
      "I1120 16:06:43.866261 47619347533312 create_pretraining_data.py:161] input_ids: 101 84097 120033 23466 23635 9531 84457 13767 8932 20595 110862 9836 30873 18622 110862 9352 43962 12310 120355 103 9730 70122 10530 9998 16617 33975 9665 89851 12178 9766 10622 52462 110864 9694 28000 110858 114 8853 20595 10739 119550 99265 110862 9109 9730 70122 10892 9477 28396 80174 11467 9706 103 16855 9414 35506 11261 9608 33077 10739 56460 110862 84097 9665 31531 123 21789 103 10530 9248 74986 103 59724 64722 119549 102 48387 50632 120101 10739 119609 22440 20729 8888 16617 46520 110862 8888 16617 119116 10622 119629 11261 23969 9665 28143 30134 12092 29683 9448 13764 10530 119564 22440 119880 11102 9299 48599 119671 11664 9359 9460 11506 122 124 119 26565 9665 28143 30134 12092 29683 9448 42984 9689 117266 120233 11664 13767 146 32469 11090 16439 9901 69592 102059 46378 52338 10622 9069 29683 13374 9665 28143 30134 12092 29683 9448 42984 119747 10622 8925 14423 18227 119761 12310 19905 10883 11447 10113 11537 110865 11447 10113 11537 10622 119728 9890 118856 12508 58823 16439 9056 10739 28188 15001 10530 18154 119778 9665 24982 21611 17022 9996 51431 18108 119625 29208 76820 125 127 119 10738 10161 103 10113 51804 110865 11447 10113 11537 9638 22200 119205 33188 119658 10459 82338 52338 10892 55600 9959 70915 16617 103 11882 119758 9032 31928 16617 46520 11513 9550 12310 19905 9709 18227 103 118900 9336 68984 70450 10459 9102 118683 11513 9102 118681 14153 120005 120054 9747 110858 11565 10112 120775 9847 22333 119936 120060 9087 119418 13441 9709 18227 101202 118900 9336 68984 70450 10622 119550 68100 16139 103 129 119 104342 38401 9032 31928 16617 46520 11513 22185 120099 19905 9559 97146 119352 14040 120005 119878 10530 120010 9689 12965 9615 10739 68984 120005 10739 119609 120140 110862 10883 11447 10113 11537 110865 11447 10113 11537 82338 52338 10622 104865 119885 90587 30085 69164 120037 119622 102246 12424 9580 119144 9316 9450 14871 24683 119725 10622 119890 18227 51076 21711 119575 39671 110862 9890 118856 12508 58823 10459 119758 9582 103 50632 120101 10622 19905 119758 9580 118956 119205 119267 48387 50632 10622 119629 11261 23969 119953 86838 8888 37093 9569 119775 120037 10739 9095 30134 29208 9638 11261 39629 119867 9450 33654 9538 12310 9485 119330 119549 8932 98199 13441 119691 10530 9637 38378 9569 119775 119622 11489 119786 13441 9890 118858 10892 9448 13764 119772 9663 35506 119950 103 56789 119684 103 119927 22440 28195 9580 118956 8888 37093 9569 119775 9665 11741 11537 10686 9319 118907 33727 119728 119867 9909 14040 92688 103 10622 25605 119867 103 103 20309 12274 8888 37093 9569 119775 11261 119568 14843 9460 13767 119867 119053 33654 9692 31728 119567 110862 119944 9428 119867 119775 120037 10739 119670 103 9318 11506 130 119 120321 9428 119867 119775 120037 19105 120103 119867 9450 33654 103995 9247 120370 120093 32679 11664 119797 99265 119744 10622 119629 11261 119575 9358 119691 23635 8888 37093 9569 119775 11261 39629 9450 14871 13441 119867 10622 9998 70915 22440 19905 152 10729 9944 17342 24891 23811 11513 119843 119799 14040 119330 9407 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.866555 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.866850 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 19 52 67 71 125 194 196 214 227 264 274 337 397 400 422 426 427 429 445 453\n",
      "I1120 16:06:43.866987 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 19 52 67 71 125 194 196 214 227 264 274 337 397 400 422 426 427 429 445 453\n",
      "INFO:tensorflow:masked_lm_ids: 9109 12508 22333 9638 11513 11447 11537 119116 101202 128 9692 48387 9612 35756 90850 10622 9356 13374 110862 13441\n",
      "I1120 16:06:43.867129 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 9109 12508 22333 9638 11513 11447 11537 119116 101202 128 9692 48387 9612 35756 90850 10622 9356 13374 110862 13441\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.867238 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "I1120 16:06:43.867336 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.868396 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] ##체 방 ##어 ##기 ##전 등의 조절 ##에 관련 ##되어 있다. 분리 ##된 젖 ##산 ##균 ##을 대상으로 10 ##% 탈 ##지 ##분 ##유 ##에서 37 에서 24 ##시간 배 ##양 ##하여 응 ##고 ##된 균 ##주 ##만 선택 ##하여 면 ##역 [MASK] 측정 ##한 결과, L ##. ferme ##ntu [MASK] 450 균 ##주의 IL ##-1, TN ##F [MASK] ##, NO 값 ##이 각각 2 ##, ##500 pg 이상 ##/ ##m ##L ##, 2 ##, ##000 pg 이상 ##/ ##m ##L ##, 11. ##55 ##2. ##9 ##5 M ##으로 나타났 ##다( ##Table 1 ##). Cho 등 ##( ##2010 ##)에 따르면 상 ##업 ##균 ##주 인 L [MASK] [MASK] ##ntu ##m ATC ##C 1493 ##1 ##( ##10 ##8 CF ##U ##/ ##m [MASK] ##)의 [MASK] ##-1, TN ##F ##- [MASK] NO 값 ##이 각각 ##44 ##5. ##21 ##19 ##. ##8 ##7 g ##/ ##m ##L ##, 2 ##, ##21 ##9. ##42 ##8 ##1. ##57 g ##/ ##m ##L ##, 6. ##52 ##1. ##42 M ##로 나타 ##남 ##에 따라 [MASK] 본 연구에서 분리 ##된 L ##. ferme ##ntu ##m 450 균 ##주의 IL ##-1, NO 값 ##이 상 ##업 ##균 ##주 ##에 비해 분 ##비 ##능 ##이 높은 것으로 나타났다. Table 1. Effect of Lac ##to ##ba ##cil ##lus ferme ##ntu ##m 450 on the production of IL ##-1, TN ##F and NO in Raw 264 ##. ##7 cells ##3. 선 ##발 균 ##주의 [MASK] ##정 및 DNA sequence ##L ##. ferme ##ntu ##m 450 [MASK] ##주의 genus ##와 species ##를 결정 ##하기 위하여 생 ##리적 [SEP] ##나타내 ##었고 ##, 현 ##미 ##경 ##으로 ##관찰 ##시 ##R ##od 형태 ##의 ##heter ##o 균 ##이며, 산 ##소 [MASK] ##무 ##와 상관 ##없 ##이 잘 생 ##장 ##하였고, cat ##alas ##e ##와 운동 ##성은 음 ##성 ##으로 나타났다. 45 에서는 생 ##장 ##하나 ##, 15 에서 는 생 ##장 ##하지 않 ##았으며 ##, g ##lucose ##와 ar ##gini ##ne ##으로 ##부터 각각 gas 와 암 ##모 ##니아 [MASK] 생성 ##하지 않 ##아 genus Lac ##to ##ba ##cil ##lus ##에 속 ##하였다. Species ##를 정 ##하기 위하여 API 50 ##CH ##L kit ##( ##B ##io ##M ##ere ##ux ##, France ##) 를 이용하여 49 ##종의 당 발 ##효 시험 ##을 실시 ##한 결과 ##( ##Table 2 ##), L ##. ferme ##ntu ##m 450 균 ##주는 D ##- ##rib ##ose 등 13 ##종 ##으로 ##부터 산 ##을 생성 ##하였다. 그 결과를 AT ##B identification system ##에 입력 ##한 결과, Lac ##to ##ba ##cil ##lus ferme ##ntu [MASK] ##으로 판 ##명 ##되었으며 [MASK] 16 ##S r ##RNA 유 ##전 mamíferos 부분 ##을 universal primer ##를 이용한 PCR ##로 증 ##폭 ##하여 서 ##열 분석하였다. 분석 ##된 염 ##기 서 [MASK] ##을 그대로 이용하여 BL ##AS ##T search ##한 결과, Lac ##to ##ba ##cil ##lus ferme ##ntu ##m ##( ##I ##. D ##. 99 ##% ##)으로 동 [MASK] ##되었고 ##, [MASK] ##to ##ba ##cil ##lus ferme ##ntu ##m 450 ##으로 명 ##명 ##하였다 ##Table 2. Phys ##iological characteristics of Lac ##to ##ba ##cil ##lus ferme ##ntu ##m 450 ##Table 2. Conti ##nue ##d ##4. Lac ##to ##ba [SEP]\n",
      "I1120 16:06:43.868678 47619347533312 create_pretraining_data.py:151] tokens: [CLS] ##체 방 ##어 ##기 ##전 등의 조절 ##에 관련 ##되어 있다. 분리 ##된 젖 ##산 ##균 ##을 대상으로 10 ##% 탈 ##지 ##분 ##유 ##에서 37 에서 24 ##시간 배 ##양 ##하여 응 ##고 ##된 균 ##주 ##만 선택 ##하여 면 ##역 [MASK] 측정 ##한 결과, L ##. ferme ##ntu [MASK] 450 균 ##주의 IL ##-1, TN ##F [MASK] ##, NO 값 ##이 각각 2 ##, ##500 pg 이상 ##/ ##m ##L ##, 2 ##, ##000 pg 이상 ##/ ##m ##L ##, 11. ##55 ##2. ##9 ##5 M ##으로 나타났 ##다( ##Table 1 ##). Cho 등 ##( ##2010 ##)에 따르면 상 ##업 ##균 ##주 인 L [MASK] [MASK] ##ntu ##m ATC ##C 1493 ##1 ##( ##10 ##8 CF ##U ##/ ##m [MASK] ##)의 [MASK] ##-1, TN ##F ##- [MASK] NO 값 ##이 각각 ##44 ##5. ##21 ##19 ##. ##8 ##7 g ##/ ##m ##L ##, 2 ##, ##21 ##9. ##42 ##8 ##1. ##57 g ##/ ##m ##L ##, 6. ##52 ##1. ##42 M ##로 나타 ##남 ##에 따라 [MASK] 본 연구에서 분리 ##된 L ##. ferme ##ntu ##m 450 균 ##주의 IL ##-1, NO 값 ##이 상 ##업 ##균 ##주 ##에 비해 분 ##비 ##능 ##이 높은 것으로 나타났다. Table 1. Effect of Lac ##to ##ba ##cil ##lus ferme ##ntu ##m 450 on the production of IL ##-1, TN ##F and NO in Raw 264 ##. ##7 cells ##3. 선 ##발 균 ##주의 [MASK] ##정 및 DNA sequence ##L ##. ferme ##ntu ##m 450 [MASK] ##주의 genus ##와 species ##를 결정 ##하기 위하여 생 ##리적 [SEP] ##나타내 ##었고 ##, 현 ##미 ##경 ##으로 ##관찰 ##시 ##R ##od 형태 ##의 ##heter ##o 균 ##이며, 산 ##소 [MASK] ##무 ##와 상관 ##없 ##이 잘 생 ##장 ##하였고, cat ##alas ##e ##와 운동 ##성은 음 ##성 ##으로 나타났다. 45 에서는 생 ##장 ##하나 ##, 15 에서 는 생 ##장 ##하지 않 ##았으며 ##, g ##lucose ##와 ar ##gini ##ne ##으로 ##부터 각각 gas 와 암 ##모 ##니아 [MASK] 생성 ##하지 않 ##아 genus Lac ##to ##ba ##cil ##lus ##에 속 ##하였다. Species ##를 정 ##하기 위하여 API 50 ##CH ##L kit ##( ##B ##io ##M ##ere ##ux ##, France ##) 를 이용하여 49 ##종의 당 발 ##효 시험 ##을 실시 ##한 결과 ##( ##Table 2 ##), L ##. ferme ##ntu ##m 450 균 ##주는 D ##- ##rib ##ose 등 13 ##종 ##으로 ##부터 산 ##을 생성 ##하였다. 그 결과를 AT ##B identification system ##에 입력 ##한 결과, Lac ##to ##ba ##cil ##lus ferme ##ntu [MASK] ##으로 판 ##명 ##되었으며 [MASK] 16 ##S r ##RNA 유 ##전 mamíferos 부분 ##을 universal primer ##를 이용한 PCR ##로 증 ##폭 ##하여 서 ##열 분석하였다. 분석 ##된 염 ##기 서 [MASK] ##을 그대로 이용하여 BL ##AS ##T search ##한 결과, Lac ##to ##ba ##cil ##lus ferme ##ntu ##m ##( ##I ##. D ##. 99 ##% ##)으로 동 [MASK] ##되었고 ##, [MASK] ##to ##ba ##cil ##lus ferme ##ntu ##m 450 ##으로 명 ##명 ##하였다 ##Table 2. Phys ##iological characteristics of Lac ##to ##ba ##cil ##lus ferme ##ntu ##m 450 ##Table 2. Conti ##nue ##d ##4. Lac ##to ##ba [SEP]\n",
      "INFO:tensorflow:input_ids: 101 29683 9328 12965 12310 16617 28697 120032 10530 86080 16855 119547 120095 13441 9671 21386 77692 10622 119640 10150 110855 9848 12508 37712 42815 11489 11204 24178 10233 100699 9330 37114 13374 9636 11664 13441 8923 16323 19105 119756 13374 9279 23160 103 119559 11102 119891 149 110864 50755 40468 103 16718 8923 37224 37817 120515 63626 11565 103 110862 49307 8850 10739 63042 123 110862 120372 42302 66982 110865 10147 11369 110862 123 110862 77802 42302 66982 110865 10147 11369 110862 120239 99555 119562 11373 11166 150 11467 119660 119576 119599 122 119558 50690 9121 110858 63704 119716 59355 9414 26784 77692 16323 9640 149 103 103 40468 10147 102093 10858 42358 10759 110858 20305 11396 29551 12022 110865 10147 103 119592 103 120515 63626 11565 110863 103 49307 8850 10739 63042 98041 119801 47499 54055 110864 11396 11305 175 110865 10147 11369 110862 123 110862 47499 120087 91147 11396 119589 89156 175 110865 10147 11369 110862 119989 92161 119589 91147 150 11261 119965 37004 10530 22799 103 9358 119674 120095 13441 149 110864 50755 40468 10147 16718 8923 37224 37817 120515 49307 8850 10739 9414 26784 77692 16323 10530 100876 9367 29455 74986 10739 55600 23925 119588 34421 119590 61201 10108 12602 10340 10537 34128 14075 50755 40468 10147 16718 10135 10105 12116 10108 37817 120515 63626 11565 10111 49307 10106 30712 25356 110864 11305 23182 119573 9428 51431 8923 37224 103 16605 9316 15517 30265 11369 110864 50755 40468 10147 16718 103 37224 10620 12638 10542 11513 119688 22440 68010 9420 119813 102 121893 48754 110862 9978 22458 31720 11467 120598 14040 11273 12680 119652 10459 33926 10133 8923 119841 9407 22333 103 32537 12638 120127 119136 10739 9654 9420 13890 119773 41163 109088 10112 12638 119899 107442 9634 17138 11467 119588 10827 120275 9420 13890 120328 110862 10208 24178 9043 9420 13890 23665 9523 103561 110862 175 103645 12638 10456 54497 10238 11467 17655 63042 16091 9590 9526 39420 51533 103 119786 23665 9523 16985 10620 12602 10340 10537 34128 14075 10530 9449 119548 10300 11513 9670 22440 68010 45187 10462 86448 11369 72812 110858 11274 10638 11517 12122 11855 110862 10688 110859 9233 119593 11580 91393 9067 9323 119449 119733 10622 119632 11102 85533 110858 119599 123 119557 149 110864 50755 40468 10147 16718 8923 100633 141 110863 47116 14569 9121 10249 22200 11467 17655 9407 10622 119786 119548 8924 119639 30554 11274 38877 11787 10530 120063 11102 119891 12602 10340 10537 34128 14075 50755 40468 103 11467 9903 16758 55835 103 10250 10731 186 83931 9625 16617 76604 119725 10622 29865 11501 11513 119728 99422 11261 9705 119400 13374 9425 79604 120012 119552 13441 9570 12310 9425 103 10622 110589 119593 102549 38025 11090 22419 11102 119891 12602 10340 10537 34128 14075 50755 40468 10147 110858 11281 110864 141 110864 12187 110855 119991 9095 103 49953 110862 103 10340 10537 34128 14075 50755 40468 10147 16718 11467 9281 16758 12609 119599 119616 53658 96522 40582 10108 12602 10340 10537 34128 14075 50755 40468 10147 16718 119599 119616 68918 84709 10162 119619 12602 10340 10537 102\n",
      "I1120 16:06:43.871540 47619347533312 create_pretraining_data.py:161] input_ids: 101 29683 9328 12965 12310 16617 28697 120032 10530 86080 16855 119547 120095 13441 9671 21386 77692 10622 119640 10150 110855 9848 12508 37712 42815 11489 11204 24178 10233 100699 9330 37114 13374 9636 11664 13441 8923 16323 19105 119756 13374 9279 23160 103 119559 11102 119891 149 110864 50755 40468 103 16718 8923 37224 37817 120515 63626 11565 103 110862 49307 8850 10739 63042 123 110862 120372 42302 66982 110865 10147 11369 110862 123 110862 77802 42302 66982 110865 10147 11369 110862 120239 99555 119562 11373 11166 150 11467 119660 119576 119599 122 119558 50690 9121 110858 63704 119716 59355 9414 26784 77692 16323 9640 149 103 103 40468 10147 102093 10858 42358 10759 110858 20305 11396 29551 12022 110865 10147 103 119592 103 120515 63626 11565 110863 103 49307 8850 10739 63042 98041 119801 47499 54055 110864 11396 11305 175 110865 10147 11369 110862 123 110862 47499 120087 91147 11396 119589 89156 175 110865 10147 11369 110862 119989 92161 119589 91147 150 11261 119965 37004 10530 22799 103 9358 119674 120095 13441 149 110864 50755 40468 10147 16718 8923 37224 37817 120515 49307 8850 10739 9414 26784 77692 16323 10530 100876 9367 29455 74986 10739 55600 23925 119588 34421 119590 61201 10108 12602 10340 10537 34128 14075 50755 40468 10147 16718 10135 10105 12116 10108 37817 120515 63626 11565 10111 49307 10106 30712 25356 110864 11305 23182 119573 9428 51431 8923 37224 103 16605 9316 15517 30265 11369 110864 50755 40468 10147 16718 103 37224 10620 12638 10542 11513 119688 22440 68010 9420 119813 102 121893 48754 110862 9978 22458 31720 11467 120598 14040 11273 12680 119652 10459 33926 10133 8923 119841 9407 22333 103 32537 12638 120127 119136 10739 9654 9420 13890 119773 41163 109088 10112 12638 119899 107442 9634 17138 11467 119588 10827 120275 9420 13890 120328 110862 10208 24178 9043 9420 13890 23665 9523 103561 110862 175 103645 12638 10456 54497 10238 11467 17655 63042 16091 9590 9526 39420 51533 103 119786 23665 9523 16985 10620 12602 10340 10537 34128 14075 10530 9449 119548 10300 11513 9670 22440 68010 45187 10462 86448 11369 72812 110858 11274 10638 11517 12122 11855 110862 10688 110859 9233 119593 11580 91393 9067 9323 119449 119733 10622 119632 11102 85533 110858 119599 123 119557 149 110864 50755 40468 10147 16718 8923 100633 141 110863 47116 14569 9121 10249 22200 11467 17655 9407 10622 119786 119548 8924 119639 30554 11274 38877 11787 10530 120063 11102 119891 12602 10340 10537 34128 14075 50755 40468 103 11467 9903 16758 55835 103 10250 10731 186 83931 9625 16617 76604 119725 10622 29865 11501 11513 119728 99422 11261 9705 119400 13374 9425 79604 120012 119552 13441 9570 12310 9425 103 10622 110589 119593 102549 38025 11090 22419 11102 119891 12602 10340 10537 34128 14075 50755 40468 10147 110858 11281 110864 141 110864 12187 110855 119991 9095 103 49953 110862 103 10340 10537 34128 14075 50755 40468 10147 16718 11467 9281 16758 12609 119599 119616 53658 96522 40582 10108 12602 10340 10537 34128 14075 50755 40468 10147 16718 119599 119616 68918 84709 10162 119619 12602 10340 10537 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.871865 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.872150 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 43 51 59 107 108 122 124 129 169 234 245 276 325 367 412 417 424 444 471 474\n",
      "I1120 16:06:43.872287 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 43 51 59 107 108 122 124 129 169 234 245 276 325 367 412 417 424 444 471 474\n",
      "INFO:tensorflow:masked_lm_ids: 120665 10147 110863 110864 50755 11369 37817 110862 110862 9095 8923 9625 11513 119632 10147 110862 13764 79604 16605 12602\n",
      "I1120 16:06:43.872409 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 120665 10147 110863 110864 50755 11369 37817 110862 110862 9095 8923 9625 11513 119632 10147 110862 13764 79604 16605 12602\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.872522 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "I1120 16:06:43.872628 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.873740 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 소 ##득 ##은 200 ##만 ##원 이상 ##이 88 ##. ##7 ##%로 199 ##만 ##원 이하 11. ##3 ##% ##보다 많은 분포 ##를 차 ##지 ##하였다. 정 ##기 ##적 구 ##강 ##검 ##진 여 ##부는 없다 ##가 71 ##. ##4 ##%로 있다 28 ##. ##6 ##% ##보다 많은 것으로 나타났 ##고, 구 ##강 ##보 ##건 ##교육 ##경험 여 ##부는 안 받은 그 ##룹 ##이 66 ##. ##8 ##%로 받은 그 ##룹 33 ##. ##2 ##% ##보다 많 ##았다. 건강 ##보 ##험 치 ##석 ##제거 경험 ##여 ##부는 있다 23 ##. ##5% ##보다 없다 ##가 76 ##. ##5% ##로 더 많 ##았다. 연구 ##대상 ##자의 건강 ##보 [MASK] 치 ##석 ##제거 수 ##진 의 ##향 ##은 성 ##별 ##, 정 ##기 ##적 구 ##강 ##검 ##진 ##여 ##부 ##, 구 ##강 ##보 ##건 ##교육 경험 ##여 ##부 ##, 건강 [MASK] ##험 치 [MASK] ##제거 경험 ##여 ##부에 ##서 통계 ##적으로 유의미 ##한 [MASK] 있었다. 이 ##중 여자 ##가 남자 ##보다 수 ##진 의 ##향 ##이 높 ##았다. 정 ##기 ##적 구 ##강 ##검 ##진 ##을 받 ##는 경우, [MASK] ##강 ##보 ##건 ##교육 경험 ##이 있는 경우, 건강 ##보 ##험 치 ##석 ##제거 경험 ##이 있는 경우가 경험 ##이 없는 경우 [MASK] 수 ##진 의 ##향 ##이 높게 나타났 ##다( ##Table 1 ##). ##Table 1. ##V ##alu ##es are presented as n ( ##% ##). K ##R ##W Korean Won ##. [SEP] ##- ##val ##ue was calculated by chi ##- ##s ##qua ##re test ##. ##2. 건강 ##보 ##험 치 [MASK] ##제거 ##에 대한 개선 [MASK] 및 인식 ##건강 ##보 ##험 치 ##석 ##제거 ##에 대한 개선 ##점 ##은 연 ##간 ##횟 ##수가 42 ##. ##9 ##%로 가장 많 [MASK] ##, 본 ##인 ##부 ##담 ##금 31 ##. ##5%, 연령 제한 13. ##4 ##%, 후 ##속 치료 ##제한 12. ##2 [MASK] 순 ##이었다. 건강 ##보 ##험 [MASK] ##석 ##제거 ##에 대한 인지 ##도는 보통 ##이다 ##가 41 ##. ##2 ##%로 많 ##았고 ##, 건강 ##보 ##험 치 ##석 ##제거 제 ##도에 대한 지 ##지 ##도는 그 ##렇 ##다가 46 ##. ##6 ##%로 가장 많은 분포 ##를 차 ##지 ##하였다. 정보 ##습 ##득 ##의 경 ##로는 인터 basado TV ##가 47 ##. ##2 ##%로 가장 많은 분포 ##를 [MASK] ##지 ##하였으며, 건강 ##보 ##험 치 ##석 ##제거 ##를 받 ##지 ##않은 이유 ##는 시간 ##이 없 ##어 ##서 ##가 walks ##. [MASK] ##로 가장 많 ##았다 ##( ##Table 2 ##). ##Table 2. ##a ##R ##esu ##lts of multiple response ##. ##3. 건강 ##보 ##험 치 ##석 ##제거 수 ##진 ##에 영향을 미치는 요인 ##로 ##지 ##스 ##틱 다 ##중 ##회 ##귀 ##분석 결과 Model I ##에서 성 ##별 ##, 소 ##득 ##, 정 ##기 ##적 구 ##강 ##검 ##진 ##여 ##부 ##, 구 ##강 ##보 ##건 ##교육 ##여 ##부 ##, 건강 ##보 ##험 치 ##석 ##제거 경험 ##여 ##부가 유의미 ##한 영향을 미치는 것으로 나타났 ##고 변수를 [MASK] ##정한 Model II ##에서 소 ##득 ##, 건강 ##보 ##험 치 ##석 ##제거 경험 ##여 ##부 ##, 정 ##기 ##적 구 ##강 ##검 ##진 ##여 ##부가 건강 ##보 ##험 치 ##석 ##제거 수 ##진 [SEP]\n",
      "I1120 16:06:43.874041 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 소 ##득 ##은 200 ##만 ##원 이상 ##이 88 ##. ##7 ##%로 199 ##만 ##원 이하 11. ##3 ##% ##보다 많은 분포 ##를 차 ##지 ##하였다. 정 ##기 ##적 구 ##강 ##검 ##진 여 ##부는 없다 ##가 71 ##. ##4 ##%로 있다 28 ##. ##6 ##% ##보다 많은 것으로 나타났 ##고, 구 ##강 ##보 ##건 ##교육 ##경험 여 ##부는 안 받은 그 ##룹 ##이 66 ##. ##8 ##%로 받은 그 ##룹 33 ##. ##2 ##% ##보다 많 ##았다. 건강 ##보 ##험 치 ##석 ##제거 경험 ##여 ##부는 있다 23 ##. ##5% ##보다 없다 ##가 76 ##. ##5% ##로 더 많 ##았다. 연구 ##대상 ##자의 건강 ##보 [MASK] 치 ##석 ##제거 수 ##진 의 ##향 ##은 성 ##별 ##, 정 ##기 ##적 구 ##강 ##검 ##진 ##여 ##부 ##, 구 ##강 ##보 ##건 ##교육 경험 ##여 ##부 ##, 건강 [MASK] ##험 치 [MASK] ##제거 경험 ##여 ##부에 ##서 통계 ##적으로 유의미 ##한 [MASK] 있었다. 이 ##중 여자 ##가 남자 ##보다 수 ##진 의 ##향 ##이 높 ##았다. 정 ##기 ##적 구 ##강 ##검 ##진 ##을 받 ##는 경우, [MASK] ##강 ##보 ##건 ##교육 경험 ##이 있는 경우, 건강 ##보 ##험 치 ##석 ##제거 경험 ##이 있는 경우가 경험 ##이 없는 경우 [MASK] 수 ##진 의 ##향 ##이 높게 나타났 ##다( ##Table 1 ##). ##Table 1. ##V ##alu ##es are presented as n ( ##% ##). K ##R ##W Korean Won ##. [SEP] ##- ##val ##ue was calculated by chi ##- ##s ##qua ##re test ##. ##2. 건강 ##보 ##험 치 [MASK] ##제거 ##에 대한 개선 [MASK] 및 인식 ##건강 ##보 ##험 치 ##석 ##제거 ##에 대한 개선 ##점 ##은 연 ##간 ##횟 ##수가 42 ##. ##9 ##%로 가장 많 [MASK] ##, 본 ##인 ##부 ##담 ##금 31 ##. ##5%, 연령 제한 13. ##4 ##%, 후 ##속 치료 ##제한 12. ##2 [MASK] 순 ##이었다. 건강 ##보 ##험 [MASK] ##석 ##제거 ##에 대한 인지 ##도는 보통 ##이다 ##가 41 ##. ##2 ##%로 많 ##았고 ##, 건강 ##보 ##험 치 ##석 ##제거 제 ##도에 대한 지 ##지 ##도는 그 ##렇 ##다가 46 ##. ##6 ##%로 가장 많은 분포 ##를 차 ##지 ##하였다. 정보 ##습 ##득 ##의 경 ##로는 인터 basado TV ##가 47 ##. ##2 ##%로 가장 많은 분포 ##를 [MASK] ##지 ##하였으며, 건강 ##보 ##험 치 ##석 ##제거 ##를 받 ##지 ##않은 이유 ##는 시간 ##이 없 ##어 ##서 ##가 walks ##. [MASK] ##로 가장 많 ##았다 ##( ##Table 2 ##). ##Table 2. ##a ##R ##esu ##lts of multiple response ##. ##3. 건강 ##보 ##험 치 ##석 ##제거 수 ##진 ##에 영향을 미치는 요인 ##로 ##지 ##스 ##틱 다 ##중 ##회 ##귀 ##분석 결과 Model I ##에서 성 ##별 ##, 소 ##득 ##, 정 ##기 ##적 구 ##강 ##검 ##진 ##여 ##부 ##, 구 ##강 ##보 ##건 ##교육 ##여 ##부 ##, 건강 ##보 ##험 치 ##석 ##제거 경험 ##여 ##부가 유의미 ##한 영향을 미치는 것으로 나타났 ##고 변수를 [MASK] ##정한 Model II ##에서 소 ##득 ##, 건강 ##보 ##험 치 ##석 ##제거 경험 ##여 ##부 ##, 정 ##기 ##적 구 ##강 ##검 ##진 ##여 ##부가 건강 ##보 ##험 치 ##석 ##제거 수 ##진 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 9448 118813 10892 10777 19105 14279 66982 10739 12074 110864 11305 119910 23366 19105 14279 120052 120239 10884 110855 80001 25685 119785 11513 9730 12508 119548 9670 12310 14801 8908 47181 118625 18623 9565 58904 39218 11287 12513 110864 11011 119910 11506 10348 110864 11211 110855 80001 25685 23925 119660 119563 8908 47181 30005 71439 119696 120215 9565 58904 9521 74141 8924 87114 10739 12215 110864 11396 119910 74141 8924 87114 11000 110864 10729 110855 80001 9249 119662 119681 30005 86834 9779 40958 120562 119698 29935 58904 11506 10328 110864 119872 80001 39218 11287 12428 110864 119872 11261 9074 9249 119662 91785 119845 42984 119681 30005 103 9779 40958 120562 9460 18623 9637 79544 10892 9434 61844 110862 9670 12310 14801 8908 47181 118625 18623 29935 14646 110862 8908 47181 30005 71439 119696 119698 29935 14646 110862 119681 103 86834 9779 103 120562 119698 29935 52961 12424 119709 17022 120176 11102 103 119659 9638 41693 62592 11287 76854 80001 9460 18623 9637 79544 10739 9028 119662 9670 12310 14801 8908 47181 118625 18623 10622 9322 11018 119913 103 47181 30005 71439 119696 119698 10739 13767 119913 119681 30005 86834 9779 40958 120562 119698 10739 13767 108462 119698 10739 40364 28467 103 9460 18623 9637 79544 10739 119886 119660 119576 119599 122 119558 119599 119590 11779 45532 10171 10301 20027 10146 182 113 110855 119558 148 11273 13034 20501 36939 110864 102 110863 12234 12772 10134 87382 10155 14325 110863 10107 32973 10246 15839 110864 119562 119681 30005 86834 9779 103 120562 10530 18154 119744 103 9316 119644 120126 30005 86834 9779 40958 120562 10530 18154 119744 34907 10892 9568 18784 119447 73894 11276 110864 11373 119910 22224 9249 103 110862 9358 12030 14646 105462 40032 10413 110864 120359 120020 120042 120294 11011 119749 10003 43962 119807 120403 120234 10729 103 9462 120107 119681 30005 86834 103 40958 120562 10530 18154 119870 60884 84097 11925 11287 11349 110864 10729 119910 9249 77172 110862 119681 30005 86834 9779 40958 120562 9672 108521 18154 9706 12508 60884 8924 118871 80244 11528 110864 11211 119910 22224 25685 119785 11513 9730 12508 119548 119596 119081 118813 10459 8885 70186 119914 55560 10813 11287 11413 110864 10729 119910 22224 25685 119785 11513 103 12508 119654 119681 30005 86834 9779 40958 120562 11513 9322 12508 121487 120076 11018 119612 10739 9555 12965 12424 11287 106216 110864 103 11261 22224 9249 27303 110858 119599 123 119558 119599 119616 10113 11273 78448 72847 10108 19865 21001 110864 119573 119681 30005 86834 9779 40958 120562 9460 18623 10530 58088 119610 119602 11261 12508 12605 119375 9056 41693 14863 118661 119665 85533 14398 146 11489 9434 61844 110862 9448 118813 110862 9670 12310 14801 8908 47181 118625 18623 29935 14646 110862 8908 47181 30005 71439 119696 29935 14646 110862 119681 30005 86834 9779 40958 120562 119698 29935 81896 120176 11102 58088 119610 23925 119660 11664 120381 103 59456 14398 10335 11489 9448 118813 110862 119681 30005 86834 9779 40958 120562 119698 29935 14646 110862 9670 12310 14801 8908 47181 118625 18623 29935 81896 119681 30005 86834 9779 40958 120562 9460 18623 102\n",
      "I1120 16:06:43.874381 47619347533312 create_pretraining_data.py:161] input_ids: 101 9448 118813 10892 10777 19105 14279 66982 10739 12074 110864 11305 119910 23366 19105 14279 120052 120239 10884 110855 80001 25685 119785 11513 9730 12508 119548 9670 12310 14801 8908 47181 118625 18623 9565 58904 39218 11287 12513 110864 11011 119910 11506 10348 110864 11211 110855 80001 25685 23925 119660 119563 8908 47181 30005 71439 119696 120215 9565 58904 9521 74141 8924 87114 10739 12215 110864 11396 119910 74141 8924 87114 11000 110864 10729 110855 80001 9249 119662 119681 30005 86834 9779 40958 120562 119698 29935 58904 11506 10328 110864 119872 80001 39218 11287 12428 110864 119872 11261 9074 9249 119662 91785 119845 42984 119681 30005 103 9779 40958 120562 9460 18623 9637 79544 10892 9434 61844 110862 9670 12310 14801 8908 47181 118625 18623 29935 14646 110862 8908 47181 30005 71439 119696 119698 29935 14646 110862 119681 103 86834 9779 103 120562 119698 29935 52961 12424 119709 17022 120176 11102 103 119659 9638 41693 62592 11287 76854 80001 9460 18623 9637 79544 10739 9028 119662 9670 12310 14801 8908 47181 118625 18623 10622 9322 11018 119913 103 47181 30005 71439 119696 119698 10739 13767 119913 119681 30005 86834 9779 40958 120562 119698 10739 13767 108462 119698 10739 40364 28467 103 9460 18623 9637 79544 10739 119886 119660 119576 119599 122 119558 119599 119590 11779 45532 10171 10301 20027 10146 182 113 110855 119558 148 11273 13034 20501 36939 110864 102 110863 12234 12772 10134 87382 10155 14325 110863 10107 32973 10246 15839 110864 119562 119681 30005 86834 9779 103 120562 10530 18154 119744 103 9316 119644 120126 30005 86834 9779 40958 120562 10530 18154 119744 34907 10892 9568 18784 119447 73894 11276 110864 11373 119910 22224 9249 103 110862 9358 12030 14646 105462 40032 10413 110864 120359 120020 120042 120294 11011 119749 10003 43962 119807 120403 120234 10729 103 9462 120107 119681 30005 86834 103 40958 120562 10530 18154 119870 60884 84097 11925 11287 11349 110864 10729 119910 9249 77172 110862 119681 30005 86834 9779 40958 120562 9672 108521 18154 9706 12508 60884 8924 118871 80244 11528 110864 11211 119910 22224 25685 119785 11513 9730 12508 119548 119596 119081 118813 10459 8885 70186 119914 55560 10813 11287 11413 110864 10729 119910 22224 25685 119785 11513 103 12508 119654 119681 30005 86834 9779 40958 120562 11513 9322 12508 121487 120076 11018 119612 10739 9555 12965 12424 11287 106216 110864 103 11261 22224 9249 27303 110858 119599 123 119558 119599 119616 10113 11273 78448 72847 10108 19865 21001 110864 119573 119681 30005 86834 9779 40958 120562 9460 18623 10530 58088 119610 119602 11261 12508 12605 119375 9056 41693 14863 118661 119665 85533 14398 146 11489 9434 61844 110862 9448 118813 110862 9670 12310 14801 8908 47181 118625 18623 29935 14646 110862 8908 47181 30005 71439 119696 29935 14646 110862 119681 30005 86834 9779 40958 120562 119698 29935 81896 120176 11102 58088 119610 23925 119660 11664 120381 103 59456 14398 10335 11489 9448 118813 110862 119681 30005 86834 9779 40958 120562 119698 29935 14646 110862 9670 12310 14801 8908 47181 118625 18623 29935 81896 119681 30005 86834 9779 40958 120562 9460 18623 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.874677 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.874966 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 75 107 139 142 152 168 178 201 250 255 279 292 300 306 356 367 388 390 476 496\n",
      "I1120 16:06:43.924038 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 75 107 139 142 152 168 178 201 250 255 279 292 300 306 356 367 388 390 476 496\n",
      "INFO:tensorflow:masked_lm_ids: 110855 86834 30005 40958 119694 12310 8908 80001 40958 34907 103561 11011 110855 9779 82881 9730 11303 119771 9356 14801\n",
      "I1120 16:06:43.924153 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 110855 86834 30005 40958 119694 12310 8908 80001 40958 34907 103561 11011 110855 9779 82881 9730 11303 119771 9356 14801\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.924267 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "I1120 16:06:43.924371 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.926162 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] [MASK] Product ##ive time per day is 6 [MASK] ##. [SEP] ##E ##om et al., 2010 ##)의 1일 작업 ##비용 400 ##, ##000 ##원 ##/ ##일 ##을 적용 ##한 단위 ##재 ##적 ##( [MASK] ##3) ##당 소 ##운 ##재 ##작업 ##의 비용 ##은 9 ##, ##39 ##4 ##원 ##/ ##m ##3 로 산출 ##되었다. 소 ##운 ##재 ##거 ##리 1. ##5 km ##에 해당 ##하는 굴 ##삭 ##기 그 ##래 ##플 및 소 ##운 ##재 ##용 트 ##럭 ##에 의한 소 ##운 ##재 및 집 ##적 ##작업 ##비용 ##은 굴 ##삭 ##기 그 ##래 ##플 ##에 [MASK] 상 ##차 ##작업 ##비용 ##과 소 ##운 ##재 ##용 트 ##럭 ##에 의한 소 ##운 [MASK] ##작업 ##비용 ##, 그리고 굴 ##삭 ##기 그 ##래 ##플 ##에 의한 집 ##적 ##작업 ##비용 ##의 합 ##으로 단위 ##재 ##적 ##( ##m ##3) ##당 약 21 ##, ##91 ##4 ##원 ##/ ##m ##3 ##으로 나타났다. ##2) 굴 ##삭 ##기 그 ##래 ##플 및 모 ##로 ##오 [MASK] 임 ##내 ##작업 ##차 ##에 의한 소 ##운 ##재 [MASK] ##비용 ##상 ##차 및 집 ##적 작업 ##에 사용 ##된 굴 [MASK] ##기 그 ##래 ##플 ##의 작업 ##비용 ##을 산출 ##하기 위해 사용 ##된 기초 ##인 ##자 및 산출 ##내 ##역 ##은 상 ##기 Table 4 ##와 같 ##고 모 ##로 ##오 ##카 임 ##내 ##작업 ##차 ##에 의한 소 ##운 ##재 ##작업 ##비용 ##을 산출 ##하기 위해 사용 [MASK] [MASK] ##인 ##자 및 산출 ##내 ##역 ##은 Table [MASK] ##와 같다. 산출 ##한 시간 ##당 비용 ##은 감 ##가 ##상 ##각 ##비 17 ##, ##400 ##원 ##/ ##hr ##, 이 ##자 ##비용 4 ##, ##35 ##0 ##원 ##/ ##hr ##, [MASK] ##리 ##유지 ##비 [MASK] ##, ##66 ##0 ##원 ##/ ##hr ##, 유 ##류 ##비 12 ##, ##04 ##5 ##원 ##/ ##hr ##, 인 ##건 ##비 19 ##, ##04 ##3 ##원 ##/ ##hr ##으로 나타났 ##으며, 모 ##로 ##오 ##카 [MASK] ##내 ##작업 ##차 ##의 작업 ##공정 ##은 9 ##. ##52 m ##3 ##/ ##hr ##으로 ##단위 ##재 ##적 ##( ##m ##3) ##당 소 ##운 ##재 ##작업 ##의 비용 ##은 7 ##, ##13 ##4 ##원 ##/ ##m ##3 ##로 산출 ##되었다. Table 5. Cal ##cula ##tion of operational cost for mini ##- ##for ##ward ##er ##N ##otes 1 ##) Product ##ive time per day is 6 hours [MASK] 2 ##) Forward ##ing distance [MASK] 1. ##5 km ##. 소 ##운 ##재 ##거 ##리 1. ##5 [MASK] ##에 해당 ##하는 굴 ##삭 ##기 그 ##래 ##플 및 모 ##로 ##오 ##카 임 ##내 ##작업 ##차 ##에 의한 소 ##운 ##재 및 집 ##적 ##작업 ##비용 ##은 굴 ##삭 ##기 그 ##래 ##플 ##에 의한 상 ##차 ##작업 ##비용 ##과 모 ##로 ##오 ##카 임 ##내 ##작업 ##차 ##에 의한 소 ##운 ##재 ##작업 ##비용 ##, 그리고 굴 ##삭 ##기 그 ##래 ##플 ##에 의한 집 ##적 ##작업 ##비용 ##의 합 ##으로 단위 ##재 ##적 ##( ##m ##3) ##당 약 16 ##, ##52 ##3 ##원 ##/ ##m ##3 ##으로 타 ##나 ##났다 ##. ##4. 파 ##쇄 ##작업 ##비용 분석 ##1) 소 ##형 목 ##재 ##파 [MASK] ##기에 의한 [SEP]\n",
      "I1120 16:06:43.926732 47619347533312 create_pretraining_data.py:151] tokens: [CLS] [MASK] Product ##ive time per day is 6 [MASK] ##. [SEP] ##E ##om et al., 2010 ##)의 1일 작업 ##비용 400 ##, ##000 ##원 ##/ ##일 ##을 적용 ##한 단위 ##재 ##적 ##( [MASK] ##3) ##당 소 ##운 ##재 ##작업 ##의 비용 ##은 9 ##, ##39 ##4 ##원 ##/ ##m ##3 로 산출 ##되었다. 소 ##운 ##재 ##거 ##리 1. ##5 km ##에 해당 ##하는 굴 ##삭 ##기 그 ##래 ##플 및 소 ##운 ##재 ##용 트 ##럭 ##에 의한 소 ##운 ##재 및 집 ##적 ##작업 ##비용 ##은 굴 ##삭 ##기 그 ##래 ##플 ##에 [MASK] 상 ##차 ##작업 ##비용 ##과 소 ##운 ##재 ##용 트 ##럭 ##에 의한 소 ##운 [MASK] ##작업 ##비용 ##, 그리고 굴 ##삭 ##기 그 ##래 ##플 ##에 의한 집 ##적 ##작업 ##비용 ##의 합 ##으로 단위 ##재 ##적 ##( ##m ##3) ##당 약 21 ##, ##91 ##4 ##원 ##/ ##m ##3 ##으로 나타났다. ##2) 굴 ##삭 ##기 그 ##래 ##플 및 모 ##로 ##오 [MASK] 임 ##내 ##작업 ##차 ##에 의한 소 ##운 ##재 [MASK] ##비용 ##상 ##차 및 집 ##적 작업 ##에 사용 ##된 굴 [MASK] ##기 그 ##래 ##플 ##의 작업 ##비용 ##을 산출 ##하기 위해 사용 ##된 기초 ##인 ##자 및 산출 ##내 ##역 ##은 상 ##기 Table 4 ##와 같 ##고 모 ##로 ##오 ##카 임 ##내 ##작업 ##차 ##에 의한 소 ##운 ##재 ##작업 ##비용 ##을 산출 ##하기 위해 사용 [MASK] [MASK] ##인 ##자 및 산출 ##내 ##역 ##은 Table [MASK] ##와 같다. 산출 ##한 시간 ##당 비용 ##은 감 ##가 ##상 ##각 ##비 17 ##, ##400 ##원 ##/ ##hr ##, 이 ##자 ##비용 4 ##, ##35 ##0 ##원 ##/ ##hr ##, [MASK] ##리 ##유지 ##비 [MASK] ##, ##66 ##0 ##원 ##/ ##hr ##, 유 ##류 ##비 12 ##, ##04 ##5 ##원 ##/ ##hr ##, 인 ##건 ##비 19 ##, ##04 ##3 ##원 ##/ ##hr ##으로 나타났 ##으며, 모 ##로 ##오 ##카 [MASK] ##내 ##작업 ##차 ##의 작업 ##공정 ##은 9 ##. ##52 m ##3 ##/ ##hr ##으로 ##단위 ##재 ##적 ##( ##m ##3) ##당 소 ##운 ##재 ##작업 ##의 비용 ##은 7 ##, ##13 ##4 ##원 ##/ ##m ##3 ##로 산출 ##되었다. Table 5. Cal ##cula ##tion of operational cost for mini ##- ##for ##ward ##er ##N ##otes 1 ##) Product ##ive time per day is 6 hours [MASK] 2 ##) Forward ##ing distance [MASK] 1. ##5 km ##. 소 ##운 ##재 ##거 ##리 1. ##5 [MASK] ##에 해당 ##하는 굴 ##삭 ##기 그 ##래 ##플 및 모 ##로 ##오 ##카 임 ##내 ##작업 ##차 ##에 의한 소 ##운 ##재 및 집 ##적 ##작업 ##비용 ##은 굴 ##삭 ##기 그 ##래 ##플 ##에 의한 상 ##차 ##작업 ##비용 ##과 모 ##로 ##오 ##카 임 ##내 ##작업 ##차 ##에 의한 소 ##운 ##재 ##작업 ##비용 ##, 그리고 굴 ##삭 ##기 그 ##래 ##플 ##에 의한 집 ##적 ##작업 ##비용 ##의 합 ##으로 단위 ##재 ##적 ##( ##m ##3) ##당 약 16 ##, ##52 ##3 ##원 ##/ ##m ##3 ##으로 타 ##나 ##났다 ##. ##4. 파 ##쇄 ##작업 ##비용 분석 ##1) 소 ##형 목 ##재 ##파 [MASK] ##기에 의한 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 103 93218 11942 10635 10178 11940 10124 127 103 110864 102 11259 10692 10131 119680 10175 119592 18329 119884 120147 11176 110862 77802 14279 110865 18392 10622 119564 11102 120057 36210 14801 110858 103 119740 21928 9448 21614 36210 120291 10459 120104 10892 130 110862 120247 11011 14279 110865 10147 10884 9202 120039 119582 9448 21614 36210 41521 12692 119590 11166 10204 10530 91621 12178 8912 119025 12310 8924 37388 119412 9316 9448 21614 36210 24974 9890 118864 10530 60804 9448 21614 36210 9316 9711 14801 120291 120147 10892 8912 119025 12310 8924 37388 119412 10530 103 9414 23466 120291 120147 11882 9448 21614 36210 24974 9890 118864 10530 60804 9448 21614 103 120291 120147 110862 23289 8912 119025 12310 8924 37388 119412 10530 60804 9711 14801 120291 120147 10459 9957 11467 120057 36210 14801 110858 10147 119740 21928 9539 10296 110862 74178 11011 14279 110865 10147 10884 11467 119588 119647 8912 119025 12310 8924 37388 119412 9316 9283 11261 28188 103 9644 31605 120291 23466 10530 60804 9448 21614 36210 103 120147 14871 23466 9316 9711 14801 119884 10530 119550 13441 8912 103 12310 8924 37388 119412 10459 119884 120147 10622 120039 22440 19905 119550 13441 119933 12030 13764 9316 120039 31605 23160 10892 9414 12310 34421 125 12638 8855 11664 9283 11261 28188 24206 9644 31605 120291 23466 10530 60804 9448 21614 36210 120291 120147 10622 120039 22440 19905 119550 103 103 12030 13764 9316 120039 31605 23160 10892 34421 103 12638 119655 120039 11102 119612 21928 120104 10892 8848 11287 14871 66540 29455 10273 110862 108122 14279 110865 16757 110862 9638 13764 120147 125 110862 76897 10929 14279 110865 16757 110862 103 12692 120424 29455 103 110862 87372 10929 14279 110865 16757 110862 9625 46520 29455 10186 110862 92546 11166 14279 110865 16757 110862 9640 71439 29455 10270 110862 92546 10884 14279 110865 16757 11467 119660 119579 9283 11261 28188 24206 103 31605 120291 23466 10459 119884 120255 10892 130 110864 92161 181 10884 110865 16757 11467 120226 36210 14801 110858 10147 119740 21928 9448 21614 36210 120291 10459 120104 10892 128 110862 45389 11011 14279 110865 10147 10884 11261 120039 119582 34421 119857 41280 32107 10822 10108 49150 18849 10142 25103 110863 19706 16988 10165 11537 54989 122 110859 93218 11942 10635 10178 11940 10124 127 19573 103 123 110859 66387 10230 18527 103 119590 11166 10204 110864 9448 21614 36210 41521 12692 119590 11166 103 10530 91621 12178 8912 119025 12310 8924 37388 119412 9316 9283 11261 28188 24206 9644 31605 120291 23466 10530 60804 9448 21614 36210 9316 9711 14801 120291 120147 10892 8912 119025 12310 8924 37388 119412 10530 60804 9414 23466 120291 120147 11882 9283 11261 28188 24206 9644 31605 120291 23466 10530 60804 9448 21614 36210 120291 120147 110862 23289 8912 119025 12310 8924 37388 119412 10530 60804 9711 14801 120291 120147 10459 9957 11467 120057 36210 14801 110858 10147 119740 21928 9539 10250 110862 92161 10884 14279 110865 10147 10884 11467 9845 16439 58813 110864 119619 9901 119058 120291 120147 119552 119627 9448 27506 9284 36210 46150 103 33797 60804 102\n",
      "I1120 16:06:43.927442 47619347533312 create_pretraining_data.py:161] input_ids: 101 103 93218 11942 10635 10178 11940 10124 127 103 110864 102 11259 10692 10131 119680 10175 119592 18329 119884 120147 11176 110862 77802 14279 110865 18392 10622 119564 11102 120057 36210 14801 110858 103 119740 21928 9448 21614 36210 120291 10459 120104 10892 130 110862 120247 11011 14279 110865 10147 10884 9202 120039 119582 9448 21614 36210 41521 12692 119590 11166 10204 10530 91621 12178 8912 119025 12310 8924 37388 119412 9316 9448 21614 36210 24974 9890 118864 10530 60804 9448 21614 36210 9316 9711 14801 120291 120147 10892 8912 119025 12310 8924 37388 119412 10530 103 9414 23466 120291 120147 11882 9448 21614 36210 24974 9890 118864 10530 60804 9448 21614 103 120291 120147 110862 23289 8912 119025 12310 8924 37388 119412 10530 60804 9711 14801 120291 120147 10459 9957 11467 120057 36210 14801 110858 10147 119740 21928 9539 10296 110862 74178 11011 14279 110865 10147 10884 11467 119588 119647 8912 119025 12310 8924 37388 119412 9316 9283 11261 28188 103 9644 31605 120291 23466 10530 60804 9448 21614 36210 103 120147 14871 23466 9316 9711 14801 119884 10530 119550 13441 8912 103 12310 8924 37388 119412 10459 119884 120147 10622 120039 22440 19905 119550 13441 119933 12030 13764 9316 120039 31605 23160 10892 9414 12310 34421 125 12638 8855 11664 9283 11261 28188 24206 9644 31605 120291 23466 10530 60804 9448 21614 36210 120291 120147 10622 120039 22440 19905 119550 103 103 12030 13764 9316 120039 31605 23160 10892 34421 103 12638 119655 120039 11102 119612 21928 120104 10892 8848 11287 14871 66540 29455 10273 110862 108122 14279 110865 16757 110862 9638 13764 120147 125 110862 76897 10929 14279 110865 16757 110862 103 12692 120424 29455 103 110862 87372 10929 14279 110865 16757 110862 9625 46520 29455 10186 110862 92546 11166 14279 110865 16757 110862 9640 71439 29455 10270 110862 92546 10884 14279 110865 16757 11467 119660 119579 9283 11261 28188 24206 103 31605 120291 23466 10459 119884 120255 10892 130 110864 92161 181 10884 110865 16757 11467 120226 36210 14801 110858 10147 119740 21928 9448 21614 36210 120291 10459 120104 10892 128 110862 45389 11011 14279 110865 10147 10884 11261 120039 119582 34421 119857 41280 32107 10822 10108 49150 18849 10142 25103 110863 19706 16988 10165 11537 54989 122 110859 93218 11942 10635 10178 11940 10124 127 19573 103 123 110859 66387 10230 18527 103 119590 11166 10204 110864 9448 21614 36210 41521 12692 119590 11166 103 10530 91621 12178 8912 119025 12310 8924 37388 119412 9316 9283 11261 28188 24206 9644 31605 120291 23466 10530 60804 9448 21614 36210 9316 9711 14801 120291 120147 10892 8912 119025 12310 8924 37388 119412 10530 60804 9414 23466 120291 120147 11882 9283 11261 28188 24206 9644 31605 120291 23466 10530 60804 9448 21614 36210 120291 120147 110862 23289 8912 119025 12310 8924 37388 119412 10530 60804 9711 14801 120291 120147 10459 9957 11467 120057 36210 14801 110858 10147 119740 21928 9539 10250 110862 92161 10884 14279 110865 10147 10884 11467 9845 16439 58813 110864 119619 9901 119058 120291 120147 119552 119627 9448 27506 9284 36210 46150 103 33797 60804 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.928029 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.928557 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 1 9 34 97 113 162 172 184 233 234 243 275 276 279 315 382 388 400 448 508\n",
      "I1120 16:06:43.928835 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 1 9 34 97 113 162 172 184 233 234 243 275 276 279 315 382 388 400 448 508\n",
      "INFO:tensorflow:masked_lm_ids: 20231 19573 10147 60804 36210 24206 120291 119025 13441 119933 126 9460 12692 10208 9644 110864 10124 10204 31605 119058\n",
      "I1120 16:06:43.929074 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 20231 19573 10147 60804 36210 24206 120291 119025 13441 119933 126 9460 12692 10208 9644 110864 10124 10204 31605 119058\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.929307 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "I1120 16:06:43.929523 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.931575 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] Fig. 7 ##. Earth pressure with depth ##( ##ball ##aste ##d track ##). ##Fig. 8 ##. Earth pressure with depth ##( ##ball ##aste ##d track on the asp ##halt road ##bed ##). ##Fig. 9 ##. Com ##pari [MASK] of settlement of rein ##forced road ##bed [MASK] 동 ##적 열 ##차 ##하 ##중 재 ##하 실험 결과를 살펴보 ##면 자 ##갈 ##궤 ##도와 [MASK] ##자 ##갈 ##궤 ##도의 강 ##화 ##노 등에 상 ##면 ##의 누 ##적 침 ##하 ##량을 나타낸 것이 Fig. 10 ##이다. 그림 ##에 나타낸 바 ##와 같이 반 ##복 ##하 ##중 재 ##하 초기에 급 ##격 ##한 침 ##하 ##가 일 ##어나 ##고 이후 점 ##차 수 ##렴 ##하여 300 ##만 ##회 재 ##하 ##시 누 ##적 침 ##하 ##량은 각각 1. ##5 ##6 ##mm ##와 0. ##99 [MASK] ##로 측정 ##되었다. 두 단 ##면 모두 철도 ##설계 ##기준 7 gestão 의 ##거 [MASK] ##차 ##하 ##중에 의한 노 ##반 ##의 허 ##용 침 ##하 ##량 [MASK] ##mm ##이 ##내 ##를 만족 ##하는 값을 나타내었다. 또한 Fig. 11 ##은 반 ##복 ##하 ##중 재 ##하 시 ##의 [MASK] ##성 변 ##위를 나타낸 것으로 두 단 ##면 모두 약 0. ##4 ##mm ##정 ##도의 유사 ##한 값을 나타내 ##고 있으며 일본 철도 ##설계 ##기준 8 에 명 ##시 ##된 탄 ##성 ##변 ##위 2. ##5 ##mm ##이 ##내 ##임을 확인할 수 있다. [SEP] Fig. 10. Cum ##ulat ##ive settlement of rein ##forced [MASK] ##bed ##. Fig. 11. Ela ##stic dis ##placement of rein ##forced road ##bed ##. 동 ##적 열 ##차 ##하 ##중 재 ##하 시 ##의 강 ##화 ##노 ##반 상 ##면 ##에서의 토 ##압 분포 ##는 Fig. 12 ##와 같다. Fig. 12 ##는 5 ##본 ##의 침 ##목 ##으로 구성 ##한 궤 ##광 ##에 의해 100 ##만 ##회 ##까지 재 ##하 ##하고 이후 단 ##침 ##목 ##의 조건 ##에서 300 ##만 ##회 ##까지 재 ##하 ##하였 ##을 때 ##의 [MASK] ##압 분포 ##를 나타낸 것이다. AC ##자 ##갈 ##궤 ##도의 강 ##화 ##노 ##반 상 ##면 ##에서의 토 [MASK] ##은 32 59 ##k ##Pa ##이고, 자 ##갈 ##궤 ##도는 50 88 ##k ##Pa ##의 분포 ##를 나타내 ##고 있어 AC ##자 ##갈 ##궤 ##도가 자 ##갈 ##궤 ##도에 비해 열 ##차 ##하 ##중 ##의 분 ##산 효과 ##가 있는 것을 알 수 있다. 100 ##만 ##회 [MASK] ##부터 토 ##압 ##이 증가 ##한 이유 ##는 100 [MASK] ##회 재 ##하 ##시 발생 ##한 뜬 침 ##목 효과 ##로 인해 재 ##하 ##된 하 ##중 [MASK] 자 ##갈 ##도 ##상 ##과 노 ##반 ##에 제 ##대로 전 ##달 ##되지 않은 반 ##면 100 ##만 ##회 이후 단 ##침 ##목 ##으로 하 ##중 ##을 재 ##하 ##함 ##으로서 뜬 침 ##목 효과 ##가 배 [MASK] ##되어 재 ##하 하 ##중 [MASK] 직접 노 ##반 ##으로 전 ##달 ##되었다 ##는 [MASK] 의미 ##한다. Fig. 12. Com ##pari ##son of earth pressure of rein ##forced road ##bed ##. Fig. 13 ##은 2 ##개의 실험 ##단 ##면 ##에 대한 각각 정 ##적 재 ##하 실험 ##과 동 ##적 재 ##하 실험 ##에 의한 깊 ##이 ##별 토 ##압 ##분포 ##를 나타낸 [SEP]\n",
      "I1120 16:06:43.932137 47619347533312 create_pretraining_data.py:151] tokens: [CLS] Fig. 7 ##. Earth pressure with depth ##( ##ball ##aste ##d track ##). ##Fig. 8 ##. Earth pressure with depth ##( ##ball ##aste ##d track on the asp ##halt road ##bed ##). ##Fig. 9 ##. Com ##pari [MASK] of settlement of rein ##forced road ##bed [MASK] 동 ##적 열 ##차 ##하 ##중 재 ##하 실험 결과를 살펴보 ##면 자 ##갈 ##궤 ##도와 [MASK] ##자 ##갈 ##궤 ##도의 강 ##화 ##노 등에 상 ##면 ##의 누 ##적 침 ##하 ##량을 나타낸 것이 Fig. 10 ##이다. 그림 ##에 나타낸 바 ##와 같이 반 ##복 ##하 ##중 재 ##하 초기에 급 ##격 ##한 침 ##하 ##가 일 ##어나 ##고 이후 점 ##차 수 ##렴 ##하여 300 ##만 ##회 재 ##하 ##시 누 ##적 침 ##하 ##량은 각각 1. ##5 ##6 ##mm ##와 0. ##99 [MASK] ##로 측정 ##되었다. 두 단 ##면 모두 철도 ##설계 ##기준 7 gestão 의 ##거 [MASK] ##차 ##하 ##중에 의한 노 ##반 ##의 허 ##용 침 ##하 ##량 [MASK] ##mm ##이 ##내 ##를 만족 ##하는 값을 나타내었다. 또한 Fig. 11 ##은 반 ##복 ##하 ##중 재 ##하 시 ##의 [MASK] ##성 변 ##위를 나타낸 것으로 두 단 ##면 모두 약 0. ##4 ##mm ##정 ##도의 유사 ##한 값을 나타내 ##고 있으며 일본 철도 ##설계 ##기준 8 에 명 ##시 ##된 탄 ##성 ##변 ##위 2. ##5 ##mm ##이 ##내 ##임을 확인할 수 있다. [SEP] Fig. 10. Cum ##ulat ##ive settlement of rein ##forced [MASK] ##bed ##. Fig. 11. Ela ##stic dis ##placement of rein ##forced road ##bed ##. 동 ##적 열 ##차 ##하 ##중 재 ##하 시 ##의 강 ##화 ##노 ##반 상 ##면 ##에서의 토 ##압 분포 ##는 Fig. 12 ##와 같다. Fig. 12 ##는 5 ##본 ##의 침 ##목 ##으로 구성 ##한 궤 ##광 ##에 의해 100 ##만 ##회 ##까지 재 ##하 ##하고 이후 단 ##침 ##목 ##의 조건 ##에서 300 ##만 ##회 ##까지 재 ##하 ##하였 ##을 때 ##의 [MASK] ##압 분포 ##를 나타낸 것이다. AC ##자 ##갈 ##궤 ##도의 강 ##화 ##노 ##반 상 ##면 ##에서의 토 [MASK] ##은 32 59 ##k ##Pa ##이고, 자 ##갈 ##궤 ##도는 50 88 ##k ##Pa ##의 분포 ##를 나타내 ##고 있어 AC ##자 ##갈 ##궤 ##도가 자 ##갈 ##궤 ##도에 비해 열 ##차 ##하 ##중 ##의 분 ##산 효과 ##가 있는 것을 알 수 있다. 100 ##만 ##회 [MASK] ##부터 토 ##압 ##이 증가 ##한 이유 ##는 100 [MASK] ##회 재 ##하 ##시 발생 ##한 뜬 침 ##목 효과 ##로 인해 재 ##하 ##된 하 ##중 [MASK] 자 ##갈 ##도 ##상 ##과 노 ##반 ##에 제 ##대로 전 ##달 ##되지 않은 반 ##면 100 ##만 ##회 이후 단 ##침 ##목 ##으로 하 ##중 ##을 재 ##하 ##함 ##으로서 뜬 침 ##목 효과 ##가 배 [MASK] ##되어 재 ##하 하 ##중 [MASK] 직접 노 ##반 ##으로 전 ##달 ##되었다 ##는 [MASK] 의미 ##한다. Fig. 12. Com ##pari ##son of earth pressure of rein ##forced road ##bed ##. Fig. 13 ##은 2 ##개의 실험 ##단 ##면 ##에 대한 각각 정 ##적 재 ##하 실험 ##과 동 ##적 재 ##하 실험 ##에 의한 깊 ##이 ##별 토 ##압 ##분포 ##를 나타낸 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 119603 128 110864 11012 23460 10169 41098 110858 19805 25096 10162 14310 119558 119565 129 110864 11012 23460 10169 41098 110858 19805 25096 10162 14310 10135 10105 28438 27015 15485 33627 119558 119565 130 110864 16680 101813 103 10108 23931 10108 74720 69794 15485 33627 103 9095 14801 9569 23466 35506 41693 9659 35506 119569 119639 119828 14867 9651 101202 118660 119724 103 13764 101202 118660 54469 8853 18227 28981 77547 9414 14867 10459 9032 14801 9783 35506 119717 119777 27487 119603 10150 119555 119621 10530 119777 9318 12638 38401 9321 70915 35506 41693 9659 35506 120524 8929 45465 11102 9783 35506 11287 9641 120098 11664 18347 9668 23466 9460 118878 13374 11093 19105 14863 9659 35506 14040 9032 14801 9783 35506 119868 63042 119590 11166 11211 17525 12638 119560 88657 103 11261 119559 119582 9102 9059 14867 29414 87624 120153 119992 128 102288 9637 41521 103 23466 35506 81724 60804 9022 30134 10459 9968 24974 9783 35506 44321 103 17525 10739 31605 11513 119673 12178 119864 119932 19789 119603 10193 10892 9321 70915 35506 41693 9659 35506 9485 10459 103 17138 9352 31166 119777 23925 9102 9059 14867 29414 9539 119560 11011 17525 16605 54469 119754 11102 119864 119666 11664 22634 23130 87624 120153 119992 129 9559 9281 14040 13441 9847 17138 118985 19855 119616 11166 17525 10739 31605 96972 119924 9460 119547 102 119603 120197 64211 46059 11942 23931 10108 74720 69794 103 33627 110864 119603 120239 26271 26666 27920 62303 10108 74720 69794 15485 33627 110864 9095 14801 9569 23466 35506 41693 9659 35506 9485 10459 8853 18227 28981 30134 9414 14867 119650 9873 119116 119785 11018 119603 10186 12638 119655 119603 10186 11018 126 40419 10459 9783 68055 11467 119571 11102 8919 118649 10530 23610 10407 19105 14863 18382 9659 35506 12453 18347 9059 119285 68055 10459 119705 11489 11093 19105 14863 18382 9659 35506 119585 10622 9137 10459 103 119116 119785 11513 119777 119584 18132 13764 101202 118660 54469 8853 18227 28981 30134 9414 14867 119650 9873 103 10892 10842 11867 10174 89525 120148 9651 101202 118660 60884 10462 12074 10174 89525 10459 119785 11513 119666 11664 45893 18132 13764 101202 118660 68516 9651 101202 118660 108521 100876 9569 23466 35506 41693 10459 9367 21386 119620 11287 13767 21371 9524 9460 119547 10407 19105 14863 103 17655 9873 119116 10739 119561 11102 120076 11018 10407 103 14863 9659 35506 14040 119568 11102 9152 9783 68055 119620 11261 39629 9659 35506 13441 9952 41693 103 9651 101202 12092 14871 11882 9022 30134 10530 9672 37601 9665 89851 59902 54543 9321 14867 10407 19105 14863 18347 9059 119285 68055 11467 9952 41693 10622 9659 35506 48533 120024 9152 9783 68055 119620 11287 9330 103 16855 9659 35506 9952 41693 103 67288 9022 30134 11467 9665 89851 13628 11018 103 119614 119554 119603 120234 16680 101813 11599 10108 39189 23460 10108 74720 69794 15485 33627 110864 119603 10249 10892 123 32501 119569 24989 14867 10530 18154 63042 9670 14801 9659 35506 119569 11882 9095 14801 9659 35506 119569 10530 60804 8938 10739 61844 9873 119116 120150 11513 119777 102\n",
      "I1120 16:06:43.932809 47619347533312 create_pretraining_data.py:161] input_ids: 101 119603 128 110864 11012 23460 10169 41098 110858 19805 25096 10162 14310 119558 119565 129 110864 11012 23460 10169 41098 110858 19805 25096 10162 14310 10135 10105 28438 27015 15485 33627 119558 119565 130 110864 16680 101813 103 10108 23931 10108 74720 69794 15485 33627 103 9095 14801 9569 23466 35506 41693 9659 35506 119569 119639 119828 14867 9651 101202 118660 119724 103 13764 101202 118660 54469 8853 18227 28981 77547 9414 14867 10459 9032 14801 9783 35506 119717 119777 27487 119603 10150 119555 119621 10530 119777 9318 12638 38401 9321 70915 35506 41693 9659 35506 120524 8929 45465 11102 9783 35506 11287 9641 120098 11664 18347 9668 23466 9460 118878 13374 11093 19105 14863 9659 35506 14040 9032 14801 9783 35506 119868 63042 119590 11166 11211 17525 12638 119560 88657 103 11261 119559 119582 9102 9059 14867 29414 87624 120153 119992 128 102288 9637 41521 103 23466 35506 81724 60804 9022 30134 10459 9968 24974 9783 35506 44321 103 17525 10739 31605 11513 119673 12178 119864 119932 19789 119603 10193 10892 9321 70915 35506 41693 9659 35506 9485 10459 103 17138 9352 31166 119777 23925 9102 9059 14867 29414 9539 119560 11011 17525 16605 54469 119754 11102 119864 119666 11664 22634 23130 87624 120153 119992 129 9559 9281 14040 13441 9847 17138 118985 19855 119616 11166 17525 10739 31605 96972 119924 9460 119547 102 119603 120197 64211 46059 11942 23931 10108 74720 69794 103 33627 110864 119603 120239 26271 26666 27920 62303 10108 74720 69794 15485 33627 110864 9095 14801 9569 23466 35506 41693 9659 35506 9485 10459 8853 18227 28981 30134 9414 14867 119650 9873 119116 119785 11018 119603 10186 12638 119655 119603 10186 11018 126 40419 10459 9783 68055 11467 119571 11102 8919 118649 10530 23610 10407 19105 14863 18382 9659 35506 12453 18347 9059 119285 68055 10459 119705 11489 11093 19105 14863 18382 9659 35506 119585 10622 9137 10459 103 119116 119785 11513 119777 119584 18132 13764 101202 118660 54469 8853 18227 28981 30134 9414 14867 119650 9873 103 10892 10842 11867 10174 89525 120148 9651 101202 118660 60884 10462 12074 10174 89525 10459 119785 11513 119666 11664 45893 18132 13764 101202 118660 68516 9651 101202 118660 108521 100876 9569 23466 35506 41693 10459 9367 21386 119620 11287 13767 21371 9524 9460 119547 10407 19105 14863 103 17655 9873 119116 10739 119561 11102 120076 11018 10407 103 14863 9659 35506 14040 119568 11102 9152 9783 68055 119620 11261 39629 9659 35506 13441 9952 41693 103 9651 101202 12092 14871 11882 9022 30134 10530 9672 37601 9665 89851 59902 54543 9321 14867 10407 19105 14863 18347 9059 119285 68055 11467 9952 41693 10622 9659 35506 48533 120024 9152 9783 68055 119620 11287 9330 103 16855 9659 35506 9952 41693 103 67288 9022 30134 11467 9665 89851 13628 11018 103 119614 119554 119603 120234 16680 101813 11599 10108 39189 23460 10108 74720 69794 15485 33627 110864 119603 10249 10892 123 32501 119569 24989 14867 10530 18154 63042 9670 14801 9659 35506 119569 11882 9095 14801 9659 35506 119569 10530 60804 8938 10739 61844 9873 119116 120150 11513 119777 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.933369 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.933894 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 38 46 63 71 132 144 147 160 181 235 314 333 381 385 391 409 410 447 453 462\n",
      "I1120 16:06:43.934160 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 38 46 63 71 132 144 147 160 181 235 314 333 381 385 391 409 410 447 453 462\n",
      "INFO:tensorflow:masked_lm_ids: 11599 110864 18132 30134 17525 9559 9569 126 9847 15485 9873 119116 18347 10739 19105 10739 9651 17730 10739 21371\n",
      "I1120 16:06:43.934390 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 11599 110864 18132 30134 17525 9559 9569 126 9847 15485 9873 119116 18347 10739 19105 10739 9651 17730 10739 21371\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.934622 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "I1120 16:06:43.934861 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.936793 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 이는 복 Lexington 겔 고 ##분 ##자 전 ##해 ##질 내 ##에서의 리 ##튬 양 ##이 ##온 ##의 이동 ##이 더 용 [MASK] 때문 ##인 것으로 판단된다. 1 ##C [MASK] 전 ##류 ##밀 ##도를 높 ##였다 ##가 다시 0. ##1 ##C ##로 전 ##류 밀 ##도를 [MASK] ##추 ##었 ##을 때 ##, 두 전 ##지 모두 가 ##역 ##성이 우 ##수 ##하기 때문에 방 ##전 용 ##량은 초기의 용 ##량을 회 ##복 ##하였다. Fig. 5. Ini ##tial charge ##- ##disch ##ar ##ge curve ##s ( ##a ##), cycle performance ( ##b ##) and rate ##- ##cap ##ability at RT of two different Li ##/ ##GP ##E ##/ ##N ##MC [MASK] ##. [MASK] [MASK] ##전기 ##방 ##사에 의 ##여 제작 ##된 두 가지 겔 고 ##분 ##자 전 ##해 ##질 ##의 물 ##리 ##화 ##학적 ##, 전기 ##화 [MASK] 특성을 비교 분석하였다. 6 w ##t ##. ##% ##의 Al ##2 ##O ##3 ##를 첨가 ##한 복 ##합 고 ##분 ##자 분리 ##막 ##은 순 ##수 ##한 고 ##분 ##자 분리 ##막 ##보다 [MASK] 액 ##체 전 ##해 ##질 함 ##침 ##량 ##과 더 가 ##는 섬 ##유 직 ##경 ##을 가지고 있다. [SEP] ##색 ##( ##L = 43 ##, a = 66 ##, b = 53 ##)에 비해 색 ##의 명 ##도를 나타내 ##는 L ##의 수 ##치가 크 ##고, red ##- ##green ##의 색 ##상을 [MASK] ##는 a 값 [MASK] ( ##- ##)를 나타내 전 ##반 ##적으로 초록 ##색 ##상이 강 ##한 것을 알 수 있었다. 이때 추출 ##된 색 ##소 ##와 목표 ##색 ##과의 색 ##도 ##차 ##를 나타내 ##는 E ##* ##가 각각 97 ##. ##3 ##과 96 ##. ##1 ##로 목표 ##색 ##과 ##는 확 ##연 ##한 색 ##도 ##차이를 나타내었다. 또한 중 ##성 ##영역 ##인 pH 7 ##에서는 L ##= 71 ##. ##9 ##, a = [MASK] ##. ##4 ##, b = 60 ##. [MASK] ##로 황 ##홍 ##색 ##을 나타내 ##어 E ##* ##가 40 ##. ##7 ##로 계산 ##되었다. 그러나 pH ##가 염 ##기 ##성 영역 ##으로 증가 ##함 ##에 따라 추출 ##된 색 ##소 ##가 적 ##색 ##으로 변화 ##하였다. 추출 ##시간 20 min ##을 기준으로 pH ##가 증가 ##함 ##에 따라 9 ( ##L = 32 ##. ##6 ##, a = 50. ##8 ##, b = 46 ##. ##1), 10 ( ##L = 26 ##. ##9 ##, a = 72 ##. ##0 ##, b = 46 ##. ##3), 12 [MASK] ##L = 29 ##. ##4 ##, a [MASK] 77 ##. ##7 ##, b = 50. ##0 ##)로 적 ##색 목표 ##색 ##인 카 ##드 ##뮴 레 ##드 색 ##도에 근 ##접 ##하게 나타났다. 이때 색 अन्य ##를 나타내 ##는 E ##* ##는 18 ##. ##2 18 ##. ##7 ##로 계산 ##되었다. 이는 소 ##목 [MASK] 적 ##색 ##소 ##인 bra ##zili ##n ##이 공 ##기 중에 산 ##화 ##하여 bra ##zil ##ein ##으로 변화 ##하는데 bra ##zil ##ein ##의 경우 산 ##성이 ##나 중 ##성 [MASK] ##매 ##에서 추출 ##될 경우 엷 [MASK] 황 ##홍 ##색 ##을 나타내 ##지만 용 ##매 ##의 염 ##기 ##성이 증가 ##하면 적 ##색 ##으로 발 ##색 [SEP]\n",
      "I1120 16:06:43.937321 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 이는 복 Lexington 겔 고 ##분 ##자 전 ##해 ##질 내 ##에서의 리 ##튬 양 ##이 ##온 ##의 이동 ##이 더 용 [MASK] 때문 ##인 것으로 판단된다. 1 ##C [MASK] 전 ##류 ##밀 ##도를 높 ##였다 ##가 다시 0. ##1 ##C ##로 전 ##류 밀 ##도를 [MASK] ##추 ##었 ##을 때 ##, 두 전 ##지 모두 가 ##역 ##성이 우 ##수 ##하기 때문에 방 ##전 용 ##량은 초기의 용 ##량을 회 ##복 ##하였다. Fig. 5. Ini ##tial charge ##- ##disch ##ar ##ge curve ##s ( ##a ##), cycle performance ( ##b ##) and rate ##- ##cap ##ability at RT of two different Li ##/ ##GP ##E ##/ ##N ##MC [MASK] ##. [MASK] [MASK] ##전기 ##방 ##사에 의 ##여 제작 ##된 두 가지 겔 고 ##분 ##자 전 ##해 ##질 ##의 물 ##리 ##화 ##학적 ##, 전기 ##화 [MASK] 특성을 비교 분석하였다. 6 w ##t ##. ##% ##의 Al ##2 ##O ##3 ##를 첨가 ##한 복 ##합 고 ##분 ##자 분리 ##막 ##은 순 ##수 ##한 고 ##분 ##자 분리 ##막 ##보다 [MASK] 액 ##체 전 ##해 ##질 함 ##침 ##량 ##과 더 가 ##는 섬 ##유 직 ##경 ##을 가지고 있다. [SEP] ##색 ##( ##L = 43 ##, a = 66 ##, b = 53 ##)에 비해 색 ##의 명 ##도를 나타내 ##는 L ##의 수 ##치가 크 ##고, red ##- ##green ##의 색 ##상을 [MASK] ##는 a 값 [MASK] ( ##- ##)를 나타내 전 ##반 ##적으로 초록 ##색 ##상이 강 ##한 것을 알 수 있었다. 이때 추출 ##된 색 ##소 ##와 목표 ##색 ##과의 색 ##도 ##차 ##를 나타내 ##는 E ##* ##가 각각 97 ##. ##3 ##과 96 ##. ##1 ##로 목표 ##색 ##과 ##는 확 ##연 ##한 색 ##도 ##차이를 나타내었다. 또한 중 ##성 ##영역 ##인 pH 7 ##에서는 L ##= 71 ##. ##9 ##, a = [MASK] ##. ##4 ##, b = 60 ##. [MASK] ##로 황 ##홍 ##색 ##을 나타내 ##어 E ##* ##가 40 ##. ##7 ##로 계산 ##되었다. 그러나 pH ##가 염 ##기 ##성 영역 ##으로 증가 ##함 ##에 따라 추출 ##된 색 ##소 ##가 적 ##색 ##으로 변화 ##하였다. 추출 ##시간 20 min ##을 기준으로 pH ##가 증가 ##함 ##에 따라 9 ( ##L = 32 ##. ##6 ##, a = 50. ##8 ##, b = 46 ##. ##1), 10 ( ##L = 26 ##. ##9 ##, a = 72 ##. ##0 ##, b = 46 ##. ##3), 12 [MASK] ##L = 29 ##. ##4 ##, a [MASK] 77 ##. ##7 ##, b = 50. ##0 ##)로 적 ##색 목표 ##색 ##인 카 ##드 ##뮴 레 ##드 색 ##도에 근 ##접 ##하게 나타났다. 이때 색 अन्य ##를 나타내 ##는 E ##* ##는 18 ##. ##2 18 ##. ##7 ##로 계산 ##되었다. 이는 소 ##목 [MASK] 적 ##색 ##소 ##인 bra ##zili ##n ##이 공 ##기 중에 산 ##화 ##하여 bra ##zil ##ein ##으로 변화 ##하는데 bra ##zil ##ein ##의 경우 산 ##성이 ##나 중 ##성 [MASK] ##매 ##에서 추출 ##될 경우 엷 [MASK] 황 ##홍 ##색 ##을 나타내 ##지만 용 ##매 ##의 염 ##기 ##성이 증가 ##하면 적 ##색 ##으로 발 ##색 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 33904 9357 62359 8874 8888 37712 13764 9665 14523 48599 8996 119650 9238 119370 9543 10739 37093 10459 119831 10739 9074 9603 103 119832 12030 23925 119975 122 10858 103 9665 46520 118958 52602 9028 34776 11287 25805 119560 10759 10858 11261 9665 46520 9313 52602 103 119274 119138 10622 9137 110862 9102 9665 12508 29414 8843 23160 53371 9604 15891 22440 20729 9328 16617 9603 119868 120798 9603 119717 9998 70915 119548 119603 119857 25336 72416 18163 110863 85154 10354 10525 67088 10107 113 10113 119557 25850 14432 113 10457 110859 10111 18344 110863 93103 35717 10160 56898 10108 10551 12902 13258 110865 74450 11259 110865 11537 99649 103 110864 103 103 120361 42337 86580 9637 29935 104865 13441 9102 69164 8874 8888 37712 13764 9665 14523 48599 10459 9299 12692 18227 87503 110862 120022 18227 103 119772 119572 120012 127 191 10123 110864 110855 10459 10883 10729 11403 10884 11513 119836 11102 9357 33188 8888 37712 13764 120095 118907 10892 9462 15891 11102 8888 37712 13764 120095 118907 80001 103 9533 29683 9665 14523 48599 9956 119285 44321 11882 9074 8843 11018 9430 42815 9707 31720 10622 44270 119547 102 41442 110858 11369 134 11370 110862 169 134 12215 110862 170 134 11756 119716 100876 9416 10459 9281 52602 119666 11018 149 10459 9460 104504 9834 119563 10680 110863 102247 10459 9416 33654 103 11018 169 8850 103 113 110863 119638 119666 9665 30134 17022 120040 41442 83902 8853 11102 21371 9524 9460 119659 86838 119702 13441 9416 22333 12638 120006 41442 102003 9416 12092 23466 11513 119666 11018 142 110860 11287 63042 12328 110864 10884 11882 12308 110864 10759 11261 120006 41442 11882 11018 9994 25486 11102 9416 12092 120931 119932 19789 9694 17138 120118 12030 30211 128 23635 149 110869 12513 110864 11373 110862 169 134 103 110864 11011 110862 170 134 10709 110864 103 11261 9997 119444 41442 10622 119666 12965 142 110860 11287 10533 110864 11305 11261 119690 119582 21890 30211 11287 9570 12310 17138 119663 11467 119561 48533 10530 22799 119702 13441 9416 22333 11287 9664 41442 11467 119586 119548 119702 100699 10197 13484 10622 81600 30211 11287 119561 48533 10530 22799 130 113 11369 134 10842 110864 11211 110862 169 134 120633 11396 110862 170 134 11528 110864 120189 10150 113 11369 134 10314 110864 11373 110862 169 134 12120 110864 10929 110862 170 134 11528 110864 120338 10186 103 11369 134 10386 110864 11011 110862 169 103 12527 110864 11305 110862 170 134 120633 10929 119895 9664 41442 120006 41442 12030 9786 15001 120920 9186 15001 9416 108521 8926 119205 17594 119588 86838 9416 22197 11513 119666 11018 142 110860 11018 10218 110864 10729 10218 110864 11305 11261 119690 119582 33904 9448 68055 103 9664 41442 22333 12030 67603 81373 10115 10739 8896 12310 102246 9407 18227 13374 67603 44791 17892 11467 119586 119885 67603 44791 17892 10459 28467 9407 53371 16439 9694 17138 103 100372 11489 119702 59330 28467 121910 103 9997 119444 41442 10622 119666 28578 9603 100372 10459 9570 12310 53371 119561 38378 9664 41442 11467 9323 41442 102\n",
      "I1120 16:06:43.937961 47619347533312 create_pretraining_data.py:161] input_ids: 101 33904 9357 62359 8874 8888 37712 13764 9665 14523 48599 8996 119650 9238 119370 9543 10739 37093 10459 119831 10739 9074 9603 103 119832 12030 23925 119975 122 10858 103 9665 46520 118958 52602 9028 34776 11287 25805 119560 10759 10858 11261 9665 46520 9313 52602 103 119274 119138 10622 9137 110862 9102 9665 12508 29414 8843 23160 53371 9604 15891 22440 20729 9328 16617 9603 119868 120798 9603 119717 9998 70915 119548 119603 119857 25336 72416 18163 110863 85154 10354 10525 67088 10107 113 10113 119557 25850 14432 113 10457 110859 10111 18344 110863 93103 35717 10160 56898 10108 10551 12902 13258 110865 74450 11259 110865 11537 99649 103 110864 103 103 120361 42337 86580 9637 29935 104865 13441 9102 69164 8874 8888 37712 13764 9665 14523 48599 10459 9299 12692 18227 87503 110862 120022 18227 103 119772 119572 120012 127 191 10123 110864 110855 10459 10883 10729 11403 10884 11513 119836 11102 9357 33188 8888 37712 13764 120095 118907 10892 9462 15891 11102 8888 37712 13764 120095 118907 80001 103 9533 29683 9665 14523 48599 9956 119285 44321 11882 9074 8843 11018 9430 42815 9707 31720 10622 44270 119547 102 41442 110858 11369 134 11370 110862 169 134 12215 110862 170 134 11756 119716 100876 9416 10459 9281 52602 119666 11018 149 10459 9460 104504 9834 119563 10680 110863 102247 10459 9416 33654 103 11018 169 8850 103 113 110863 119638 119666 9665 30134 17022 120040 41442 83902 8853 11102 21371 9524 9460 119659 86838 119702 13441 9416 22333 12638 120006 41442 102003 9416 12092 23466 11513 119666 11018 142 110860 11287 63042 12328 110864 10884 11882 12308 110864 10759 11261 120006 41442 11882 11018 9994 25486 11102 9416 12092 120931 119932 19789 9694 17138 120118 12030 30211 128 23635 149 110869 12513 110864 11373 110862 169 134 103 110864 11011 110862 170 134 10709 110864 103 11261 9997 119444 41442 10622 119666 12965 142 110860 11287 10533 110864 11305 11261 119690 119582 21890 30211 11287 9570 12310 17138 119663 11467 119561 48533 10530 22799 119702 13441 9416 22333 11287 9664 41442 11467 119586 119548 119702 100699 10197 13484 10622 81600 30211 11287 119561 48533 10530 22799 130 113 11369 134 10842 110864 11211 110862 169 134 120633 11396 110862 170 134 11528 110864 120189 10150 113 11369 134 10314 110864 11373 110862 169 134 12120 110864 10929 110862 170 134 11528 110864 120338 10186 103 11369 134 10386 110864 11011 110862 169 103 12527 110864 11305 110862 170 134 120633 10929 119895 9664 41442 120006 41442 12030 9786 15001 120920 9186 15001 9416 108521 8926 119205 17594 119588 86838 9416 22197 11513 119666 11018 142 110860 11018 10218 110864 10729 10218 110864 11305 11261 119690 119582 33904 9448 68055 103 9664 41442 22333 12030 67603 81373 10115 10739 8896 12310 102246 9407 18227 13374 67603 44791 17892 11467 119586 119885 67603 44791 17892 10459 28467 9407 53371 16439 9694 17138 103 100372 11489 119702 59330 28467 121910 103 9997 119444 41442 10622 119666 28578 9603 100372 10459 9570 12310 53371 119561 38378 9664 41442 11467 9323 41442 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.938507 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.939004 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 3 23 30 47 110 112 113 138 172 218 226 230 301 309 398 406 434 453 484 491\n",
      "I1120 16:06:43.939267 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 3 23 30 47 110 112 113 138 172 218 226 230 301 309 398 406 434 453 484 491\n",
      "INFO:tensorflow:masked_lm_ids: 33188 121266 18382 8992 23182 119619 119948 87503 55600 9834 119666 10739 11171 11396 113 134 23466 10459 24974 10892\n",
      "I1120 16:06:43.939486 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 33188 121266 18382 8992 23182 119619 119948 87503 55600 9834 119666 10739 11171 11396 113 134 23466 10459 24974 10892\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.939706 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "I1120 16:06:43.939916 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.941938 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] ##기 위해 ##서 기본 ##적인 프 ##라 ##이 ##버 ##시 ##와 혼 ##잡 ##에 대한 고려 ##가 필요한 공간 ##이다 ##( ##노 ##영 [MASK] ##, 1999 박 ##지 ##영 ##, 2002 ##). 이러한 외 [MASK] ##진 ##료 ##부 ##문 ##의 특징 ##은 다음과 같다. 첫 ##째, 통 ##원 ##할 수 있는 환자를 치료 ##하는 기능 ##. 둘 ##째, 병 ##원에 입 ##원 ##하고자 하는 환자 ##나 입 ##원 ##할 필요가 있는 환자의 진 ##찰 및 입 ##원 ##여 ##부 판단 ##. 셋 ##째, 퇴 ##원 환자의 지속 ##적 치료 [MASK] ##. 넷 ##째, 건강 ##진 ##단 ##을 [MASK] 질 ##병 ##의 예 ##방 및 조 ##기 ##발 ##견 ##. 다 ##섯 ##째, 마 ##비 기능 ##의 회 ##복 ##, 잔 ##존 ##기능 ##의 유지 ##, 보 ##완 ##기능 ##의 개발 및 연구 ##와 수 ##련 ##의 Frères [MASK] [MASK] ##소 ##로 ##의 역할 등을 담 ##당 ##하고 있다( ##최 ##승 ##근 ##, ##200 ##1). ##앞 ##에서 언 ##급 ##한 [MASK] ##과 더 ##불 ##어 외 [MASK] ##진 ##료 ##부 ##문 ##은 환자의 증가 ##에 따른 그 변화 상황 ##에 민 ##감 ##하게 반응 ##하고, 전문화 및 세 ##분 ##화 ##에 대 ##응 ##하는 공간 구성 ##의 변화 ##에 대한 요구 ##가 크 ##기 때문에 병 ##원의 의료 ##수준 ##을 파악 ##할 수 있는 중요한 척 ##도 역할을 한다. ##2) Character ##istics of Out ##pati ##ent Department of Psychiatry ##신 ##경 ##정 ##신 ##과 ##에서 정 ##신 ##과의 분 ##화 ##, 정 ##신 ##과 ##에서 정 ##신 [MASK] ##의 ##학과 ##로 ##의 개 ##명 등의 환경 ##적 변화 ##와 정 ##신 ##질 ##환 ##에 대한 인식 개선 ##은 [SEP] 식 ##수 ##(C ##ix ##ous [MASK] 주 ##변 ##부에 위치 ##해 발 ##화 [MASK] 기 ##회를 얻 ##지 [MASK] ##함으로써 남 ##성 중심 ##적 역 ##사에 ##서 소 ##외 ##되어 온 여성 ##의 삶 ##과 정 ##체 ##성을 드 ##러 ##내 ##기 위해 여성 ##적 글 ##쓰 ##기를 제시 ##한다 8 . 스 ##피 [MASK] ##(S ##pi ##vak ##)은 주 [MASK] 아닌 대상으로 간 ##주 ##되는 제 ##3 ##세 [MASK] 여성 ##들은 자신의 언 ##어를 가 ##질 수 있어 ##야 하며 ##, 지식 ##인 여성 ##은 말 ##걸 ##기를 통해 이 ##들의 경험 ##을 담 ##론 ##의 영역 ##으로 끌 ##어 ##와 ##야 한다 ##고 주 ##장 ##한다 5 . ##III ##. 여성 ##주의 다 ##큐 ##멘 ##터 ##리 연구 ##멀 ##비 ##( ##M ##ul ##vey ##)가 미 [MASK] ##어 ##에 재 ##현 ##되는 여성 ##의 이미 ##지에 대한 남 ##성 ##적 응 ##시 ##라는 개념 ##을 제시 ##한 후 9 영화 ##이론 ##을 정 ##신 ##분석 ##학 ##에 접 ##목 ##시 ##킨 씨 ##네 페 ##미 ##니 ##즘 ##에 대한 연구가 ##stande ##발 ##히 이루어 ##졌 ##으나 페 ##미 ##니 ##즘 영화 ##이론 ##은 할 ##리 ##우 ##드 극 ##영 ##화를 주 연구 ##대상으로 삼 ##기 때문에 여성 ##주의 다 [MASK] ##멘 ##터 ##리에 대한 연구는 상대적으로 드 ##물 ##다 10 . ##다 ##큐 ##멘 ##터 ##리 연구에서 여성 ##주의 다 ##큐 ##멘 ##터 ##리는 종 ##종 언 ##급 ##되 ##나 많은 비 ##중 ##을 차 ##지 ##하지 ##는 않는다 ##. [SEP]\n",
      "I1120 16:06:43.942475 47619347533312 create_pretraining_data.py:151] tokens: [CLS] ##기 위해 ##서 기본 ##적인 프 ##라 ##이 ##버 ##시 ##와 혼 ##잡 ##에 대한 고려 ##가 필요한 공간 ##이다 ##( ##노 ##영 [MASK] ##, 1999 박 ##지 ##영 ##, 2002 ##). 이러한 외 [MASK] ##진 ##료 ##부 ##문 ##의 특징 ##은 다음과 같다. 첫 ##째, 통 ##원 ##할 수 있는 환자를 치료 ##하는 기능 ##. 둘 ##째, 병 ##원에 입 ##원 ##하고자 하는 환자 ##나 입 ##원 ##할 필요가 있는 환자의 진 ##찰 및 입 ##원 ##여 ##부 판단 ##. 셋 ##째, 퇴 ##원 환자의 지속 ##적 치료 [MASK] ##. 넷 ##째, 건강 ##진 ##단 ##을 [MASK] 질 ##병 ##의 예 ##방 및 조 ##기 ##발 ##견 ##. 다 ##섯 ##째, 마 ##비 기능 ##의 회 ##복 ##, 잔 ##존 ##기능 ##의 유지 ##, 보 ##완 ##기능 ##의 개발 및 연구 ##와 수 ##련 ##의 Frères [MASK] [MASK] ##소 ##로 ##의 역할 등을 담 ##당 ##하고 있다( ##최 ##승 ##근 ##, ##200 ##1). ##앞 ##에서 언 ##급 ##한 [MASK] ##과 더 ##불 ##어 외 [MASK] ##진 ##료 ##부 ##문 ##은 환자의 증가 ##에 따른 그 변화 상황 ##에 민 ##감 ##하게 반응 ##하고, 전문화 및 세 ##분 ##화 ##에 대 ##응 ##하는 공간 구성 ##의 변화 ##에 대한 요구 ##가 크 ##기 때문에 병 ##원의 의료 ##수준 ##을 파악 ##할 수 있는 중요한 척 ##도 역할을 한다. ##2) Character ##istics of Out ##pati ##ent Department of Psychiatry ##신 ##경 ##정 ##신 ##과 ##에서 정 ##신 ##과의 분 ##화 ##, 정 ##신 ##과 ##에서 정 ##신 [MASK] ##의 ##학과 ##로 ##의 개 ##명 등의 환경 ##적 변화 ##와 정 ##신 ##질 ##환 ##에 대한 인식 개선 ##은 [SEP] 식 ##수 ##(C ##ix ##ous [MASK] 주 ##변 ##부에 위치 ##해 발 ##화 [MASK] 기 ##회를 얻 ##지 [MASK] ##함으로써 남 ##성 중심 ##적 역 ##사에 ##서 소 ##외 ##되어 온 여성 ##의 삶 ##과 정 ##체 ##성을 드 ##러 ##내 ##기 위해 여성 ##적 글 ##쓰 ##기를 제시 ##한다 8 . 스 ##피 [MASK] ##(S ##pi ##vak ##)은 주 [MASK] 아닌 대상으로 간 ##주 ##되는 제 ##3 ##세 [MASK] 여성 ##들은 자신의 언 ##어를 가 ##질 수 있어 ##야 하며 ##, 지식 ##인 여성 ##은 말 ##걸 ##기를 통해 이 ##들의 경험 ##을 담 ##론 ##의 영역 ##으로 끌 ##어 ##와 ##야 한다 ##고 주 ##장 ##한다 5 . ##III ##. 여성 ##주의 다 ##큐 ##멘 ##터 ##리 연구 ##멀 ##비 ##( ##M ##ul ##vey ##)가 미 [MASK] ##어 ##에 재 ##현 ##되는 여성 ##의 이미 ##지에 대한 남 ##성 ##적 응 ##시 ##라는 개념 ##을 제시 ##한 후 9 영화 ##이론 ##을 정 ##신 ##분석 ##학 ##에 접 ##목 ##시 ##킨 씨 ##네 페 ##미 ##니 ##즘 ##에 대한 연구가 ##stande ##발 ##히 이루어 ##졌 ##으나 페 ##미 ##니 ##즘 영화 ##이론 ##은 할 ##리 ##우 ##드 극 ##영 ##화를 주 연구 ##대상으로 삼 ##기 때문에 여성 ##주의 다 [MASK] ##멘 ##터 ##리에 대한 연구는 상대적으로 드 ##물 ##다 10 . ##다 ##큐 ##멘 ##터 ##리 연구에서 여성 ##주의 다 ##큐 ##멘 ##터 ##리는 종 ##종 언 ##급 ##되 ##나 많은 비 ##중 ##을 차 ##지 ##하지 ##는 않는다 ##. [SEP]\n",
      "INFO:tensorflow:input_ids: 101 12310 19905 12424 119875 15387 9942 17342 10739 41605 14040 12638 9987 119199 10530 18154 119608 11287 119873 119711 11925 110858 28981 30858 103 110862 10324 9319 12508 30858 110862 10276 119558 34079 9597 103 18623 38688 14646 25934 10459 119854 10892 39402 119655 9750 119685 9879 14279 14843 9460 13767 120408 119807 12178 119646 110864 9105 119685 9355 108280 9645 14279 119713 23969 119896 16439 9645 14279 14843 120075 13767 120156 9708 99118 9316 9645 14279 29935 14646 119797 110864 9441 119685 9880 14279 120156 119732 14801 119807 103 110864 9015 119685 119681 18623 24989 10622 103 9709 73380 10459 9576 42337 9316 9678 12310 51431 118634 110864 9056 103906 119685 9246 29455 119646 10459 9998 70915 110862 9653 79718 120123 10459 119729 110862 9356 119160 120123 10459 110176 9316 91785 12638 9460 101440 10459 106524 103 103 22333 11261 10459 120129 33727 9064 21928 12453 119798 119273 48210 50248 110862 89478 120179 119120 11489 9548 37568 11102 103 11882 9074 118992 12965 9597 103 18623 38688 14646 25934 10892 120156 119561 10530 110463 8924 119586 119742 10530 9311 105197 17594 119721 119604 120929 9316 9435 37712 18227 10530 9069 119187 12178 119711 119571 10459 119586 10530 18154 119703 11287 9834 12310 20729 9355 74125 119883 119825 10622 119720 14843 9460 13767 63552 9745 12092 69144 119575 119647 90207 108477 10108 14504 33399 11405 12933 10108 97313 25387 31720 16605 25387 11882 11489 9670 25387 102003 9367 18227 110862 9670 25387 11882 11489 9670 25387 103 10459 65610 11261 10459 8857 16758 28697 119606 14801 119586 12638 9670 25387 48599 51745 10530 18154 119644 119744 10892 102 9486 15891 119936 13274 13499 103 9689 118985 52961 119656 14523 9323 18227 103 8932 88168 9550 12508 103 119866 8987 17138 119947 14801 9566 86580 12424 9448 78705 16855 9582 100006 10459 9409 11882 9670 29683 36456 9113 30873 31605 12310 19905 100006 14801 8927 119103 29669 119591 14102 129 119 9477 97146 103 119941 12675 95982 119748 9689 103 63783 119640 8845 16323 24683 9672 10884 24982 103 100006 22879 31956 9548 80940 8843 48599 9460 45893 21711 64866 110862 119810 12030 100006 10892 9251 118624 29669 25605 9638 25258 119698 10622 9064 42769 10459 119663 11467 8973 12965 12638 21711 16139 11664 9689 13890 14102 126 119 61514 110864 100006 37224 9056 119324 118929 21876 12692 91785 118923 29455 110858 11517 10604 50038 120060 9309 103 12965 10530 9659 30842 24683 100006 10459 71771 84899 18154 8987 17138 14801 9636 14040 60362 119739 10622 119591 11102 10003 130 42428 120290 10622 9670 25387 119665 23321 10530 9669 68055 14040 119330 9516 77884 9918 22458 25503 119229 10530 18154 119778 98386 51431 18108 119645 119210 35466 9918 22458 25503 119229 42428 120290 10892 9955 12692 27355 15001 8925 30858 56999 9689 91785 120583 9410 12310 20729 100006 37224 9056 103 118929 21876 46766 18154 119634 120046 9113 29364 11903 10150 119 11903 119324 118929 21876 12692 119674 100006 37224 9056 119324 118929 21876 26344 9684 22200 9548 37568 118800 16439 25685 9379 41693 10622 9730 12508 23665 11018 52723 110864 102\n",
      "I1120 16:06:43.943116 47619347533312 create_pretraining_data.py:161] input_ids: 101 12310 19905 12424 119875 15387 9942 17342 10739 41605 14040 12638 9987 119199 10530 18154 119608 11287 119873 119711 11925 110858 28981 30858 103 110862 10324 9319 12508 30858 110862 10276 119558 34079 9597 103 18623 38688 14646 25934 10459 119854 10892 39402 119655 9750 119685 9879 14279 14843 9460 13767 120408 119807 12178 119646 110864 9105 119685 9355 108280 9645 14279 119713 23969 119896 16439 9645 14279 14843 120075 13767 120156 9708 99118 9316 9645 14279 29935 14646 119797 110864 9441 119685 9880 14279 120156 119732 14801 119807 103 110864 9015 119685 119681 18623 24989 10622 103 9709 73380 10459 9576 42337 9316 9678 12310 51431 118634 110864 9056 103906 119685 9246 29455 119646 10459 9998 70915 110862 9653 79718 120123 10459 119729 110862 9356 119160 120123 10459 110176 9316 91785 12638 9460 101440 10459 106524 103 103 22333 11261 10459 120129 33727 9064 21928 12453 119798 119273 48210 50248 110862 89478 120179 119120 11489 9548 37568 11102 103 11882 9074 118992 12965 9597 103 18623 38688 14646 25934 10892 120156 119561 10530 110463 8924 119586 119742 10530 9311 105197 17594 119721 119604 120929 9316 9435 37712 18227 10530 9069 119187 12178 119711 119571 10459 119586 10530 18154 119703 11287 9834 12310 20729 9355 74125 119883 119825 10622 119720 14843 9460 13767 63552 9745 12092 69144 119575 119647 90207 108477 10108 14504 33399 11405 12933 10108 97313 25387 31720 16605 25387 11882 11489 9670 25387 102003 9367 18227 110862 9670 25387 11882 11489 9670 25387 103 10459 65610 11261 10459 8857 16758 28697 119606 14801 119586 12638 9670 25387 48599 51745 10530 18154 119644 119744 10892 102 9486 15891 119936 13274 13499 103 9689 118985 52961 119656 14523 9323 18227 103 8932 88168 9550 12508 103 119866 8987 17138 119947 14801 9566 86580 12424 9448 78705 16855 9582 100006 10459 9409 11882 9670 29683 36456 9113 30873 31605 12310 19905 100006 14801 8927 119103 29669 119591 14102 129 119 9477 97146 103 119941 12675 95982 119748 9689 103 63783 119640 8845 16323 24683 9672 10884 24982 103 100006 22879 31956 9548 80940 8843 48599 9460 45893 21711 64866 110862 119810 12030 100006 10892 9251 118624 29669 25605 9638 25258 119698 10622 9064 42769 10459 119663 11467 8973 12965 12638 21711 16139 11664 9689 13890 14102 126 119 61514 110864 100006 37224 9056 119324 118929 21876 12692 91785 118923 29455 110858 11517 10604 50038 120060 9309 103 12965 10530 9659 30842 24683 100006 10459 71771 84899 18154 8987 17138 14801 9636 14040 60362 119739 10622 119591 11102 10003 130 42428 120290 10622 9670 25387 119665 23321 10530 9669 68055 14040 119330 9516 77884 9918 22458 25503 119229 10530 18154 119778 98386 51431 18108 119645 119210 35466 9918 22458 25503 119229 42428 120290 10892 9955 12692 27355 15001 8925 30858 56999 9689 91785 120583 9410 12310 20729 100006 37224 9056 103 118929 21876 46766 18154 119634 120046 9113 29364 11903 10150 119 11903 119324 118929 21876 12692 119674 100006 37224 9056 119324 118929 21876 26344 9684 22200 9548 37568 118800 16439 25685 9379 41693 10622 9730 12508 23665 11018 52723 110864 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.943644 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.943979 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 8 24 35 90 98 137 138 139 160 166 247 274 282 287 323 329 338 397 441 470\n",
      "I1120 16:06:43.944145 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 8 24 35 90 98 137 138 139 160 166 247 274 282 287 323 329 338 397 441 470\n",
      "INFO:tensorflow:masked_lm_ids: 10739 49515 37388 119611 119837 10459 119583 13890 119854 37388 120126 119706 10459 9290 118963 92319 21611 48446 9996 119324\n",
      "I1120 16:06:43.944376 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 10739 49515 37388 119611 119837 10459 119583 13890 119854 37388 120126 119706 10459 9290 118963 92319 21611 48446 9996 119324\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.944594 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "I1120 16:06:43.944813 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.946537 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] [MASK] ##에 의한 아 ##포 ##리 ##포 ##포 ##린 ##- ##III ##의 흡 ##수 ##A ##poli ##pop ##hor ##in ##- ##III up ##take [MASK] the adult teste ##s in the [MASK] ##x moth ##, Galleria mell ##one ##lla ##윤 ##화 ##경 초록 ##아 ##포 ##리 ##포 羨 ##린 ##- ##III ( ##apo ##L ##p ##- ##III ##)를 [MASK] ##벌 ##부 ##채 ##명 ##나 ##방 종 ##령 유 ##충 혈 ##림 ##프로 ##부터 KB ##r 농 ##도 ##구 ##배 초 ##원 [MASK] ##분리 ##와 겔 ##크 ##로 ##마 ##토 ##그 ##래 ##피 ##(S ##ep ##had ##ex G ##-100 ##)를 이용하여 분리 ##, 정 ##제 ##하였다. KB ##r 농 ##도 ##구 ##배 초 ##원 ##심 ##분리 ##가 끝 ##난 후 ##, 리 [MASK] ##포 ##린 ##을 제외 ##한 분 ##획 ( ##lip ##op ##hor ##in [MASK] ##fre ##e fraction ##s ##)을 겔 ##크 ##로 ##마 ##토 ##그 ##래 ##νές 시료 ##로 사용 ##하였으며, 겔 [MASK] ##로 ##마 ##토 ##그 ##래 ##피 ##를 행 ##한 ##후 sodium do ##de ##cy ##l sul ##fat ##e ( ##SD ##S ##) ##- ##전기 ##영 ##동 ##으로 apo ##L ##p ##- ##III ##의 정 ##제를 확인 ##하였다. 또한, 본 연구에서는 유 ##충 혈 ##림 ##프로 ##부터 정 ##제 ##된 apo ##L ##p ##- ##III ##가 꿀 ##벌 ##부 ##채 ##명 ##나 ##방 ##의 성 ##충 정 ##소 ##에 의해 흡 ##수 [MASK] 지 ##를 조사 ##하였다. 우 ##화 ##한 지 1일 또는 2일 ##된 성 ##충 ##으로 ##부터 성 ##충 정 ##소를 차 ##가 ##운 링 ##거 ##액 ##에서 분리 ##한 후 조직 배 ##양의 시료 [MASK] 사용하였다. 순 ##수 정 ##제한 [MASK] ##L ##p ##- ##III ##를 di ##meth ##yl sul ##fo ##xide ( ##DM ##S ##O ##)에 녹 ##인 형 ##광 ##물질 fl ##uo ##res ##cei ##n iso ##thi ##oc ##yana ##te ( ##F ##IT ##C ##)와 상 ##온 ##에서 계속 저 ##어 ##가 ##면서 1 ##시간 동안 배 ##양 ##하였다. F ##IT ##C ##로 표 ##지 ##된 apo ##L ##p ##- ##III ( ##F ##IT ##C ##- ##lab ##eled apo ##L ##p ##- ##III ##)를 Sep ##had ##ex G ##- ##25 PD ##-10 column ##을 이용하여 정 ##제 ##하고 확인 ##하였다. 정 ##제 ##된 F ##IT ##C ##- ##lab ##eled [MASK] ##L ##p ##- ##III ##와 성 ##충 정 ##소 [MASK] ##을 상 ##온 ##에서 30 ##분 ##간 배 ##양 ##하였다. 배 ##양 후 형 ##광 ##현 ##미 ##경 ( ##f ##lu ##ores ##cence A ##xi ##os ##kop micro ##scope ##)과 SD ##S ##- ##전기 ##영 ##동을 이용하여 F ##IT ##C ##- ##lab ##eled apo ##L ##p ##- ##III ##가 정 ##소 조직 ##으로 들어 ##가는 지 ##의 여 ##부를 확인 ##하였다. 그 결과 F ##IT ##C ##- ##lab ##eled apo ##L ##p ##- ##III ##가 성 [SEP] [MASK] ##poli ##pop ##hor ##in ##- ##III ( ##apo ##L ##p [MASK] ##III ##) was isolated and pur ##ified from the last larva ##l [MASK] ##ol ##ym ##ph of Galleria mell ##one ##lla by KB ##r gradi ##ent ultra ##cent ##rif ##ugati ##on and gel ch ##roma ##tography ( ##S ##ep ##had ##ex G ##-100 ##). [SEP]\n",
      "I1120 16:06:43.947036 47619347533312 create_pretraining_data.py:151] tokens: [CLS] [MASK] ##에 의한 아 ##포 ##리 ##포 ##포 ##린 ##- ##III ##의 흡 ##수 ##A ##poli ##pop ##hor ##in ##- ##III up ##take [MASK] the adult teste ##s in the [MASK] ##x moth ##, Galleria mell ##one ##lla ##윤 ##화 ##경 초록 ##아 ##포 ##리 ##포 羨 ##린 ##- ##III ( ##apo ##L ##p ##- ##III ##)를 [MASK] ##벌 ##부 ##채 ##명 ##나 ##방 종 ##령 유 ##충 혈 ##림 ##프로 ##부터 KB ##r 농 ##도 ##구 ##배 초 ##원 [MASK] ##분리 ##와 겔 ##크 ##로 ##마 ##토 ##그 ##래 ##피 ##(S ##ep ##had ##ex G ##-100 ##)를 이용하여 분리 ##, 정 ##제 ##하였다. KB ##r 농 ##도 ##구 ##배 초 ##원 ##심 ##분리 ##가 끝 ##난 후 ##, 리 [MASK] ##포 ##린 ##을 제외 ##한 분 ##획 ( ##lip ##op ##hor ##in [MASK] ##fre ##e fraction ##s ##)을 겔 ##크 ##로 ##마 ##토 ##그 ##래 ##νές 시료 ##로 사용 ##하였으며, 겔 [MASK] ##로 ##마 ##토 ##그 ##래 ##피 ##를 행 ##한 ##후 sodium do ##de ##cy ##l sul ##fat ##e ( ##SD ##S ##) ##- ##전기 ##영 ##동 ##으로 apo ##L ##p ##- ##III ##의 정 ##제를 확인 ##하였다. 또한, 본 연구에서는 유 ##충 혈 ##림 ##프로 ##부터 정 ##제 ##된 apo ##L ##p ##- ##III ##가 꿀 ##벌 ##부 ##채 ##명 ##나 ##방 ##의 성 ##충 정 ##소 ##에 의해 흡 ##수 [MASK] 지 ##를 조사 ##하였다. 우 ##화 ##한 지 1일 또는 2일 ##된 성 ##충 ##으로 ##부터 성 ##충 정 ##소를 차 ##가 ##운 링 ##거 ##액 ##에서 분리 ##한 후 조직 배 ##양의 시료 [MASK] 사용하였다. 순 ##수 정 ##제한 [MASK] ##L ##p ##- ##III ##를 di ##meth ##yl sul ##fo ##xide ( ##DM ##S ##O ##)에 녹 ##인 형 ##광 ##물질 fl ##uo ##res ##cei ##n iso ##thi ##oc ##yana ##te ( ##F ##IT ##C ##)와 상 ##온 ##에서 계속 저 ##어 ##가 ##면서 1 ##시간 동안 배 ##양 ##하였다. F ##IT ##C ##로 표 ##지 ##된 apo ##L ##p ##- ##III ( ##F ##IT ##C ##- ##lab ##eled apo ##L ##p ##- ##III ##)를 Sep ##had ##ex G ##- ##25 PD ##-10 column ##을 이용하여 정 ##제 ##하고 확인 ##하였다. 정 ##제 ##된 F ##IT ##C ##- ##lab ##eled [MASK] ##L ##p ##- ##III ##와 성 ##충 정 ##소 [MASK] ##을 상 ##온 ##에서 30 ##분 ##간 배 ##양 ##하였다. 배 ##양 후 형 ##광 ##현 ##미 ##경 ( ##f ##lu ##ores ##cence A ##xi ##os ##kop micro ##scope ##)과 SD ##S ##- ##전기 ##영 ##동을 이용하여 F ##IT ##C ##- ##lab ##eled apo ##L ##p ##- ##III ##가 정 ##소 조직 ##으로 들어 ##가는 지 ##의 여 ##부를 확인 ##하였다. 그 결과 F ##IT ##C ##- ##lab ##eled apo ##L ##p ##- ##III ##가 성 [SEP] [MASK] ##poli ##pop ##hor ##in ##- ##III ( ##apo ##L ##p [MASK] ##III ##) was isolated and pur ##ified from the last larva ##l [MASK] ##ol ##ym ##ph of Galleria mell ##one ##lla by KB ##r gradi ##ent ultra ##cent ##rif ##ugati ##on and gel ch ##roma ##tography ( ##S ##ep ##had ##ex G ##-100 ##). [SEP]\n",
      "INFO:tensorflow:input_ids: 101 103 10530 60804 9519 55530 12692 55530 55530 27654 110863 61514 10459 10020 15891 10738 29378 63229 39854 10245 110863 61514 10741 47529 103 10105 30521 62574 10107 10106 10105 103 10686 28877 110862 58725 121758 12926 11083 119182 18227 31720 120040 16985 55530 12692 55530 6427 27654 110863 61514 113 102161 11369 10410 110863 61514 119638 103 68773 14646 119253 16758 16439 42337 9684 44220 9625 119276 9979 67527 120281 17655 47971 10129 9027 12092 17196 76036 9757 14279 103 120377 12638 8874 20308 11261 23811 26444 78136 37388 97146 119941 19986 33796 28580 144 120726 119638 119593 120095 110862 9670 17730 119548 47971 10129 9027 12092 17196 76036 9757 14279 71013 120377 11287 8977 33305 10003 110862 9238 103 55530 27654 10622 119970 11102 9367 103155 113 69553 13362 39854 10245 103 37135 10112 107433 10107 119643 8874 20308 11261 23811 26444 78136 37388 60945 119923 11261 119550 119654 8874 103 11261 23811 26444 78136 37388 97146 11513 9966 11102 31531 90371 10149 10253 11710 10161 12037 25616 10112 113 83452 10731 110859 110863 120361 30858 18778 11467 34768 11369 10410 110863 61514 10459 9670 53726 84300 119548 120036 9358 119618 9625 119276 9979 67527 120281 17655 9670 17730 13441 34768 11369 10410 110863 61514 11287 8964 68773 14646 119253 16758 16439 42337 10459 9434 119276 9670 22333 10530 23610 10020 15891 103 9706 11513 119595 119548 9604 18227 11102 9706 18329 20625 39788 13441 9434 119276 11467 17655 9434 119276 9670 86488 9730 11287 21614 9245 41521 119122 11489 120095 11102 10003 119682 9330 92290 119923 103 119935 9462 15891 9670 120403 103 11369 10410 110863 61514 11513 10120 120705 27652 12037 21330 44186 113 94138 10731 11403 119716 9023 12030 9983 118649 120085 58768 21187 11234 91199 10115 93455 53504 25125 31523 10216 113 11565 37611 10858 119822 9414 37093 11489 77039 9663 12965 11287 30936 122 100699 41886 9330 37114 119548 143 37611 10858 11261 9934 12508 13441 34768 11369 10410 110863 61514 113 11565 37611 10858 110863 41284 122017 34768 11369 10410 110863 61514 119638 67281 33796 28580 144 110863 69168 65535 120405 41278 10622 119593 9670 17730 12453 84300 119548 9670 17730 13441 143 37611 10858 110863 41284 122017 103 11369 10410 110863 61514 12638 9434 119276 9670 22333 103 10622 9414 37093 11489 10244 37712 18784 9330 37114 119548 9330 37114 10003 9983 118649 30842 22458 31720 113 10575 11435 20183 65217 138 20572 10310 46392 54396 42562 119863 27589 10731 110863 120361 30858 69448 119593 143 37611 10858 110863 41284 122017 34768 11369 10410 110863 61514 11287 9670 22333 119682 11467 71568 68828 9706 10459 9565 73969 84300 119548 8924 85533 143 37611 10858 110863 41284 122017 34768 11369 10410 110863 61514 11287 9434 102 103 29378 63229 39854 10245 110863 61514 113 102161 11369 10410 103 61514 110859 10134 54622 10111 32385 31825 10188 10105 12469 61118 10161 103 11481 16889 28088 10108 58725 121758 12926 11083 10155 47971 10129 101581 11405 71560 25907 52070 85844 10263 10111 74458 18643 84624 107487 113 10731 19986 33796 28580 144 120726 119558 102\n",
      "I1120 16:06:43.947612 47619347533312 create_pretraining_data.py:161] input_ids: 101 103 10530 60804 9519 55530 12692 55530 55530 27654 110863 61514 10459 10020 15891 10738 29378 63229 39854 10245 110863 61514 10741 47529 103 10105 30521 62574 10107 10106 10105 103 10686 28877 110862 58725 121758 12926 11083 119182 18227 31720 120040 16985 55530 12692 55530 6427 27654 110863 61514 113 102161 11369 10410 110863 61514 119638 103 68773 14646 119253 16758 16439 42337 9684 44220 9625 119276 9979 67527 120281 17655 47971 10129 9027 12092 17196 76036 9757 14279 103 120377 12638 8874 20308 11261 23811 26444 78136 37388 97146 119941 19986 33796 28580 144 120726 119638 119593 120095 110862 9670 17730 119548 47971 10129 9027 12092 17196 76036 9757 14279 71013 120377 11287 8977 33305 10003 110862 9238 103 55530 27654 10622 119970 11102 9367 103155 113 69553 13362 39854 10245 103 37135 10112 107433 10107 119643 8874 20308 11261 23811 26444 78136 37388 60945 119923 11261 119550 119654 8874 103 11261 23811 26444 78136 37388 97146 11513 9966 11102 31531 90371 10149 10253 11710 10161 12037 25616 10112 113 83452 10731 110859 110863 120361 30858 18778 11467 34768 11369 10410 110863 61514 10459 9670 53726 84300 119548 120036 9358 119618 9625 119276 9979 67527 120281 17655 9670 17730 13441 34768 11369 10410 110863 61514 11287 8964 68773 14646 119253 16758 16439 42337 10459 9434 119276 9670 22333 10530 23610 10020 15891 103 9706 11513 119595 119548 9604 18227 11102 9706 18329 20625 39788 13441 9434 119276 11467 17655 9434 119276 9670 86488 9730 11287 21614 9245 41521 119122 11489 120095 11102 10003 119682 9330 92290 119923 103 119935 9462 15891 9670 120403 103 11369 10410 110863 61514 11513 10120 120705 27652 12037 21330 44186 113 94138 10731 11403 119716 9023 12030 9983 118649 120085 58768 21187 11234 91199 10115 93455 53504 25125 31523 10216 113 11565 37611 10858 119822 9414 37093 11489 77039 9663 12965 11287 30936 122 100699 41886 9330 37114 119548 143 37611 10858 11261 9934 12508 13441 34768 11369 10410 110863 61514 113 11565 37611 10858 110863 41284 122017 34768 11369 10410 110863 61514 119638 67281 33796 28580 144 110863 69168 65535 120405 41278 10622 119593 9670 17730 12453 84300 119548 9670 17730 13441 143 37611 10858 110863 41284 122017 103 11369 10410 110863 61514 12638 9434 119276 9670 22333 103 10622 9414 37093 11489 10244 37712 18784 9330 37114 119548 9330 37114 10003 9983 118649 30842 22458 31720 113 10575 11435 20183 65217 138 20572 10310 46392 54396 42562 119863 27589 10731 110863 120361 30858 69448 119593 143 37611 10858 110863 41284 122017 34768 11369 10410 110863 61514 11287 9670 22333 119682 11467 71568 68828 9706 10459 9565 73969 84300 119548 8924 85533 143 37611 10858 110863 41284 122017 34768 11369 10410 110863 61514 11287 9434 102 103 29378 63229 39854 10245 110863 61514 113 102161 11369 10410 103 61514 110859 10134 54622 10111 32385 31825 10188 10105 12469 61118 10161 103 11481 16889 28088 10108 58725 121758 12926 11083 10155 47971 10129 101581 11405 71560 25907 52070 85844 10263 10111 74458 18643 84624 107487 113 10731 19986 33796 28580 144 120726 119558 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.948125 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.948581 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 1 24 31 47 58 81 121 134 147 153 225 260 266 365 367 377 442 455 466 479\n",
      "I1120 16:06:43.948827 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 1 24 31 47 58 81 121 134 147 153 225 260 266 365 367 377 442 455 466 479\n",
      "INFO:tensorflow:masked_lm_ids: 22333 10155 11471 55530 8964 71013 55530 110863 97146 20308 24683 11261 34768 41284 34768 119682 37611 138 110863 14166\n",
      "I1120 16:06:43.949033 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 22333 10155 11471 55530 8964 71013 55530 110863 97146 20308 24683 11261 34768 41284 34768 119682 37611 138 110863 14166\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.949241 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "I1120 16:06:43.949430 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.951245 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 교 ##반 ##기 ##, 적 ##하여 ##두 ##, 냉 ##각 ##기 및 질 ##소 ##도입 ##관 ##이 장 ##착 ##된 [MASK] [MASK] ##L 4 ##구 플 ##라 ##스 ##크 ##내 ##에 규 ##정 ##량의 EA ##와 tol ##uen ##e 120 ##ml ##를 투 ##입 ##하고 질 ##소 ##기 ##류 ##하 ##에서 80 까 ##지 가 ##열 ##하였다. 계속 ##해서 규 ##정 ##량 H ##EA ##와 tol [MASK] ##e 75 ##ml ##의 혼합 ##용 ##액 ##을 적 ##하여 ##두 ##를 통해 2 ##시간 ##에 걸쳐 투 ##입 ##하면서 또 다른 여 ##두 ##를 이용하여 미 ##리 준 ##비 ##된 AI ##B ##N 0. ##5 ##g ##과 tol ##uen ##e 60 ##ml [MASK] 촉 ##매 혼합 ##액 ##을 3 ##시간 ##에 [MASK] [MASK] ##하 [MASK] [MASK] ##료 후 같은 온 ##도에서 반응 ##을 1 ##시간 더 유지 ##시 ##킨 다음 감 ##압 ##하 ##에서 용 ##매 ##를 제거 ##하여 고 ##무 ##상 백 ##색 ##의 전 ##구 ##중 ##합 ##체를 제조 ##하였다. ##2. ##3. ##2 열 ##경 ##화 반응 ##얻 ##어진 전 ##구 ##중 ##합 ##체 ##에 tol ##uen ##e ##을 희 ##석 ##용 ##매 ##로 하여 20% o ##. w ##. s ##로 용 ##해 ##한 후 ##, 가 ##교 ##제 ##인 HD ##I ##를 mol ##비 기준 H ##EA ##의 0. ##52 ##배 ##의 범위 ##내 ##에서 투 ##입 ##하고 반응 ##촉 ##매 ##로서 di ##- [MASK] ##- ##but ##yl tin dil ##au ##late ##를 전 ##구 ##중 ##합 ##체의 0. ##1 ##w ##t ##% 첨가 ##하였으며 교 ##반 ##장 [MASK] 사용하여 충 ##분 ##히 [SEP] 고려 ##해야 ##할 설계 ##요소 ##들을 알 ##아 ##보고 수 ##신 ##기 구조 설계 ##에 대하여 고 ##찰 ##하였고 설계 ##구조 ##에 따른 성능 ##분석을 시뮬 ##레이션 ##을 통해 확인해 보 ##았다. ##2. SF ##H 위 ##성 ##통 ##신 시스템 ##에서의 레 ##인 ##징 신호 구조 설계 ##2. ##1 DR [MASK] ##를 이용한 주파 ##수 도 ##약 위 ##성 ##통 ##신 시스템 ##2. ##1. ##1 DR ##T 구조 ##D ##RT ##를 이용한 주파 ##수 도 ##약 위 ##성 ##통 ##신 시스템 ##의 구성 ##은 Fig. 1 ##과 같이 상 ##향 ##링 ##크 주파 ##수 도 ##약 패 ##턴 ##으로 송 ##신 ##하는 지 ##상 ##송 ##신 ##기 ##와 DR ##T ##, 그리고 하 ##향 ##링 ##크 주파 ##수 도 ##약 패 ##턴 ##을 수 ##신 ##하는 수 ##신 ##기로 구성 ##된다. DR ##T ##는 지 ##상 ##에서 올 ##라 ##오는 상 ##향 ##링 ##크 신호 [MASK] 수 ##신 ##하여 RF ##대 ##역 ##에서 IF ##대 [MASK] ##으로 변 ##환 ##한 후 각 주파 [MASK] 도 ##약 그 ##룹 [MASK] 필 ##터 ##링 ##을 한 후 다시 RF ##대 ##역 ##으로 변 ##환 ##하여 하 ##향 ##링 ##크 신호 ##로 송 ##신 ##하는 능 ##동 중 ##계 ##방식 ##의 중 ##계 ##기 ##다. 중 ##계 ##기 내 ##에서 도 ##약 주파 ##수 순 ##서를 바 ##꾸 ##어 refiere ##향 ##링 ##크 ##의 주파 ##수 도 ##약 신호 ##와 하 ##향 ##링 ##크 ##의 주파 ##수 도 ##약 신호 ##의 패 ##턴 ##이 서로 다른 구조 ##를 갖 ##게 ##하여 피 ##탐 ##능 ##력 ##과 항 [SEP]\n",
      "I1120 16:06:43.951737 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 교 ##반 ##기 ##, 적 ##하여 ##두 ##, 냉 ##각 ##기 및 질 ##소 ##도입 ##관 ##이 장 ##착 ##된 [MASK] [MASK] ##L 4 ##구 플 ##라 ##스 ##크 ##내 ##에 규 ##정 ##량의 EA ##와 tol ##uen ##e 120 ##ml ##를 투 ##입 ##하고 질 ##소 ##기 ##류 ##하 ##에서 80 까 ##지 가 ##열 ##하였다. 계속 ##해서 규 ##정 ##량 H ##EA ##와 tol [MASK] ##e 75 ##ml ##의 혼합 ##용 ##액 ##을 적 ##하여 ##두 ##를 통해 2 ##시간 ##에 걸쳐 투 ##입 ##하면서 또 다른 여 ##두 ##를 이용하여 미 ##리 준 ##비 ##된 AI ##B ##N 0. ##5 ##g ##과 tol ##uen ##e 60 ##ml [MASK] 촉 ##매 혼합 ##액 ##을 3 ##시간 ##에 [MASK] [MASK] ##하 [MASK] [MASK] ##료 후 같은 온 ##도에서 반응 ##을 1 ##시간 더 유지 ##시 ##킨 다음 감 ##압 ##하 ##에서 용 ##매 ##를 제거 ##하여 고 ##무 ##상 백 ##색 ##의 전 ##구 ##중 ##합 ##체를 제조 ##하였다. ##2. ##3. ##2 열 ##경 ##화 반응 ##얻 ##어진 전 ##구 ##중 ##합 ##체 ##에 tol ##uen ##e ##을 희 ##석 ##용 ##매 ##로 하여 20% o ##. w ##. s ##로 용 ##해 ##한 후 ##, 가 ##교 ##제 ##인 HD ##I ##를 mol ##비 기준 H ##EA ##의 0. ##52 ##배 ##의 범위 ##내 ##에서 투 ##입 ##하고 반응 ##촉 ##매 ##로서 di ##- [MASK] ##- ##but ##yl tin dil ##au ##late ##를 전 ##구 ##중 ##합 ##체의 0. ##1 ##w ##t ##% 첨가 ##하였으며 교 ##반 ##장 [MASK] 사용하여 충 ##분 ##히 [SEP] 고려 ##해야 ##할 설계 ##요소 ##들을 알 ##아 ##보고 수 ##신 ##기 구조 설계 ##에 대하여 고 ##찰 ##하였고 설계 ##구조 ##에 따른 성능 ##분석을 시뮬 ##레이션 ##을 통해 확인해 보 ##았다. ##2. SF ##H 위 ##성 ##통 ##신 시스템 ##에서의 레 ##인 ##징 신호 구조 설계 ##2. ##1 DR [MASK] ##를 이용한 주파 ##수 도 ##약 위 ##성 ##통 ##신 시스템 ##2. ##1. ##1 DR ##T 구조 ##D ##RT ##를 이용한 주파 ##수 도 ##약 위 ##성 ##통 ##신 시스템 ##의 구성 ##은 Fig. 1 ##과 같이 상 ##향 ##링 ##크 주파 ##수 도 ##약 패 ##턴 ##으로 송 ##신 ##하는 지 ##상 ##송 ##신 ##기 ##와 DR ##T ##, 그리고 하 ##향 ##링 ##크 주파 ##수 도 ##약 패 ##턴 ##을 수 ##신 ##하는 수 ##신 ##기로 구성 ##된다. DR ##T ##는 지 ##상 ##에서 올 ##라 ##오는 상 ##향 ##링 ##크 신호 [MASK] 수 ##신 ##하여 RF ##대 ##역 ##에서 IF ##대 [MASK] ##으로 변 ##환 ##한 후 각 주파 [MASK] 도 ##약 그 ##룹 [MASK] 필 ##터 ##링 ##을 한 후 다시 RF ##대 ##역 ##으로 변 ##환 ##하여 하 ##향 ##링 ##크 신호 ##로 송 ##신 ##하는 능 ##동 중 ##계 ##방식 ##의 중 ##계 ##기 ##다. 중 ##계 ##기 내 ##에서 도 ##약 주파 ##수 순 ##서를 바 ##꾸 ##어 refiere ##향 ##링 ##크 ##의 주파 ##수 도 ##약 신호 ##와 하 ##향 ##링 ##크 ##의 주파 ##수 도 ##약 신호 ##의 패 ##턴 ##이 서로 다른 구조 ##를 갖 ##게 ##하여 피 ##탐 ##능 ##력 ##과 항 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 8907 30134 12310 110862 9664 13374 118802 110862 9001 66540 12310 9316 9709 22333 120853 20595 10739 9657 119248 13441 103 103 11369 125 17196 9944 17342 12605 20308 31605 10530 8922 16605 119900 38478 12638 53183 25733 10112 12048 63308 11513 9881 58303 12453 9709 22333 12310 46520 35506 11489 10832 8939 12508 8843 79604 119548 77039 70146 8922 16605 44321 145 36789 12638 53183 103 10112 11417 63308 10459 120016 24974 119122 10622 9664 13374 118802 11513 25605 123 100699 10530 92210 9881 58303 37341 9144 19709 9565 118802 11513 119593 9309 12692 9691 29455 13441 62405 11274 11537 119560 11166 10240 11882 53183 25733 10112 10709 63308 103 9758 100372 120016 119122 10622 124 100699 10530 103 103 35506 103 103 38688 10003 18589 9582 120188 119721 10622 122 100699 9074 119729 14040 119330 52292 8848 119116 35506 11489 9603 100372 11513 119976 13374 8888 32537 14871 9331 41442 10459 9665 17196 41693 33188 84957 119847 119548 119562 119573 10729 9569 31720 18227 119721 119133 46572 9665 17196 41693 33188 29683 10530 53183 25733 10112 10622 10023 40958 24974 100372 11261 51076 120329 183 110864 191 110864 187 11261 9603 14523 11102 10003 110862 8843 25242 17730 12030 18987 11281 11513 39520 29455 63185 145 36789 10459 119560 92161 76036 10459 119851 31605 11489 9881 58303 12453 119721 119267 100372 92413 10120 110863 103 110863 23170 27652 21629 36031 11705 23953 11513 9665 17196 41693 33188 79025 119560 10759 10874 10123 110855 119836 53529 8907 30134 13890 103 119843 9770 37712 18108 102 119608 108436 14843 119628 119981 25820 9524 16985 120204 9460 25387 12310 119605 119628 10530 68357 8888 99118 36251 119628 119915 10530 110463 119745 120115 120091 120013 10622 25605 120738 9356 119662 119562 38277 12396 9619 17138 43022 25387 119597 119650 9186 12030 119233 119826 119605 119628 119562 10759 45457 103 11513 119728 120088 15891 9087 47289 9619 17138 43022 25387 119597 119562 119589 10759 45457 11090 119605 11490 46935 11513 119728 120088 15891 9087 47289 9619 17138 43022 25387 119597 10459 119571 10892 119603 122 11882 38401 9414 79544 80174 20308 120088 15891 9087 47289 9909 57346 11467 9454 25387 12178 9706 14871 119057 25387 12310 12638 45457 11090 110862 23289 9952 79544 80174 20308 120088 15891 9087 47289 9909 57346 10622 9460 25387 12178 9460 25387 62675 119571 119574 45457 11090 11018 9706 14871 11489 9583 17342 82823 9414 79544 80174 20308 119826 103 9460 25387 13374 72148 14423 23160 11489 25000 14423 103 11467 9352 51745 11102 10003 8844 120088 103 9087 47289 8924 87114 103 9949 21876 80174 10622 9954 10003 25805 72148 14423 23160 11467 9352 51745 13374 9952 79544 80174 20308 119826 11261 9454 25387 12178 9046 18778 9694 21611 120117 10459 9694 21611 12310 119549 9694 21611 12310 8996 11489 9087 47289 120088 15891 9462 99433 9318 118694 12965 62605 79544 80174 20308 10459 120088 15891 9087 47289 119826 12638 9952 79544 80174 20308 10459 120088 15891 9087 47289 119826 10459 9909 57346 10739 67324 19709 119605 11513 8854 14153 13374 9946 119337 74986 28143 11882 9959 102\n",
      "I1120 16:06:43.952344 47619347533312 create_pretraining_data.py:161] input_ids: 101 8907 30134 12310 110862 9664 13374 118802 110862 9001 66540 12310 9316 9709 22333 120853 20595 10739 9657 119248 13441 103 103 11369 125 17196 9944 17342 12605 20308 31605 10530 8922 16605 119900 38478 12638 53183 25733 10112 12048 63308 11513 9881 58303 12453 9709 22333 12310 46520 35506 11489 10832 8939 12508 8843 79604 119548 77039 70146 8922 16605 44321 145 36789 12638 53183 103 10112 11417 63308 10459 120016 24974 119122 10622 9664 13374 118802 11513 25605 123 100699 10530 92210 9881 58303 37341 9144 19709 9565 118802 11513 119593 9309 12692 9691 29455 13441 62405 11274 11537 119560 11166 10240 11882 53183 25733 10112 10709 63308 103 9758 100372 120016 119122 10622 124 100699 10530 103 103 35506 103 103 38688 10003 18589 9582 120188 119721 10622 122 100699 9074 119729 14040 119330 52292 8848 119116 35506 11489 9603 100372 11513 119976 13374 8888 32537 14871 9331 41442 10459 9665 17196 41693 33188 84957 119847 119548 119562 119573 10729 9569 31720 18227 119721 119133 46572 9665 17196 41693 33188 29683 10530 53183 25733 10112 10622 10023 40958 24974 100372 11261 51076 120329 183 110864 191 110864 187 11261 9603 14523 11102 10003 110862 8843 25242 17730 12030 18987 11281 11513 39520 29455 63185 145 36789 10459 119560 92161 76036 10459 119851 31605 11489 9881 58303 12453 119721 119267 100372 92413 10120 110863 103 110863 23170 27652 21629 36031 11705 23953 11513 9665 17196 41693 33188 79025 119560 10759 10874 10123 110855 119836 53529 8907 30134 13890 103 119843 9770 37712 18108 102 119608 108436 14843 119628 119981 25820 9524 16985 120204 9460 25387 12310 119605 119628 10530 68357 8888 99118 36251 119628 119915 10530 110463 119745 120115 120091 120013 10622 25605 120738 9356 119662 119562 38277 12396 9619 17138 43022 25387 119597 119650 9186 12030 119233 119826 119605 119628 119562 10759 45457 103 11513 119728 120088 15891 9087 47289 9619 17138 43022 25387 119597 119562 119589 10759 45457 11090 119605 11490 46935 11513 119728 120088 15891 9087 47289 9619 17138 43022 25387 119597 10459 119571 10892 119603 122 11882 38401 9414 79544 80174 20308 120088 15891 9087 47289 9909 57346 11467 9454 25387 12178 9706 14871 119057 25387 12310 12638 45457 11090 110862 23289 9952 79544 80174 20308 120088 15891 9087 47289 9909 57346 10622 9460 25387 12178 9460 25387 62675 119571 119574 45457 11090 11018 9706 14871 11489 9583 17342 82823 9414 79544 80174 20308 119826 103 9460 25387 13374 72148 14423 23160 11489 25000 14423 103 11467 9352 51745 11102 10003 8844 120088 103 9087 47289 8924 87114 103 9949 21876 80174 10622 9954 10003 25805 72148 14423 23160 11467 9352 51745 13374 9952 79544 80174 20308 119826 11261 9454 25387 12178 9046 18778 9694 21611 120117 10459 9694 21611 12310 119549 9694 21611 12310 8996 11489 9087 47289 120088 15891 9462 99433 9318 118694 12965 62605 79544 80174 20308 10459 120088 15891 9087 47289 119826 12638 9952 79544 80174 20308 10459 120088 15891 9087 47289 119826 10459 9909 57346 10739 67324 19709 119605 11513 8854 14153 13374 9946 119337 74986 28143 11882 9959 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.952855 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.953311 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 21 22 67 75 110 111 120 121 123 124 148 227 251 307 317 402 412 420 425 473\n",
      "I1120 16:06:43.953549 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 21 22 67 75 110 111 120 121 123 124 148 227 251 307 317 402 412 420 425 473\n",
      "INFO:tensorflow:masked_lm_ids: 10757 10147 25733 10622 63308 10459 92210 9664 119548 9684 8888 10115 62672 11090 25387 11513 23160 15891 61844 9414\n",
      "I1120 16:06:43.953753 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 10757 10147 25733 10622 63308 10459 92210 9664 119548 9684 8888 10115 62672 11090 25387 11513 23160 15891 61844 9414\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.953968 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "I1120 16:06:43.954155 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.956049 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] Kim 3 은 양 ##호 ##교사 ##에 의한 정 ##기 ##적 보 ##건 ##교육 실 ##행 ##군 ##과 비 [MASK] ##행 ##군의 비교 ##분석 연구 ##결과 ##에서 건강 ##지식 정도 ##와 건강 ##행 ##위 ##실 ##태 ##에 대해 보 ##건 ##교육 실 ##행 ##군 ##에서 통계 ##적으로 유의 [MASK] 높은 수 ##치가 나타났 ##고, 건강 ##행 ##위에 영향을 미치는 변수 ##로 건강 ##지식 ##, 지 ##각 ##된 건강 ##상태 ##, 성 ##별 ##, 건강 ##에 대한 중요 ##성 인식 ##의 변수가 설명 ##력 있는 것으로 조사 ##하였다. [SEP] 앤 ##트 ##그 ##룹 ##은 [MASK] 홍 [MASK] ##과 상 ##하 ##이에서 동 ##시 ##상 ##장을 추 ##진 ##할 예 ##정이 ##었다. [MASK] ##달 ##금 ##액 ##은 역 ##대 최대 ##규 ##모 ##인 370 ##억 ##달 ##러 ##에 이 ##른다 ##. 알 ##리 ##페 ##이 서비스 업 ##체 앤 ##트 [MASK] ##룹 ##이 주 ##식 ##상 ##장 [MASK] ##전에 이를 연 ##기 ##했다 [MASK] ##푸 ##드 ##빌 [MASK] ##식 ##통 ##에 따르면 중국 금 ##융 ##당 ##국 ##은 마 ##윈 ##회 ##장 ##과 회 ##담 ##에서 이 회 ##사의 [MASK] ##라인 금 ##융 ##사업 ##을 한 ##층 더 엄 ##격 ##하게 감 ##시 ##할 방 ##침 ##이라 ##고 말 ##한 것으로 알려 ##졌다 ##. 마 ##윈 ##회 ##장은 지 ##난 ##달 열 ##렸 ##던 행 ##사에 ##서 중국 [MASK] 금 ##융 ##규 ##제가 시대 ##에 뒤 ##떨 ##어진 것이 ##라 ##며 금 ##융 ##혁 ##신을 주 ##도 ##하고 있는 기술 기업 ##들의 입 ##장을 대 ##변 ##했다. 이 발 ##언 ##이 중국 금 ##융 ##당 ##국의 심 ##사를 건 ##드 [MASK] 괘 ##씸 ##죄 ##에 걸 ##린 것으로 보인다 ##. 앤 ##트 ##그 ##룹 ##은 모 ##바 ##일 ##결 ##제 서비스 알 ##리 ##페 ##이를 제공 ##하고 있는 중국 제 ##1 ##의 결 ##제 서비스 업 ##체 ##이다. 중국 ##은 최근 준 ##비 ##중 ##인 금 ##융 ##정책 ##안 ##에서 혁 ##신을 장 ##려 ##하지만 동시에 핀 ##테 ##크 기업 등을 전 ##면 ##적으로 감독 [MASK] 것을 골 ##자로 핀 ##테 ##크 기업 ##에 대한 규 ##제 ##강 ##화 움 ##직 ##임을 보 ##이고 있다. 아 ##울 ##러 이 ##번 앤 ##트 ##그 ##룹 ##의 상 ##장 ##연 ##기가 그의 따른 것으로 보인다 ##. 안 ##희 ##권 ##기 ##자 ar ##gon in ##ews ##24 ##. [MASK] 네 ##이 ##버 채 ##널 ##에서 아 ##이 ##뉴스 ##24 를 구 ##독 ##해 ##주 ##세 ##요 ##. 재 ##밌 ##는 아 ##이 ##뉴스 ##TV 영상 ##보 ##기 아 ##이 ##뉴스 ##24 [MASK] ##가 ##기 아 ##이 ##뉴스 ##24 무 ##단 ##전 ##재 및 재 ##배 ##포 금 ##지 [SEP]\n",
      "I1120 16:06:43.956474 47619347533312 create_pretraining_data.py:151] tokens: [CLS] Kim 3 은 양 ##호 ##교사 ##에 의한 정 ##기 ##적 보 ##건 ##교육 실 ##행 ##군 ##과 비 [MASK] ##행 ##군의 비교 ##분석 연구 ##결과 ##에서 건강 ##지식 정도 ##와 건강 ##행 ##위 ##실 ##태 ##에 대해 보 ##건 ##교육 실 ##행 ##군 ##에서 통계 ##적으로 유의 [MASK] 높은 수 ##치가 나타났 ##고, 건강 ##행 ##위에 영향을 미치는 변수 ##로 건강 ##지식 ##, 지 ##각 ##된 건강 ##상태 ##, 성 ##별 ##, 건강 ##에 대한 중요 ##성 인식 ##의 변수가 설명 ##력 있는 것으로 조사 ##하였다. [SEP] 앤 ##트 ##그 ##룹 ##은 [MASK] 홍 [MASK] ##과 상 ##하 ##이에서 동 ##시 ##상 ##장을 추 ##진 ##할 예 ##정이 ##었다. [MASK] ##달 ##금 ##액 ##은 역 ##대 최대 ##규 ##모 ##인 370 ##억 ##달 ##러 ##에 이 ##른다 ##. 알 ##리 ##페 ##이 서비스 업 ##체 앤 ##트 [MASK] ##룹 ##이 주 ##식 ##상 ##장 [MASK] ##전에 이를 연 ##기 ##했다 [MASK] ##푸 ##드 ##빌 [MASK] ##식 ##통 ##에 따르면 중국 금 ##융 ##당 ##국 ##은 마 ##윈 ##회 ##장 ##과 회 ##담 ##에서 이 회 ##사의 [MASK] ##라인 금 ##융 ##사업 ##을 한 ##층 더 엄 ##격 ##하게 감 ##시 ##할 방 ##침 ##이라 ##고 말 ##한 것으로 알려 ##졌다 ##. 마 ##윈 ##회 ##장은 지 ##난 ##달 열 ##렸 ##던 행 ##사에 ##서 중국 [MASK] 금 ##융 ##규 ##제가 시대 ##에 뒤 ##떨 ##어진 것이 ##라 ##며 금 ##융 ##혁 ##신을 주 ##도 ##하고 있는 기술 기업 ##들의 입 ##장을 대 ##변 ##했다. 이 발 ##언 ##이 중국 금 ##융 ##당 ##국의 심 ##사를 건 ##드 [MASK] 괘 ##씸 ##죄 ##에 걸 ##린 것으로 보인다 ##. 앤 ##트 ##그 ##룹 ##은 모 ##바 ##일 ##결 ##제 서비스 알 ##리 ##페 ##이를 제공 ##하고 있는 중국 제 ##1 ##의 결 ##제 서비스 업 ##체 ##이다. 중국 ##은 최근 준 ##비 ##중 ##인 금 ##융 ##정책 ##안 ##에서 혁 ##신을 장 ##려 ##하지만 동시에 핀 ##테 ##크 기업 등을 전 ##면 ##적으로 감독 [MASK] 것을 골 ##자로 핀 ##테 ##크 기업 ##에 대한 규 ##제 ##강 ##화 움 ##직 ##임을 보 ##이고 있다. 아 ##울 ##러 이 ##번 앤 ##트 ##그 ##룹 ##의 상 ##장 ##연 ##기가 그의 따른 것으로 보인다 ##. 안 ##희 ##권 ##기 ##자 ar ##gon in ##ews ##24 ##. [MASK] 네 ##이 ##버 채 ##널 ##에서 아 ##이 ##뉴스 ##24 를 구 ##독 ##해 ##주 ##세 ##요 ##. 재 ##밌 ##는 아 ##이 ##뉴스 ##TV 영상 ##보 ##기 아 ##이 ##뉴스 ##24 [MASK] ##가 ##기 아 ##이 ##뉴스 ##24 무 ##단 ##전 ##재 및 재 ##배 ##포 금 ##지 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 13539 124 9632 9543 20309 120228 10530 60804 9670 12310 14801 9356 71439 119696 9489 25549 17360 11882 9379 103 25549 46741 119572 119665 91785 119712 11489 119681 120268 107657 12638 119681 25549 19855 31503 83616 10530 33378 9356 71439 119696 9489 25549 17360 11489 119709 17022 119676 103 55600 9460 104504 119660 119563 119681 25549 73450 58088 119610 119934 11261 119681 120268 110862 9706 66540 13441 119681 119946 110862 9434 61844 110862 119681 10530 18154 119692 17138 119644 10459 120581 119699 28143 13767 23925 119595 119548 102 9534 15184 78136 87114 10892 103 9992 103 11882 9414 35506 120744 9095 14040 14871 35963 9765 18623 14843 9576 98489 119664 103 89851 40032 119122 10892 9566 14423 99405 69753 39420 12030 24145 91837 89851 30873 10530 9638 66346 110864 9524 12692 119391 10739 119617 9554 29683 9534 15184 103 87114 10739 9689 21155 14871 13890 103 68767 35756 9568 12310 12490 103 119405 15001 119002 103 21155 43022 10530 59355 45397 8928 119184 21928 20479 10892 9246 119178 14863 13890 11882 9998 105462 11489 9638 9998 53023 103 120051 8928 119184 119957 10622 9954 70450 9074 9553 45465 17594 8848 14040 14843 9328 119285 119671 11664 9251 11102 23925 120073 32855 110864 9246 119178 14863 63671 9706 33305 89851 9569 118881 23990 9966 86580 12424 45397 103 8928 119184 69753 54480 102080 10530 9109 118836 46572 27487 17342 21406 8928 119184 119432 70203 9689 12092 12453 13767 119578 119667 25258 9645 35963 9069 118985 119943 9638 9323 48036 10739 45397 8928 119184 21928 39485 9491 32159 8865 15001 103 122210 125566 119216 10530 8867 27654 23925 90923 110864 9534 15184 78136 87114 10892 9283 42144 18392 74322 17730 119617 9524 12692 119391 66623 119611 12453 13767 45397 9672 10759 10459 8881 17730 119617 9554 29683 119555 45397 10892 119852 9691 29455 41693 12030 8928 119184 120216 34951 11489 9977 70203 9657 26737 120140 58248 9948 119351 20308 119667 33727 9665 14867 17022 81571 103 21371 8892 57713 9948 119351 20308 119667 10530 18154 8922 17730 47181 18227 9608 33077 96972 9356 54355 119547 9519 78123 30873 9638 35465 9534 15184 78136 87114 10459 9414 13890 25486 47869 21555 110463 23925 90923 110864 9521 49515 25347 12310 13764 10456 17928 10106 76754 53398 110864 103 9011 10739 41605 9738 49881 11489 9519 10739 90947 53398 9233 8908 80331 14523 16323 24982 48549 110864 9659 121901 11018 9519 10739 90947 18686 119859 30005 12310 9519 10739 90947 53398 103 11287 12310 9519 10739 90947 53398 9294 24989 16617 36210 9316 9659 76036 55530 8928 12508 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.957047 47619347533312 create_pretraining_data.py:161] input_ids: 101 13539 124 9632 9543 20309 120228 10530 60804 9670 12310 14801 9356 71439 119696 9489 25549 17360 11882 9379 103 25549 46741 119572 119665 91785 119712 11489 119681 120268 107657 12638 119681 25549 19855 31503 83616 10530 33378 9356 71439 119696 9489 25549 17360 11489 119709 17022 119676 103 55600 9460 104504 119660 119563 119681 25549 73450 58088 119610 119934 11261 119681 120268 110862 9706 66540 13441 119681 119946 110862 9434 61844 110862 119681 10530 18154 119692 17138 119644 10459 120581 119699 28143 13767 23925 119595 119548 102 9534 15184 78136 87114 10892 103 9992 103 11882 9414 35506 120744 9095 14040 14871 35963 9765 18623 14843 9576 98489 119664 103 89851 40032 119122 10892 9566 14423 99405 69753 39420 12030 24145 91837 89851 30873 10530 9638 66346 110864 9524 12692 119391 10739 119617 9554 29683 9534 15184 103 87114 10739 9689 21155 14871 13890 103 68767 35756 9568 12310 12490 103 119405 15001 119002 103 21155 43022 10530 59355 45397 8928 119184 21928 20479 10892 9246 119178 14863 13890 11882 9998 105462 11489 9638 9998 53023 103 120051 8928 119184 119957 10622 9954 70450 9074 9553 45465 17594 8848 14040 14843 9328 119285 119671 11664 9251 11102 23925 120073 32855 110864 9246 119178 14863 63671 9706 33305 89851 9569 118881 23990 9966 86580 12424 45397 103 8928 119184 69753 54480 102080 10530 9109 118836 46572 27487 17342 21406 8928 119184 119432 70203 9689 12092 12453 13767 119578 119667 25258 9645 35963 9069 118985 119943 9638 9323 48036 10739 45397 8928 119184 21928 39485 9491 32159 8865 15001 103 122210 125566 119216 10530 8867 27654 23925 90923 110864 9534 15184 78136 87114 10892 9283 42144 18392 74322 17730 119617 9524 12692 119391 66623 119611 12453 13767 45397 9672 10759 10459 8881 17730 119617 9554 29683 119555 45397 10892 119852 9691 29455 41693 12030 8928 119184 120216 34951 11489 9977 70203 9657 26737 120140 58248 9948 119351 20308 119667 33727 9665 14867 17022 81571 103 21371 8892 57713 9948 119351 20308 119667 10530 18154 8922 17730 47181 18227 9608 33077 96972 9356 54355 119547 9519 78123 30873 9638 35465 9534 15184 78136 87114 10459 9414 13890 25486 47869 21555 110463 23925 90923 110864 9521 49515 25347 12310 13764 10456 17928 10106 76754 53398 110864 103 9011 10739 41605 9738 49881 11489 9519 10739 90947 53398 9233 8908 80331 14523 16323 24982 48549 110864 9659 121901 11018 9519 10739 90947 18686 119859 30005 12310 9519 10739 90947 53398 103 11287 12310 9519 10739 90947 53398 9294 24989 16617 36210 9316 9659 76036 55530 8928 12508 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.957525 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.957977 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 20 47 49 56 90 94 96 111 139 146 152 156 168 178 217 259 324 374 375 407\n",
      "I1120 16:06:43.958213 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 20 47 49 56 90 94 96 111 139 146 152 156 168 178 217 259 324 374 375 407\n",
      "INFO:tensorflow:masked_lm_ids: 31503 17022 17594 25549 15184 44015 119312 9678 78136 9707 80622 9448 119178 9582 10459 26737 12178 22530 9011 71433\n",
      "I1120 16:06:43.958407 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 31503 17022 17594 25549 15184 44015 119312 9678 78136 9707 80622 9448 119178 9582 10459 26737 12178 22530 9011 71433\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.958601 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "I1120 16:06:43.958777 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.960507 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 미국 국 ##립 ##과학 ##재 ##단 ##( ##NS ##F ##)에서 오 ##래 ##전 ##부터 민 ##간 ##전문 ##가 PM ( [MASK] [MASK] ##ct Manager ##)을 운영 ##해 ##오 ##고 ##2) 있으며 18 , [MASK] ##, 일본 등 선 ##진 ##국 ##에서도 이와 유사 ##한 제 ##도를 도입 ##하고 있다 3 . ##국가 ##에서 출 ##연 ##금 또는 공 ##공 ##기 ##금 ##으로 연구 ##개발 보 ##조 ##금 ##을 지원 ##하여 추 ##진 ##하는 모든 연구 ##개발 ##사업 ##은 국가 ##연구 ##개발 ##사업 [MASK] 관리 등에 관한 [MASK] ##정 ##( ##대 ##통 ##령 ##령 제 ##26 ##7 ##2 ##9 ##호 ##, 2015. 12. [MASK] [MASK] 일부 ##개 ##정 ##)에 따른 ##다. 이 규 ##정의 핵 ##심 ##인 국가 [MASK] ##개발 ##사업 ##의 기 ##획 관리 평가 ##( ##제 2 ##장 ##)에서는 국가 ##연구 ##개발 ##사업 추 ##진 ##에 필요한 기술 ##적 ##, 경제 ##적 타 ##당 ##성 등에 대한 사 ##전 [MASK] 또는 기 ##획 ##연구 ##, 기술 ##수 ##요 ##조사 ##, 연구 ##개발 ##과 ##제 선정 ##, ##연구 ##비 관리 ##체 ##계 평가 ##, 연구 ##개발 ##성과 보고 및 평가 등을 규 ##정 ##하여 기술 ##기 ##획 ##체 ##계 ##의 근 ##간이 되고 있다. 한편 ##, IC ##T 분야 ##의 연구 ##개발 ##사업 ##은 별 ##도의 정보 ##통 ##신 방송 연구 ##개발 관리 ##규 [MASK] ##( ##미 ##래 ##창 ##조 ##과학 ##부 고 ##시 제 ##2016 ##- ##4 ##호 ##, 2016. 1. 26 ##. 일부 ##개 ##정 ##)에서 기술 ##기 ##획 전 ##반 ##의 용 ##어 ##, 추 ##진 ##체 ##계 ##, 직무 ##, 절 ##차 등을 정의 ##하고 있으며, 연구 ##개발 ##사업 구분 ##은 정책 ##과 ##제 ##, 지정 ##과 ##제 ##, 자 ##유 ##과 ##제로 나 ##누 ##어진 ##다. IC ##T 분야 ##의 기술 ##개발 수행 ##관리 ##는 정보 ##통 ##신 방송 기술 ##개발 ##사업 수행 ##관리 ##지 ##침 ##, 미 [MASK] ##창 ##조 ##과학 ##부 훈 ##령 제 ##17 ##8 ##호 ##, 2016. 1. 26 ##. ##일부 ##개 ##정 ##)과 정보 ##통 ##신 방송 기반 ##조 ##성 사업 수행 ##관리 ##지 ##침 ##, 미 ##래 ##창 ##조 ##과학 ##부 훈 ##령 제 [MASK] [MASK] ##호 ##, 2016. 1. 26 [MASK] 일부 ##개 ##정 ##)에 의 ##거 수 ##요 ##조사 등 과 ##제 ##기 ##획 단계 ##를 거쳐 RF ##P 작 ##성, 사업 ##공 ##고, 선정 ##평가 ##, 진 ##도 [MASK] ##검 ##, 연 ##차 ##평가 ##, 최종 ##평가 ##, 사업 ##화 ##의 절 ##차 ##에 따라 과 ##제 ##선정 ##, 협 ##약 ##체 ##결 ##, 사업 ##비 ##정 ##산 등이 이루어 ##지고 있다. 우리나라 ##의 [MASK] ##T 연구 ##개발 ##사업 정책 ##은 전략 ##적 기술 ##개발 ##을 통한 산업 발전 ##과 IC ##T 강 ##국 위 ##상 ##에 부 ##합 ##되는 경 ##쟁 ##력 제 ##고 ##로 고 ##부가 ##가 ##치 창 ##출 ##을 위해 IC ##T 분야 ##의 신 ##제품 ##, 신 ##기술 개발 [SEP] IC ##T 전체 연구 ##개발 ##사업 현 ##황 ##을 보 ##면, 2016년 RD 예 ##산 ##은 총 [MASK] ##, ##8 ##46 ##억 원 규 ##모 ##이며, 이 중 [MASK] ##규 ##과 ##제 예 ##산 ##은 1, ##9 ##28 ##억 원 ##이다. [SEP]\n",
      "I1120 16:06:43.960981 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 미국 국 ##립 ##과학 ##재 ##단 ##( ##NS ##F ##)에서 오 ##래 ##전 ##부터 민 ##간 ##전문 ##가 PM ( [MASK] [MASK] ##ct Manager ##)을 운영 ##해 ##오 ##고 ##2) 있으며 18 , [MASK] ##, 일본 등 선 ##진 ##국 ##에서도 이와 유사 ##한 제 ##도를 도입 ##하고 있다 3 . ##국가 ##에서 출 ##연 ##금 또는 공 ##공 ##기 ##금 ##으로 연구 ##개발 보 ##조 ##금 ##을 지원 ##하여 추 ##진 ##하는 모든 연구 ##개발 ##사업 ##은 국가 ##연구 ##개발 ##사업 [MASK] 관리 등에 관한 [MASK] ##정 ##( ##대 ##통 ##령 ##령 제 ##26 ##7 ##2 ##9 ##호 ##, 2015. 12. [MASK] [MASK] 일부 ##개 ##정 ##)에 따른 ##다. 이 규 ##정의 핵 ##심 ##인 국가 [MASK] ##개발 ##사업 ##의 기 ##획 관리 평가 ##( ##제 2 ##장 ##)에서는 국가 ##연구 ##개발 ##사업 추 ##진 ##에 필요한 기술 ##적 ##, 경제 ##적 타 ##당 ##성 등에 대한 사 ##전 [MASK] 또는 기 ##획 ##연구 ##, 기술 ##수 ##요 ##조사 ##, 연구 ##개발 ##과 ##제 선정 ##, ##연구 ##비 관리 ##체 ##계 평가 ##, 연구 ##개발 ##성과 보고 및 평가 등을 규 ##정 ##하여 기술 ##기 ##획 ##체 ##계 ##의 근 ##간이 되고 있다. 한편 ##, IC ##T 분야 ##의 연구 ##개발 ##사업 ##은 별 ##도의 정보 ##통 ##신 방송 연구 ##개발 관리 ##규 [MASK] ##( ##미 ##래 ##창 ##조 ##과학 ##부 고 ##시 제 ##2016 ##- ##4 ##호 ##, 2016. 1. 26 ##. 일부 ##개 ##정 ##)에서 기술 ##기 ##획 전 ##반 ##의 용 ##어 ##, 추 ##진 ##체 ##계 ##, 직무 ##, 절 ##차 등을 정의 ##하고 있으며, 연구 ##개발 ##사업 구분 ##은 정책 ##과 ##제 ##, 지정 ##과 ##제 ##, 자 ##유 ##과 ##제로 나 ##누 ##어진 ##다. IC ##T 분야 ##의 기술 ##개발 수행 ##관리 ##는 정보 ##통 ##신 방송 기술 ##개발 ##사업 수행 ##관리 ##지 ##침 ##, 미 [MASK] ##창 ##조 ##과학 ##부 훈 ##령 제 ##17 ##8 ##호 ##, 2016. 1. 26 ##. ##일부 ##개 ##정 ##)과 정보 ##통 ##신 방송 기반 ##조 ##성 사업 수행 ##관리 ##지 ##침 ##, 미 ##래 ##창 ##조 ##과학 ##부 훈 ##령 제 [MASK] [MASK] ##호 ##, 2016. 1. 26 [MASK] 일부 ##개 ##정 ##)에 의 ##거 수 ##요 ##조사 등 과 ##제 ##기 ##획 단계 ##를 거쳐 RF ##P 작 ##성, 사업 ##공 ##고, 선정 ##평가 ##, 진 ##도 [MASK] ##검 ##, 연 ##차 ##평가 ##, 최종 ##평가 ##, 사업 ##화 ##의 절 ##차 ##에 따라 과 ##제 ##선정 ##, 협 ##약 ##체 ##결 ##, 사업 ##비 ##정 ##산 등이 이루어 ##지고 있다. 우리나라 ##의 [MASK] ##T 연구 ##개발 ##사업 정책 ##은 전략 ##적 기술 ##개발 ##을 통한 산업 발전 ##과 IC ##T 강 ##국 위 ##상 ##에 부 ##합 ##되는 경 ##쟁 ##력 제 ##고 ##로 고 ##부가 ##가 ##치 창 ##출 ##을 위해 IC ##T 분야 ##의 신 ##제품 ##, 신 ##기술 개발 [SEP] IC ##T 전체 연구 ##개발 ##사업 현 ##황 ##을 보 ##면, 2016년 RD 예 ##산 ##은 총 [MASK] ##, ##8 ##46 ##억 원 규 ##모 ##이며, 이 중 [MASK] ##규 ##과 ##제 예 ##산 ##은 1, ##9 ##28 ##억 원 ##이다. [SEP]\n",
      "INFO:tensorflow:input_ids: 101 23545 8909 35115 120164 36210 24989 110858 69196 11565 119994 9580 37388 16617 17655 9311 18784 120265 11287 46161 113 103 103 14526 28779 119643 91988 14523 28188 11664 119647 22634 10218 117 103 110862 23130 9121 9428 18623 20479 119829 104342 119754 11102 9672 52602 120044 12453 11506 124 119 120447 11489 9768 25486 40032 20625 8896 28000 12310 40032 11467 91785 120043 9356 20626 40032 10622 119752 13374 9765 18623 12178 25701 91785 120043 119957 10892 93222 119679 120043 119957 103 119649 77547 42300 103 16605 110858 14423 43022 44220 44220 9672 90533 11305 10729 11373 20309 110862 120883 120234 103 103 47807 21789 16605 119716 110463 119549 9638 8922 120271 9961 71013 12030 93222 103 120043 119957 10459 8932 103155 119649 119566 110858 17730 123 13890 120362 93222 119679 120043 119957 9765 18623 10530 119873 119578 14801 110862 119792 14801 9845 21928 17138 77547 18154 9405 16617 103 20625 8932 103155 119679 110862 119578 15891 48549 119844 110862 91785 120043 11882 17730 119809 110862 119679 29455 119649 29683 21611 119566 110862 91785 120043 119683 98199 9316 119566 33727 8922 16605 13374 119578 12310 103155 29683 21611 10459 8926 96618 66674 119547 53519 110862 11649 11090 119820 10459 91785 120043 119957 10892 9353 54469 119596 43022 25387 64002 91785 120043 119649 69753 103 110858 22458 37388 100420 20626 120164 14646 8888 14040 9672 120689 110863 11011 20309 110862 121460 119590 10314 110864 47807 21789 16605 119994 119578 12310 103155 9665 30134 10459 9603 12965 110862 9765 18623 29683 21611 110862 119879 110862 9666 23466 33727 119765 12453 119661 91785 120043 119957 119763 10892 119962 11882 17730 110862 104153 11882 17730 110862 9651 42815 11882 53914 8982 118751 46572 119549 11649 11090 119820 10459 119578 120043 119570 119648 11018 119596 43022 25387 64002 119578 120043 119957 119570 119648 12508 119285 110862 9309 103 100420 20626 120164 14646 10004 44220 9672 34264 11396 20309 110862 121460 119590 10314 110864 121066 21789 16605 119863 119596 43022 25387 64002 119658 20626 17138 119803 119570 119648 12508 119285 110862 9309 37388 100420 20626 120164 14646 10004 44220 9672 103 103 20309 110862 121460 119590 10314 103 47807 21789 16605 119716 9637 41521 9460 48549 119844 9121 8898 17730 12310 103155 119781 11513 69642 72148 11127 9652 119794 119803 28000 119563 119809 119973 110862 9708 12092 103 118625 110862 9568 23466 119973 110862 120070 119973 110862 119803 18227 10459 9666 23466 10530 22799 8898 17730 120684 110862 9981 47289 29683 74322 110862 119803 29455 16605 21386 36322 119645 68833 119547 119999 10459 103 11090 91785 120043 119957 119962 10892 120014 14801 119578 120043 10622 119837 119787 119871 11882 11649 11090 8853 20479 9619 14871 10530 9365 33188 24683 8885 119202 28143 9672 11664 11261 8888 81896 11287 18622 9736 52363 10622 19905 11649 11090 119820 10459 9487 120170 110862 9487 119769 110176 102 11649 11090 96567 91785 120043 119957 9978 65649 10622 9356 119678 18950 59107 9576 21386 10892 9761 103 110862 11396 82049 91837 9612 8922 39420 119841 9638 9694 103 69753 11882 17730 9576 21386 10892 119893 11373 77850 91837 9612 119555 102\n",
      "I1120 16:06:43.961552 47619347533312 create_pretraining_data.py:161] input_ids: 101 23545 8909 35115 120164 36210 24989 110858 69196 11565 119994 9580 37388 16617 17655 9311 18784 120265 11287 46161 113 103 103 14526 28779 119643 91988 14523 28188 11664 119647 22634 10218 117 103 110862 23130 9121 9428 18623 20479 119829 104342 119754 11102 9672 52602 120044 12453 11506 124 119 120447 11489 9768 25486 40032 20625 8896 28000 12310 40032 11467 91785 120043 9356 20626 40032 10622 119752 13374 9765 18623 12178 25701 91785 120043 119957 10892 93222 119679 120043 119957 103 119649 77547 42300 103 16605 110858 14423 43022 44220 44220 9672 90533 11305 10729 11373 20309 110862 120883 120234 103 103 47807 21789 16605 119716 110463 119549 9638 8922 120271 9961 71013 12030 93222 103 120043 119957 10459 8932 103155 119649 119566 110858 17730 123 13890 120362 93222 119679 120043 119957 9765 18623 10530 119873 119578 14801 110862 119792 14801 9845 21928 17138 77547 18154 9405 16617 103 20625 8932 103155 119679 110862 119578 15891 48549 119844 110862 91785 120043 11882 17730 119809 110862 119679 29455 119649 29683 21611 119566 110862 91785 120043 119683 98199 9316 119566 33727 8922 16605 13374 119578 12310 103155 29683 21611 10459 8926 96618 66674 119547 53519 110862 11649 11090 119820 10459 91785 120043 119957 10892 9353 54469 119596 43022 25387 64002 91785 120043 119649 69753 103 110858 22458 37388 100420 20626 120164 14646 8888 14040 9672 120689 110863 11011 20309 110862 121460 119590 10314 110864 47807 21789 16605 119994 119578 12310 103155 9665 30134 10459 9603 12965 110862 9765 18623 29683 21611 110862 119879 110862 9666 23466 33727 119765 12453 119661 91785 120043 119957 119763 10892 119962 11882 17730 110862 104153 11882 17730 110862 9651 42815 11882 53914 8982 118751 46572 119549 11649 11090 119820 10459 119578 120043 119570 119648 11018 119596 43022 25387 64002 119578 120043 119957 119570 119648 12508 119285 110862 9309 103 100420 20626 120164 14646 10004 44220 9672 34264 11396 20309 110862 121460 119590 10314 110864 121066 21789 16605 119863 119596 43022 25387 64002 119658 20626 17138 119803 119570 119648 12508 119285 110862 9309 37388 100420 20626 120164 14646 10004 44220 9672 103 103 20309 110862 121460 119590 10314 103 47807 21789 16605 119716 9637 41521 9460 48549 119844 9121 8898 17730 12310 103155 119781 11513 69642 72148 11127 9652 119794 119803 28000 119563 119809 119973 110862 9708 12092 103 118625 110862 9568 23466 119973 110862 120070 119973 110862 119803 18227 10459 9666 23466 10530 22799 8898 17730 120684 110862 9981 47289 29683 74322 110862 119803 29455 16605 21386 36322 119645 68833 119547 119999 10459 103 11090 91785 120043 119957 119962 10892 120014 14801 119578 120043 10622 119837 119787 119871 11882 11649 11090 8853 20479 9619 14871 10530 9365 33188 24683 8885 119202 28143 9672 11664 11261 8888 81896 11287 18622 9736 52363 10622 19905 11649 11090 119820 10459 9487 120170 110862 9487 119769 110176 102 11649 11090 96567 91785 120043 119957 9978 65649 10622 9356 119678 18950 59107 9576 21386 10892 9761 103 110862 11396 82049 91837 9612 8922 39420 119841 9638 9694 103 69753 11882 17730 9576 21386 10892 119893 11373 77850 91837 9612 119555 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.962038 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.962468 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 21 22 34 83 87 103 104 118 151 180 215 304 346 347 353 383 419 487 498 501\n",
      "I1120 16:06:43.962685 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 21 22 34 83 87 103 104 118 151 180 215 304 346 347 353 383 419 487 498 501\n",
      "INFO:tensorflow:masked_lm_ids: 11127 71723 50266 10459 8922 10306 110864 119679 119844 119566 16605 37388 34264 11373 110864 34907 11649 130 9487 17730\n",
      "I1120 16:06:43.962888 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 11127 71723 50266 10459 8922 10306 110864 119679 119844 119566 16605 37388 34264 11373 110864 34907 11649 130 9487 17730\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.963082 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "I1120 16:06:43.963258 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.964977 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 공 ##차 ##한계 ##는 . ##12 . [MASK] ##로 . ##04 이하 ##인 변수가 없 ##고 분 ##자 ##팽 ##창 ##인 ##자 ##( ##V ##arian ##ce [MASK] ##lation Factor VI ##F ) ##도 모두 1. ##10 8 ##. ##58 ##로 나타나 어느 하나 ##도 10. ##0 ##을 넘 ##기는 것이 없 ##고 오 ##차 [MASK] ##들 간 ##에 자기 ##상관 ##의 문제 ##도 없 ##어 연구 [MASK] ##들 간 ##에 ##다 ##중 [MASK] ##선 ##성의 문제 ##를 배 ##제 ##할 수 있었다. 간호 ##서비스 질 ##에 영향을 미치는 요인 ##을 확인 ##하기 위해 실시 ##한 위 ##계 ##적 다 ##중 ##회 ##귀 ##분석 ##의 결과는 Table 4 ##와 [MASK] [SEP] ##하였다. 그 결과, [MASK] 1 ##의 설명 ##력 ##은 14. ##2 ##%, 모형 적합 ##성은 유의 ##하였 ##으나 ##( ##F ##= ##7. ##85 ##, p ##. ##00 ##1) 간 호 ##서비스 질 ##에 대한 설명 ##력이 유의한 변수는 없는 것으로 나타났다. 2 단계 ##에서는 모형 1 ##에 호 ##혜 ##성의 하 ##위 ##요인 ##인 협 ##력 ##자 ##간 균 ##형 ##, 애 ##정 ##과 호 ##의 ##, 내 ##적 보 ##상을 추가 ##로 투 ##입 ##하였다. 모형 2 ##의 설명 ##력 ##은 48 ##. ##2 ##%로 모형 1 ##에 비해 34 ##. ##0% ##나 설명 ##력이 증가 ##하였고 모형 적합 ##성 ##도 유의 ##하였으며 ##( ##F ##= ##27 ##. ##9 ##5 [MASK] p ##. ##00 ##1), 간호 ##서비스 질 ##에 대한 유의한 설명 ##력을 갖는 변수는 협 ##력 ##자 ##간 균 ##형 ##( ##= ##. ##23 ##, p ##00 ##1) ##과 내 ##적 보 ##상 ##( ##= ##. ##45 ##, p ##. ##00 ##1) ##으로 나타났다. 3 단계 ##에서는 모형 2 ##에 감 ##정 ##노 ##zlik ##의 하 ##위 ##요인 중 ##, 상관관계 ##가 나타난 [MASK] ##정 부 ##조 ##화를 추가 ##로 투 ##입 ##하였다. 그 결과, 모형 3 ##의 설명 ##력 ##은 48 ##. ##4 ##%로 모형 2 ##에 비해 0. ##2 ##% ##정 [MASK] 설명 [MASK] 증가 ##하였고 모형 ##의 적합 ##도는 유의 ##하였 ##으나 ##( ##F ##= ##25. ##7 ##6 ##, p ##. ##00 ##1), 간 호 ##서비스 질 ##에 대한 유의한 설명 ##력을 갖는 변수는 모형 2 ##에서 ##와 같이 협 ##력 ##자 ##간 균 ##형 ##( ##= ##. ##22 ##, p 001 ##)과 내 ##적 보 ##상 ##( ##= ##. ##45 ##, p . ##00 ##1) 인 것으로 나타났다. Table 4. Factor ##s Inf ##lue ##ncing Nursing Service Quality ##2) 이 ##직 ##의 ##도에 영향을 [MASK] 요인 ##회 ##귀 ##분석을 실시 ##하기 전에 회 ##귀 ##분석 ##에 대한 기본 ##가정 ##을 검토 ##한 결과, Dur ##bin ##- ##W ##ats ##on 통계 ##량은 1. ##9 ##5 ##로 임 ##계 ##치 ##인 0. ##9 [MASK] 1. ##7 ##5 ##을 넘 ##어 자기 ##상관 ##성의 문제 ##가 없 ##고 다 ##중 ##공 ##선 ##성은 변수 ##들 간의 상관관계 ##가 . ##80 이상 ##인 변수가 없 ##어 예측 ##변수 ##들 간의 독 ##립 accused ##도 확인 ##되었으며 ##, 공 ##차 ##한계 ##는 . ##48 . ##99 ##로 . ##04 이하 ##인 변수가 없 ##었고 ##, 분 ##자 ##팽 ##창 ##인 ##자 ( ##V ##arian ##ce Inf ##lation Factor VI [SEP]\n",
      "I1120 16:06:43.965419 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 공 ##차 ##한계 ##는 . ##12 . [MASK] ##로 . ##04 이하 ##인 변수가 없 ##고 분 ##자 ##팽 ##창 ##인 ##자 ##( ##V ##arian ##ce [MASK] ##lation Factor VI ##F ) ##도 모두 1. ##10 8 ##. ##58 ##로 나타나 어느 하나 ##도 10. ##0 ##을 넘 ##기는 것이 없 ##고 오 ##차 [MASK] ##들 간 ##에 자기 ##상관 ##의 문제 ##도 없 ##어 연구 [MASK] ##들 간 ##에 ##다 ##중 [MASK] ##선 ##성의 문제 ##를 배 ##제 ##할 수 있었다. 간호 ##서비스 질 ##에 영향을 미치는 요인 ##을 확인 ##하기 위해 실시 ##한 위 ##계 ##적 다 ##중 ##회 ##귀 ##분석 ##의 결과는 Table 4 ##와 [MASK] [SEP] ##하였다. 그 결과, [MASK] 1 ##의 설명 ##력 ##은 14. ##2 ##%, 모형 적합 ##성은 유의 ##하였 ##으나 ##( ##F ##= ##7. ##85 ##, p ##. ##00 ##1) 간 호 ##서비스 질 ##에 대한 설명 ##력이 유의한 변수는 없는 것으로 나타났다. 2 단계 ##에서는 모형 1 ##에 호 ##혜 ##성의 하 ##위 ##요인 ##인 협 ##력 ##자 ##간 균 ##형 ##, 애 ##정 ##과 호 ##의 ##, 내 ##적 보 ##상을 추가 ##로 투 ##입 ##하였다. 모형 2 ##의 설명 ##력 ##은 48 ##. ##2 ##%로 모형 1 ##에 비해 34 ##. ##0% ##나 설명 ##력이 증가 ##하였고 모형 적합 ##성 ##도 유의 ##하였으며 ##( ##F ##= ##27 ##. ##9 ##5 [MASK] p ##. ##00 ##1), 간호 ##서비스 질 ##에 대한 유의한 설명 ##력을 갖는 변수는 협 ##력 ##자 ##간 균 ##형 ##( ##= ##. ##23 ##, p ##00 ##1) ##과 내 ##적 보 ##상 ##( ##= ##. ##45 ##, p ##. ##00 ##1) ##으로 나타났다. 3 단계 ##에서는 모형 2 ##에 감 ##정 ##노 ##zlik ##의 하 ##위 ##요인 중 ##, 상관관계 ##가 나타난 [MASK] ##정 부 ##조 ##화를 추가 ##로 투 ##입 ##하였다. 그 결과, 모형 3 ##의 설명 ##력 ##은 48 ##. ##4 ##%로 모형 2 ##에 비해 0. ##2 ##% ##정 [MASK] 설명 [MASK] 증가 ##하였고 모형 ##의 적합 ##도는 유의 ##하였 ##으나 ##( ##F ##= ##25. ##7 ##6 ##, p ##. ##00 ##1), 간 호 ##서비스 질 ##에 대한 유의한 설명 ##력을 갖는 변수는 모형 2 ##에서 ##와 같이 협 ##력 ##자 ##간 균 ##형 ##( ##= ##. ##22 ##, p 001 ##)과 내 ##적 보 ##상 ##( ##= ##. ##45 ##, p . ##00 ##1) 인 것으로 나타났다. Table 4. Factor ##s Inf ##lue ##ncing Nursing Service Quality ##2) 이 ##직 ##의 ##도에 영향을 [MASK] 요인 ##회 ##귀 ##분석을 실시 ##하기 전에 회 ##귀 ##분석 ##에 대한 기본 ##가정 ##을 검토 ##한 결과, Dur ##bin ##- ##W ##ats ##on 통계 ##량은 1. ##9 ##5 ##로 임 ##계 ##치 ##인 0. ##9 [MASK] 1. ##7 ##5 ##을 넘 ##어 자기 ##상관 ##성의 문제 ##가 없 ##고 다 ##중 ##공 ##선 ##성은 변수 ##들 간의 상관관계 ##가 . ##80 이상 ##인 변수가 없 ##어 예측 ##변수 ##들 간의 독 ##립 accused ##도 확인 ##되었으며 ##, 공 ##차 ##한계 ##는 . ##48 . ##99 ##로 . ##04 이하 ##인 변수가 없 ##었고 ##, 분 ##자 ##팽 ##창 ##인 ##자 ( ##V ##arian ##ce Inf ##lation Factor VI [SEP]\n",
      "INFO:tensorflow:input_ids: 101 8896 23466 120441 11018 119 24747 119 103 11261 119 92546 120052 12030 120581 9555 11664 9367 13764 119386 100420 12030 13764 110858 11779 57078 10419 103 19718 41556 12262 11565 114 12092 29414 119590 20305 129 110864 83148 11261 119653 82564 119737 12092 120197 10929 10622 9008 46216 27487 9555 11664 9580 23466 103 27023 8845 10530 119760 120442 10459 119581 12092 9555 12965 91785 103 27023 8845 10530 11903 41693 103 18471 79599 119581 11513 9330 17730 14843 9460 119659 119689 120047 9709 10530 58088 119610 119602 10622 84300 22440 19905 119632 11102 9619 21611 14801 9056 41693 14863 118661 119665 10459 119811 34421 125 12638 103 102 119548 8924 119891 103 122 10459 119699 28143 10892 120324 10729 119749 119736 119880 107442 119676 119585 35466 110858 11565 110869 119846 69975 110862 184 110864 21069 119627 8845 9985 120047 9709 10530 18154 119699 61964 119767 120516 40364 23925 119588 123 119781 23635 119736 122 10530 9985 119437 79599 9952 19855 119816 12030 9981 28143 13764 18784 8923 27506 110862 9532 16605 11882 9985 10459 110862 8996 14801 9356 33654 119858 11261 9881 58303 119548 119736 123 10459 119699 28143 10892 11300 110864 10729 119910 119736 122 10530 100876 11069 110864 119771 16439 119699 61964 119561 36251 119736 119880 17138 12092 119676 53529 110858 11565 110869 90861 110864 11373 11166 103 184 110864 21069 120189 119689 120047 9709 10530 18154 119767 119699 33975 120021 120516 9981 28143 13764 18784 8923 27506 110858 110869 110864 74171 110862 184 21069 119627 11882 8996 14801 9356 14871 110858 110869 110864 76977 110862 184 110864 21069 119627 11467 119588 124 119781 23635 119736 123 10530 8848 16605 28981 86836 10459 9952 19855 119816 9694 110862 120160 11287 119988 103 16605 9365 20626 56999 119858 11261 9881 58303 119548 8924 119891 119736 124 10459 119699 28143 10892 11300 110864 11011 119910 119736 123 10530 100876 119560 10729 110855 16605 103 119699 103 119561 36251 119736 10459 119880 60884 119676 119585 35466 110858 11565 110869 120712 11305 11211 110862 184 110864 21069 120189 8845 9985 120047 9709 10530 18154 119767 119699 33975 120021 120516 119736 123 11489 12638 38401 9981 28143 13764 18784 8923 27506 110858 110869 110864 71793 110862 184 17449 119863 8996 14801 9356 14871 110858 110869 110864 76977 110862 184 119 21069 119627 9640 23925 119588 34421 119714 41556 10107 74479 75483 37730 108326 13489 60476 119647 9638 33077 10459 108521 58088 103 119602 14863 118661 120115 119632 22440 91069 9998 118661 119665 10530 18154 119875 120304 10622 120081 11102 119891 66545 16473 110863 13034 16883 10263 119709 119868 119590 11373 11166 11261 9644 21611 18622 12030 119560 11373 103 119590 11305 11166 10622 9008 12965 119760 120442 79599 119581 11287 9555 11664 9056 41693 28000 18471 107442 119934 27023 119860 120160 11287 119 44026 66982 12030 120581 9555 12965 119759 119926 27023 119860 9088 35115 37303 12092 84300 55835 110862 8896 23466 120441 11018 119 32168 119 88657 11261 119 92546 120052 12030 120581 9555 48754 110862 9367 13764 119386 100420 12030 13764 113 11779 57078 10419 74479 19718 41556 12262 102\n",
      "I1120 16:06:43.965955 47619347533312 create_pretraining_data.py:161] input_ids: 101 8896 23466 120441 11018 119 24747 119 103 11261 119 92546 120052 12030 120581 9555 11664 9367 13764 119386 100420 12030 13764 110858 11779 57078 10419 103 19718 41556 12262 11565 114 12092 29414 119590 20305 129 110864 83148 11261 119653 82564 119737 12092 120197 10929 10622 9008 46216 27487 9555 11664 9580 23466 103 27023 8845 10530 119760 120442 10459 119581 12092 9555 12965 91785 103 27023 8845 10530 11903 41693 103 18471 79599 119581 11513 9330 17730 14843 9460 119659 119689 120047 9709 10530 58088 119610 119602 10622 84300 22440 19905 119632 11102 9619 21611 14801 9056 41693 14863 118661 119665 10459 119811 34421 125 12638 103 102 119548 8924 119891 103 122 10459 119699 28143 10892 120324 10729 119749 119736 119880 107442 119676 119585 35466 110858 11565 110869 119846 69975 110862 184 110864 21069 119627 8845 9985 120047 9709 10530 18154 119699 61964 119767 120516 40364 23925 119588 123 119781 23635 119736 122 10530 9985 119437 79599 9952 19855 119816 12030 9981 28143 13764 18784 8923 27506 110862 9532 16605 11882 9985 10459 110862 8996 14801 9356 33654 119858 11261 9881 58303 119548 119736 123 10459 119699 28143 10892 11300 110864 10729 119910 119736 122 10530 100876 11069 110864 119771 16439 119699 61964 119561 36251 119736 119880 17138 12092 119676 53529 110858 11565 110869 90861 110864 11373 11166 103 184 110864 21069 120189 119689 120047 9709 10530 18154 119767 119699 33975 120021 120516 9981 28143 13764 18784 8923 27506 110858 110869 110864 74171 110862 184 21069 119627 11882 8996 14801 9356 14871 110858 110869 110864 76977 110862 184 110864 21069 119627 11467 119588 124 119781 23635 119736 123 10530 8848 16605 28981 86836 10459 9952 19855 119816 9694 110862 120160 11287 119988 103 16605 9365 20626 56999 119858 11261 9881 58303 119548 8924 119891 119736 124 10459 119699 28143 10892 11300 110864 11011 119910 119736 123 10530 100876 119560 10729 110855 16605 103 119699 103 119561 36251 119736 10459 119880 60884 119676 119585 35466 110858 11565 110869 120712 11305 11211 110862 184 110864 21069 120189 8845 9985 120047 9709 10530 18154 119767 119699 33975 120021 120516 119736 123 11489 12638 38401 9981 28143 13764 18784 8923 27506 110858 110869 110864 71793 110862 184 17449 119863 8996 14801 9356 14871 110858 110869 110864 76977 110862 184 119 21069 119627 9640 23925 119588 34421 119714 41556 10107 74479 75483 37730 108326 13489 60476 119647 9638 33077 10459 108521 58088 103 119602 14863 118661 120115 119632 22440 91069 9998 118661 119665 10530 18154 119875 120304 10622 120081 11102 119891 66545 16473 110863 13034 16883 10263 119709 119868 119590 11373 11166 11261 9644 21611 18622 12030 119560 11373 103 119590 11305 11166 10622 9008 12965 119760 120442 79599 119581 11287 9555 11664 9056 41693 28000 18471 107442 119934 27023 119860 120160 11287 119 44026 66982 12030 120581 9555 12965 119759 119926 27023 119860 9088 35115 37303 12092 84300 55835 110862 8896 23466 120441 11018 119 32168 119 88657 11261 119 92546 120052 12030 120581 9555 48754 110862 9367 13764 119386 100420 12030 13764 113 11779 57078 10419 74479 19718 41556 12262 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.966404 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.966823 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 8 9 27 55 67 73 109 114 222 239 276 286 316 318 396 401 438 461 475 495\n",
      "I1120 16:06:43.967032 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 8 9 27 55 67 73 109 114 222 239 276 286 316 318 396 401 438 461 475 495\n",
      "INFO:tensorflow:masked_lm_ids: 74178 11261 74479 9959 119926 28000 119655 119736 110862 13764 18778 8848 12092 61964 9638 119610 10729 11287 17138 48754\n",
      "I1120 16:06:43.967215 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 74178 11261 74479 9959 119926 28000 119655 119736 110862 13764 18778 8848 12092 61964 9638 119610 10729 11287 17138 48754\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.967399 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "I1120 16:06:43.967567 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.969263 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 엘 ##런 머 ##스 ##크 테 ##슬 ##라 [MASK] ##는 궁 ##극 ##적으로 일반 자동 ##차 [MASK] 안전 ##성을 3 ##배 높 ##일 계획 ##을 세 ##워 ##놓 ##고 있다. 이 ##같은 개선 ##이 미국 플 [MASK] ##리 ##다 ##주 ##에서 [MASK] ##어난 사 ##망 ##사고 ##를 막 ##았 [MASK] 것으로 보 ##느 ##냐 ##는 질 ##문 ##에 그 ##렇 ##다 고 그는 답 ##했다. 새로운 오 ##토 ##파 ##일 ##럿 ##의 [MASK] ##이 [MASK] ##가 도 ##로 ##의 큰 금 [MASK] 물 ##체를 인식 ##했 ##을 것이라고 답 ##했다. 당시 [MASK] ##량 카 ##메 ##라는 하 ##얀 ##색 트 ##럭 ##과 하 ##늘 ##을 구분 ##하지 못 ##하면서 결국 치 ##명 ##적인 사고 ##로 이어 ##졌다 ##. [SEP] 명 [MASK] 차 ##라고 ##도 한다. 이 차이가 [MASK] ##수록 콘 ##트 ##라 ##스트 ##가 강 ##한 화 ##면 [MASK] 되고 차이가 작 ##을수록 콘 ##트 ##라 ##스트 ##가 약 ##한 화 ##면 [MASK] 된다. 명 ##암 ##비 ##는 필 ##름 관 ##용 ##도와 관련 ##이 있는데 관 ##용 ##도는 선 ##명한 영상을 [MASK] [MASK] 수 있는 노 ##출 범위 ##를 의미 ##하는 것이 ##므로 관 ##용 ##도가 [MASK] 필 ##름 ##을 사용 ##할 ##수록 [MASK] 명 ##암 ##비 ##를 얻 ##을 수 있다. [SEP]\n",
      "I1120 16:06:43.969554 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 엘 ##런 머 ##스 ##크 테 ##슬 ##라 [MASK] ##는 궁 ##극 ##적으로 일반 자동 ##차 [MASK] 안전 ##성을 3 ##배 높 ##일 계획 ##을 세 ##워 ##놓 ##고 있다. 이 ##같은 개선 ##이 미국 플 [MASK] ##리 ##다 ##주 ##에서 [MASK] ##어난 사 ##망 ##사고 ##를 막 ##았 [MASK] 것으로 보 ##느 ##냐 ##는 질 ##문 ##에 그 ##렇 ##다 고 그는 답 ##했다. 새로운 오 ##토 ##파 ##일 ##럿 ##의 [MASK] ##이 [MASK] ##가 도 ##로 ##의 큰 금 [MASK] 물 ##체를 인식 ##했 ##을 것이라고 답 ##했다. 당시 [MASK] ##량 카 ##메 ##라는 하 ##얀 ##색 트 ##럭 ##과 하 ##늘 ##을 구분 ##하지 못 ##하면서 결국 치 ##명 ##적인 사고 ##로 이어 ##졌다 ##. [SEP] 명 [MASK] 차 ##라고 ##도 한다. 이 차이가 [MASK] ##수록 콘 ##트 ##라 ##스트 ##가 강 ##한 화 ##면 [MASK] 되고 차이가 작 ##을수록 콘 ##트 ##라 ##스트 ##가 약 ##한 화 ##면 [MASK] 된다. 명 ##암 ##비 ##는 필 ##름 관 ##용 ##도와 관련 ##이 있는데 관 ##용 ##도는 선 ##명한 영상을 [MASK] [MASK] 수 있는 노 ##출 범위 ##를 의미 ##하는 것이 ##므로 관 ##용 ##도가 [MASK] 필 ##름 ##을 사용 ##할 ##수록 [MASK] 명 ##암 ##비 ##를 얻 ##을 수 있다. [SEP]\n",
      "INFO:tensorflow:input_ids: 101 9562 56710 9265 12605 20308 9866 119078 17342 103 11018 8916 63243 17022 119600 120033 23466 103 119741 36456 124 76036 9028 18392 120053 10622 9435 69592 118748 11664 119547 9638 120648 119744 10739 23545 9944 103 12692 11903 16323 11489 103 54305 9405 89292 120174 11513 9247 119118 103 23925 9356 118760 118728 11018 9709 25934 10530 8924 118871 11903 8888 17889 9065 119943 39773 9580 26444 46150 18392 118868 10459 103 10739 103 11287 9087 11261 10459 9835 8928 103 9299 84957 119644 119424 10622 98854 9065 119943 24756 103 44321 9786 118927 60362 9952 119127 41442 9890 118864 11882 9952 118762 10622 119763 23665 9290 37341 50342 9779 16758 15387 119954 11261 64749 32855 110864 102 9281 103 9730 59894 12092 119575 9638 119694 103 119766 9814 15184 17342 34994 11287 8853 11102 9993 14867 103 66674 119694 9652 120080 9814 15184 17342 34994 11287 9539 11102 9993 14867 103 119684 9281 119115 29455 11018 9949 49543 8900 24974 119724 86080 10739 60030 8900 24974 60884 9428 68414 120316 103 103 9460 13767 9022 52363 119851 11513 119614 12178 27487 56460 8900 24974 68516 103 9949 49543 10622 119550 14843 119766 103 9281 119115 29455 11513 9550 10622 9460 119547 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.970017 47619347533312 create_pretraining_data.py:161] input_ids: 101 9562 56710 9265 12605 20308 9866 119078 17342 103 11018 8916 63243 17022 119600 120033 23466 103 119741 36456 124 76036 9028 18392 120053 10622 9435 69592 118748 11664 119547 9638 120648 119744 10739 23545 9944 103 12692 11903 16323 11489 103 54305 9405 89292 120174 11513 9247 119118 103 23925 9356 118760 118728 11018 9709 25934 10530 8924 118871 11903 8888 17889 9065 119943 39773 9580 26444 46150 18392 118868 10459 103 10739 103 11287 9087 11261 10459 9835 8928 103 9299 84957 119644 119424 10622 98854 9065 119943 24756 103 44321 9786 118927 60362 9952 119127 41442 9890 118864 11882 9952 118762 10622 119763 23665 9290 37341 50342 9779 16758 15387 119954 11261 64749 32855 110864 102 9281 103 9730 59894 12092 119575 9638 119694 103 119766 9814 15184 17342 34994 11287 8853 11102 9993 14867 103 66674 119694 9652 120080 9814 15184 17342 34994 11287 9539 11102 9993 14867 103 119684 9281 119115 29455 11018 9949 49543 8900 24974 119724 86080 10739 60030 8900 24974 60884 9428 68414 120316 103 103 9460 13767 9022 52363 119851 11513 119614 12178 27487 56460 8900 24974 68516 103 9949 49543 10622 119550 14843 119766 103 9281 119115 29455 11513 9550 10622 9460 119547 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.970442 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1120 16:06:43.970865 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 9 17 27 30 37 42 50 73 75 82 92 121 128 135 139 153 173 174 188 195\n",
      "I1120 16:06:43.971072 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 9 17 27 30 37 42 50 73 75 82 92 121 128 135 139 153 173 174 188 195\n",
      "INFO:tensorflow:masked_lm_ids: 24556 80001 69592 119547 11261 9641 10622 9186 54141 43962 9730 119115 9836 8853 10739 10739 120190 118724 55600 55600\n",
      "I1120 16:06:43.971260 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 24556 80001 69592 119547 11261 9641 10622 9186 54141 43962 9730 119115 9836 8853 10739 10739 120190 118724 55600 55600\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.971443 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "I1120 16:06:43.971613 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1120 16:06:43.973348 47619347533312 create_pretraining_data.py:149] *** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] 하지만 적 ##외 ##선 ##은 매우 반 ##사 ##되 ##기 쉬 ##운 성 ##질 ##을 가지 ##기 때문에 ##, 물 ##체 표면 ##의 상태 ##나 [MASK] ##는 각 ##도에 ##лат ##도 방 ##사 에너지 ##가 변화 ##한다. 이 점 ##이 하 ##천 모 ##니 ##터 ##링 ##에서 가장 중요 ##하며, 이 성 ##질 ##을 이용하여 수 ##면 ##의 미 ##묘 ##한 요 ##철 형 ##상을 영상 ##화 ##할 수 있다. 원 ##적 ##외 ##선의 또 다른 이 ##점 ##은 가 ##시 ##광 ##에 비해 파 ##장이 길 ##어 산 ##란 ##되 ##기 어려 [MASK] 성 ##질 ##을 가지 ##기 때문에 ##, 연 ##기 ##나 안 ##개의 영향을 잘 받 ##지 않는 점 ##이다. [SEP] ##가 되는 가 ##시 ##광 ##의 직 ##사에 따른 영향 ##도 전 ##혀 받 ##지 않는 점 ##도 [MASK] ##용 ##성이 ##라고 하는 점 ##에서 중요한 이 ##점이다. 따라서 원 ##적 ##외 [MASK] 카 ##메 ##라 ##를 이용하여 야 ##간의 하 ##천 영상 획 ##득 [MASK] ##면 기존의 표면 영상 ##유 ##속 ##계 ##의 한계 ##였던 야 ##간 유 ##속 ##측정의 어려 ##움을 어느 정도 해결 ##해 ##줄 수 있을 것으로 생각 ##한다. ##3. 상호 ##상관 ##법을 [MASK] 시 ##공간 영상 유 ##속 측정 방법 ##원 ##적 [MASK] ##선 영상 ##은 일반 캠 ##코 ##더 영상 ##과 비교 ##하여 영상 내 [MASK] ##경 ##잡 ##음 ##( ##back ##ground noise ##)이 상대적으로 많은 것이 단 ##점이다. 즉, 영상 ##내 수 ##표면 ##과 추 ##적 ##자의 움 ##직 ##임을 분석 ##함 ##에 있어 기존의 상호 ##상관 ##법을 이용 ##할 경우 영상 ##내 잡 ##음 ##으로 인해 상관계 ##수가 작 ##게 산 ##정 ##될 수 ##밖 ##에 없다 ##는 한계 ##가 있다. 좀 더 구체 ##적으로 표면 ##영상 ##유 ##속 ##계 ##의 유 ##속 측정 방법을 살펴보 ##면 [MASK] 표면 ##영상 ##유 ##속 ##계 ##는 P ##IV 기법 ##에서 사용 ##하고 있는 상호 ##상관 ##법 ##( ##cross ##- ##corre ##lation [MASK] ##)을 이용한다. 상호 ##상관 ##법 ##의 경우 두 장 ##의 영상 ##만 ##을 이용하여 [MASK] ##속 ##을 산 ##정 ##하기 때문에 짧 ##은 시간 [MASK] ##격 ##의 유 ##속 ##분포 측정 ##에는 장 ##점을 [MASK] 있지만 흐 [MASK] ##특성 ##과 촬 ##영 ##조건 및 분석 ##방법 ##에 따라 유 ##속 측정 결과 ##가 달 ##라 ##지 ##기 때문에 불 ##확 ##도( ##unce ##rta ##int ##y ##)를 포함 ##할 수 있다는 한계 ##가 있다( ##K ##im et al., 2011). ##이를 해결 ##하기 위한 방법 ##으로 Fuji ##ta and T ##su [MASK] ##(200 ##2) ##와 Fuji ##ta et al. ( ##200 ##5 ##)은 시 ##공간 ##영상 유 ##속 ##계 ##측 ##법 ##(S ##TI ##V ##, Spa ##tio [MASK] ##T ##emp ##oral Image Ve ##loc ##imet ##ry ##)을 개발 ##하였다. 시 ##공간 영상 ##(S ##TI ##, Spa ##tio ##- [MASK] ##emp ##oral Image ##)이 ##란 연속 ##된 영상 시 ##계 ##열 ##로부터 한 영상 ##에서 한 줄 ##씩 영상 ##줄 ##을 잘 ##라 ##내 ##고, 이를 시간 ##에 따라 연속 ##적으로 연결 ##하여 만든 영상을 말한다 ##. 즉, 시 ##공간 영상 ##은 한 축 ##은 공간 ##, 다른 한 축 ##은 시간 ##으로 이루어 ##진 영상 ##이다 ##( ##J ##hne ##, [SEP]\n",
      "I1120 16:06:43.973809 47619347533312 create_pretraining_data.py:151] tokens: [CLS] 하지만 적 ##외 ##선 ##은 매우 반 ##사 ##되 ##기 쉬 ##운 성 ##질 ##을 가지 ##기 때문에 ##, 물 ##체 표면 ##의 상태 ##나 [MASK] ##는 각 ##도에 ##лат ##도 방 ##사 에너지 ##가 변화 ##한다. 이 점 ##이 하 ##천 모 ##니 ##터 ##링 ##에서 가장 중요 ##하며, 이 성 ##질 ##을 이용하여 수 ##면 ##의 미 ##묘 ##한 요 ##철 형 ##상을 영상 ##화 ##할 수 있다. 원 ##적 ##외 ##선의 또 다른 이 ##점 ##은 가 ##시 ##광 ##에 비해 파 ##장이 길 ##어 산 ##란 ##되 ##기 어려 [MASK] 성 ##질 ##을 가지 ##기 때문에 ##, 연 ##기 ##나 안 ##개의 영향을 잘 받 ##지 않는 점 ##이다. [SEP] ##가 되는 가 ##시 ##광 ##의 직 ##사에 따른 영향 ##도 전 ##혀 받 ##지 않는 점 ##도 [MASK] ##용 ##성이 ##라고 하는 점 ##에서 중요한 이 ##점이다. 따라서 원 ##적 ##외 [MASK] 카 ##메 ##라 ##를 이용하여 야 ##간의 하 ##천 영상 획 ##득 [MASK] ##면 기존의 표면 영상 ##유 ##속 ##계 ##의 한계 ##였던 야 ##간 유 ##속 ##측정의 어려 ##움을 어느 정도 해결 ##해 ##줄 수 있을 것으로 생각 ##한다. ##3. 상호 ##상관 ##법을 [MASK] 시 ##공간 영상 유 ##속 측정 방법 ##원 ##적 [MASK] ##선 영상 ##은 일반 캠 ##코 ##더 영상 ##과 비교 ##하여 영상 내 [MASK] ##경 ##잡 ##음 ##( ##back ##ground noise ##)이 상대적으로 많은 것이 단 ##점이다. 즉, 영상 ##내 수 ##표면 ##과 추 ##적 ##자의 움 ##직 ##임을 분석 ##함 ##에 있어 기존의 상호 ##상관 ##법을 이용 ##할 경우 영상 ##내 잡 ##음 ##으로 인해 상관계 ##수가 작 ##게 산 ##정 ##될 수 ##밖 ##에 없다 ##는 한계 ##가 있다. 좀 더 구체 ##적으로 표면 ##영상 ##유 ##속 ##계 ##의 유 ##속 측정 방법을 살펴보 ##면 [MASK] 표면 ##영상 ##유 ##속 ##계 ##는 P ##IV 기법 ##에서 사용 ##하고 있는 상호 ##상관 ##법 ##( ##cross ##- ##corre ##lation [MASK] ##)을 이용한다. 상호 ##상관 ##법 ##의 경우 두 장 ##의 영상 ##만 ##을 이용하여 [MASK] ##속 ##을 산 ##정 ##하기 때문에 짧 ##은 시간 [MASK] ##격 ##의 유 ##속 ##분포 측정 ##에는 장 ##점을 [MASK] 있지만 흐 [MASK] ##특성 ##과 촬 ##영 ##조건 및 분석 ##방법 ##에 따라 유 ##속 측정 결과 ##가 달 ##라 ##지 ##기 때문에 불 ##확 ##도( ##unce ##rta ##int ##y ##)를 포함 ##할 수 있다는 한계 ##가 있다( ##K ##im et al., 2011). ##이를 해결 ##하기 위한 방법 ##으로 Fuji ##ta and T ##su [MASK] ##(200 ##2) ##와 Fuji ##ta et al. ( ##200 ##5 ##)은 시 ##공간 ##영상 유 ##속 ##계 ##측 ##법 ##(S ##TI ##V ##, Spa ##tio [MASK] ##T ##emp ##oral Image Ve ##loc ##imet ##ry ##)을 개발 ##하였다. 시 ##공간 영상 ##(S ##TI ##, Spa ##tio ##- [MASK] ##emp ##oral Image ##)이 ##란 연속 ##된 영상 시 ##계 ##열 ##로부터 한 영상 ##에서 한 줄 ##씩 영상 ##줄 ##을 잘 ##라 ##내 ##고, 이를 시간 ##에 따라 연속 ##적으로 연결 ##하여 만든 영상을 말한다 ##. 즉, 시 ##공간 영상 ##은 한 축 ##은 공간 ##, 다른 한 축 ##은 시간 ##으로 이루어 ##진 영상 ##이다 ##( ##J ##hne ##, [SEP]\n",
      "INFO:tensorflow:input_ids: 101 32775 9664 78705 18471 10892 42608 9321 12945 118800 12310 9469 21614 9434 48599 10622 69164 12310 20729 110862 9299 29683 119867 10459 119675 16439 103 11018 8844 108521 30828 12092 9328 12945 119862 11287 119586 119554 9638 9668 10739 9952 38631 9283 25503 21876 80174 11489 22224 119692 119780 9638 9434 48599 10622 119593 9460 14867 10459 9309 118943 11102 9599 47465 9983 33654 119859 18227 14843 9460 119547 9612 14801 78705 65569 9144 19709 9638 34907 10892 8843 14040 118649 10530 100876 9901 55635 8934 12965 9407 49919 118800 12310 119838 103 9434 48599 10622 69164 12310 20729 110862 9568 12310 16439 9521 32501 58088 9654 9322 12508 55698 9668 119555 102 11287 54780 8843 14040 118649 10459 9707 86580 110463 119642 12092 9665 80579 9322 12508 55698 9668 12092 103 24974 53371 59894 23969 9668 11489 63552 9638 120653 52579 9612 14801 78705 103 9786 118927 17342 11513 119593 9538 60454 9952 38631 119859 9999 118813 103 14867 119977 119867 119859 42815 43962 21611 10459 120023 103064 9538 18784 9625 43962 121662 119838 90373 82564 107657 119927 14523 119219 9460 68943 23925 119735 119554 119573 119800 120442 94199 103 9485 120139 119859 9625 43962 119559 119567 14279 14801 103 18471 119859 10892 119600 9795 25517 54141 119859 11882 119572 13374 119859 8996 103 31720 119199 32158 110858 18666 58821 58638 119782 120046 25685 27487 9059 120653 119944 119859 31605 9460 120288 11882 9765 14801 42984 9608 33077 96972 119552 48533 10530 45893 119977 119800 120442 94199 119580 14843 28467 119859 31605 9656 32158 11467 39629 120388 73894 9652 14153 9407 16605 59330 9460 118964 10530 39218 11018 120023 11287 119547 9682 9074 120074 17022 119867 120218 42815 43962 21611 10459 9625 43962 119559 119986 119828 14867 103 119867 120218 42815 43962 21611 11018 153 91238 119878 11489 119550 12453 13767 119800 120442 33768 110858 61635 110863 46968 19718 103 119643 120634 119800 120442 33768 10459 28467 9102 9657 10459 119859 19105 10622 119593 103 43962 10622 9407 16605 22440 20729 9717 10892 119612 103 45465 10459 9625 43962 120150 119559 15303 9657 67477 103 76123 10015 103 120132 11882 9763 30858 119956 9316 119552 119757 10530 22799 9625 43962 119559 85533 11287 9061 17342 12508 12310 20729 9368 119445 120045 93050 16294 16261 10157 119638 119623 14843 9460 77324 120023 11287 119798 11733 11759 10131 119680 120318 66623 119927 22440 28195 119567 11467 53509 10213 10111 157 12892 103 119908 119647 12638 53509 10213 10131 120007 113 89478 11166 119748 9485 120139 120218 9625 43962 21611 119281 33768 119941 72286 11779 110862 64766 24008 103 11090 120478 74297 35314 19561 79308 71200 10908 119643 110176 119548 9485 120139 119859 119941 72286 110862 64766 24008 110863 103 120478 74297 35314 119782 49919 100208 13441 119859 9485 21611 79604 92515 9954 119859 11489 9954 9692 119108 119859 119219 10622 9654 17342 31605 119563 35756 119612 10530 22799 100208 17022 119830 13374 73306 120316 52462 110864 119944 9485 120139 119859 10892 9954 9766 10892 119711 110862 19709 9954 9766 10892 119612 11467 119645 18623 119859 11925 110858 15417 37893 110862 102\n",
      "I1120 16:06:43.974345 47619347533312 create_pretraining_data.py:161] input_ids: 101 32775 9664 78705 18471 10892 42608 9321 12945 118800 12310 9469 21614 9434 48599 10622 69164 12310 20729 110862 9299 29683 119867 10459 119675 16439 103 11018 8844 108521 30828 12092 9328 12945 119862 11287 119586 119554 9638 9668 10739 9952 38631 9283 25503 21876 80174 11489 22224 119692 119780 9638 9434 48599 10622 119593 9460 14867 10459 9309 118943 11102 9599 47465 9983 33654 119859 18227 14843 9460 119547 9612 14801 78705 65569 9144 19709 9638 34907 10892 8843 14040 118649 10530 100876 9901 55635 8934 12965 9407 49919 118800 12310 119838 103 9434 48599 10622 69164 12310 20729 110862 9568 12310 16439 9521 32501 58088 9654 9322 12508 55698 9668 119555 102 11287 54780 8843 14040 118649 10459 9707 86580 110463 119642 12092 9665 80579 9322 12508 55698 9668 12092 103 24974 53371 59894 23969 9668 11489 63552 9638 120653 52579 9612 14801 78705 103 9786 118927 17342 11513 119593 9538 60454 9952 38631 119859 9999 118813 103 14867 119977 119867 119859 42815 43962 21611 10459 120023 103064 9538 18784 9625 43962 121662 119838 90373 82564 107657 119927 14523 119219 9460 68943 23925 119735 119554 119573 119800 120442 94199 103 9485 120139 119859 9625 43962 119559 119567 14279 14801 103 18471 119859 10892 119600 9795 25517 54141 119859 11882 119572 13374 119859 8996 103 31720 119199 32158 110858 18666 58821 58638 119782 120046 25685 27487 9059 120653 119944 119859 31605 9460 120288 11882 9765 14801 42984 9608 33077 96972 119552 48533 10530 45893 119977 119800 120442 94199 119580 14843 28467 119859 31605 9656 32158 11467 39629 120388 73894 9652 14153 9407 16605 59330 9460 118964 10530 39218 11018 120023 11287 119547 9682 9074 120074 17022 119867 120218 42815 43962 21611 10459 9625 43962 119559 119986 119828 14867 103 119867 120218 42815 43962 21611 11018 153 91238 119878 11489 119550 12453 13767 119800 120442 33768 110858 61635 110863 46968 19718 103 119643 120634 119800 120442 33768 10459 28467 9102 9657 10459 119859 19105 10622 119593 103 43962 10622 9407 16605 22440 20729 9717 10892 119612 103 45465 10459 9625 43962 120150 119559 15303 9657 67477 103 76123 10015 103 120132 11882 9763 30858 119956 9316 119552 119757 10530 22799 9625 43962 119559 85533 11287 9061 17342 12508 12310 20729 9368 119445 120045 93050 16294 16261 10157 119638 119623 14843 9460 77324 120023 11287 119798 11733 11759 10131 119680 120318 66623 119927 22440 28195 119567 11467 53509 10213 10111 157 12892 103 119908 119647 12638 53509 10213 10131 120007 113 89478 11166 119748 9485 120139 120218 9625 43962 21611 119281 33768 119941 72286 11779 110862 64766 24008 103 11090 120478 74297 35314 19561 79308 71200 10908 119643 110176 119548 9485 120139 119859 119941 72286 110862 64766 24008 110863 103 120478 74297 35314 119782 49919 100208 13441 119859 9485 21611 79604 92515 9954 119859 11489 9954 9692 119108 119859 119219 10622 9654 17342 31605 119563 35756 119612 10530 22799 100208 17022 119830 13374 73306 120316 52462 110864 119944 9485 120139 119859 10892 9954 9766 10892 119711 110862 19709 9954 9766 10892 119612 11467 119645 18623 119859 11925 110858 15417 37893 110862 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.977748 47619347533312 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1120 16:06:43.978214 47619347533312 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 26 30 85 94 133 147 160 192 202 216 290 312 327 337 347 350 402 428 449 491\n",
      "I1120 16:06:43.978433 47619347533312 create_pretraining_data.py:161] masked_lm_positions: 26 30 85 94 133 147 160 192 202 216 290 312 327 337 347 350 402 428 449 491\n",
      "INFO:tensorflow:masked_lm_ids: 9356 52579 9901 21614 9340 18471 14102 119728 78705 9330 79055 22414 9625 18784 102838 49543 79485 110863 11090 10892\n",
      "I1120 16:06:43.978618 47619347533312 create_pretraining_data.py:161] masked_lm_ids: 9356 52579 9901 21614 9340 18471 14102 119728 78705 9330 79055 22414 9625 18784 102838 49543 79485 110863 11090 10892\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "I1120 16:06:43.978808 47619347533312 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "I1120 16:06:43.978971 47619347533312 create_pretraining_data.py:161] next_sentence_labels: 0\n",
      "INFO:tensorflow:Wrote 1146149 total instances\n",
      "I1120 16:18:05.330859 47619347533312 create_pretraining_data.py:166] Wrote 1146149 total instances\n"
     ]
    }
   ],
   "source": [
    "!python create_pretraining_data.py \\\n",
    "--input_file=./training_data/Finalresult_30000.txt \\\n",
    "--vocab_file=final_vocab.txt \\\n",
    "--do_lower_case=False \\\n",
    "--max_seq_length=512 \\\n",
    "--output_file=./preprocessed_training_data/Finalresult_30000_tf.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
